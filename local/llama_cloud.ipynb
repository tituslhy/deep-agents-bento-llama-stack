{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27491480",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9631b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Alita? How does it work?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bd3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "alita_index = LlamaCloudIndex(\n",
    "  name=\"alita-index\",\n",
    "  project_name=\"Default\",\n",
    "  organization_id=\"bf9b425c-54cb-4182-a93f-8ac6aed04348\",\n",
    "  api_key=os.environ.get(\"LLAMA_CLOUD_API_KEY\"),\n",
    ")\n",
    "\n",
    "nodes = alita_index.as_retriever().retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19c925d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='2c753523-8829-4ad7-b85e-b648f422f5ae', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 1, 'start_page_index': 0, 'start_page_label': 1, 'end_page_index': 0, 'end_page_label': 1, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 1, 'end_char_idx': 2846}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='arXiv:2505.20286v1 [cs.AI] 26 May 2025\\n\\n# ALITA: GENERALIST AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL SELF-EVOLUTION\\n\\n<table>\\n<thead>\\n<tr>\\n<th>Author Name</th>\\n<th>Affiliation</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Jiahao Qiu*<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Xuan Qi*<sup>2</sup></td>\\n<td>IIIS, Tsinghua University</td>\\n</tr>\\n<tr>\\n<td>Tongcheng Zhang*<sup>3</sup></td>\\n<td>Shanghai Jiao Tong University</td>\\n</tr>\\n<tr>\\n<td>Xinzhe Juan<sup>3,4</sup></td>\\n<td>Shanghai Jiao Tong University, University of Michigan</td>\\n</tr>\\n<tr>\\n<td>Jiacheng Guo<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Yifu Lu<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Yimin Wang<sup>3,4</sup></td>\\n<td>Shanghai Jiao Tong University, University of Michigan</td>\\n</tr>\\n<tr>\\n<td>Zixin Yao<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Qihan Ren<sup>3</sup></td>\\n<td>Shanghai Jiao Tong University</td>\\n</tr>\\n<tr>\\n<td>Xun Jiang<sup>5</sup></td>\\n<td>Tianqiao and Chrissy Chen Institute</td>\\n</tr>\\n<tr>\\n<td>Xing Zhou<sup>5</sup></td>\\n<td>Tianqiao and Chrissy Chen Institute</td>\\n</tr>\\n<tr>\\n<td>Dongrui Liu<sup>3</sup></td>\\n<td>Shanghai Jiao Tong University</td>\\n</tr>\\n<tr>\\n<td>Ling Yang<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Yue Wu<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Kaixuan Huang<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Shilong Liu<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Hongru Wang<sup>6</sup></td>\\n<td>The Chinese University of Hong Kong</td>\\n</tr>\\n<tr>\\n<td>Mengdi Wang<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n## GAIA Benchmark\\n\\n<table>\\n<thead>\\n<tr>\\n<th>Level</th>\\n<th>Alita</th>\\n<th>manus.ai</th>\\n<th>OpenAI DeepResearch</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Level 1</td>\\n<td>88.7%</td>\\n<td>74.3%</td>\\n<td>86.5%</td>\\n</tr>\\n<tr>\\n<td>Level 2</td>\\n<td>89.5%</td>\\n<td>69.1%</td>\\n<td>70.1%</td>\\n</tr>\\n<tr>\\n<td>Level 3</td>\\n<td>76.9%</td>\\n<td>47.6%</td>\\n<td>57.7%</td>\\n</tr>\\n<tr>\\n<td>Average</td>\\n<td>87.3%</td>\\n<td>67.4%</td>\\n<td>73.3%</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nFigure 1: Performance of Alita, manus.ai, and OpenAI DeepResearch[1]\\n\\n## ABSTRACT\\n\\nRecent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita—a generalist agent designed with the principle of \"Simplicity is the ultimate sophistication,\" enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution.', mimetype='text/plain', start_char_idx=1, end_char_idx=2847, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8338803),\n",
       " NodeWithScore(node=TextNode(id_='c35f0a11-6235-472e-af32-99b3c2ae8421', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 1, 'start_page_index': 0, 'start_page_label': 1, 'end_page_index': 0, 'end_page_label': 1, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 2452, 'end_char_idx': 3894}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2c753523-8829-4ad7-b85e-b648f422f5ae', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 1}, hash='54839ae8c513067124938ecec5a87010d66bd4c8cafd5e15395cd177f3486922')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita—a generalist agent designed with the principle of \"Simplicity is the ultimate sophistication,\" enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. For Maximal self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at https://github.com/CharlesQ9/Alita.\\n\\n* These authors contributed equally to this work.', mimetype='text/plain', start_char_idx=2452, end_char_idx=3895, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.80126834),\n",
       " NodeWithScore(node=TextNode(id_='203850d5-b779-4c3e-81a7-7d7ef6412599', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 4, 'start_page_index': 3, 'start_page_label': 4, 'end_page_index': 3, 'end_page_label': 4, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 26493, 'end_char_idx': 30382}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1bdba247-a335-4ff9-872e-b8bb6a1de5b5', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 3}, hash='139c24376132d75e44a9923e3fcc6601e9d9a885767d714476a9c0ee62e8cc82')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# 3 Methods\\n\\nWe propose Alita, a generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal self-evolution to tackle diverse and complex tasks. Figure 3 illustrates the framework of Alita. In contrast to generalist agents that typically depend on extensive manually-designed tools and workflows [8, 9], the manager agent in Alita solely orchestrates the web agent using only basic tools. Through this approach, our framework enables Alita to plan task-specific tools through brainstorming. It then utilizes a Web Agent to search for helpful open-source libraries and other resources related to these tools. Leveraging the search results, Alita autonomously generates new tools and configures the necessary environments to enhance its capabilities and effectively solve tasks. During this process, if any issues arise with the newly generated tools or their environments, Alita can provide feedback and self-correct, improving the quality of the generated tools. Furthermore, the new tools can be encapsulated as MCP servers for future reuse. With the aid of MCPs, Alita can generate increasingly powerful, diverse, and complex MCPs, thus establishing a self-reinforcing cycle. Therefore, Alita autonomously expands its capabilities through continuous MCP integration.\\n\\n```mermaid\\nflowchart TD\\n    A[Question] --> B[Manager Agent]\\n    B <--> C[Web Agent]\\n    B --> D[MCP Brainstorming]\\n    D --> E[CodeReAct Loop]\\n    E --> F[Open-source Searching]\\n    E --> G[Script Generating]\\n    E --> H[Virtual Env Execution]\\n    F --> I[Encapsulate]\\n    G --> I\\n    H --> I\\n    I --> J[MCP Box]\\n    J --> K[Self Evolving]\\n    K --> B\\n    B --> L[Output]\\n```\\n\\nFigure 3: The architecture of Alita. Upon receiving a question, the Manager Agent initiates an iterative CodeReAct loop to analyze tasks, identify functional gaps, and trigger MCP Brainstorming for creative synthesis. The system dynamically performs open-source searching, script generation, and virtual environment execution to construct task-related functions. Useful ones are encapsulated into reusable MCPs and stored in the MCP Box. Throughout this process, the Manager Agent collaborates with the Web Agent for external information retrieval and continuously integrates intermediate results until a final output is produced. This process enables Alita to self-evolve without relying on a huge hand-crafted, elaborate tools and workflows.\\n\\n## 3.1 Execution Pipeline\\n\\nEach task commences with the construction of an augmented prompt that incorporates the original query. The manager agent (Sec. 3.2) then initiates a multi-step reasoning process to address the task at hand. Throughout this process, the agent may query external sources via the web agent (Sec. 3.3), plan and synthesize new tools (Sec. 3.4), and execute them within isolated environments (Sec. 3.4.4).\\n\\nUpon successful tool generation and accurate result formulation, the corresponding script is transformed into an MCP and stored in the internal tool registry for future reuse. All reasoning steps, intermediate code, and final outputs are systematically logged to facilitate comprehensive analysis.\\n\\n## 3.2 Manager Agent\\n\\nThe Manager Agent functions as the central coordinator within framework of Alita. When receiving a task prompt, the manager agent initially calls the MCP Brainstorming to determine whether additional tools are needed and which specific tools are required. Then the manager agent decomposes the task into subtasks and dispatches them to web agent or generates the required external tools to complete the subtask. When necessary, the manager agent utilizes the information retrieved by the web agent to generate the required new tools along with their corresponding environment configuration instructions. After collecting all intermediate results, the manager performs final aggregation and response formulation.\\n\\n4', mimetype='text/plain', start_char_idx=1, end_char_idx=3891, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7366474),\n",
       " NodeWithScore(node=TextNode(id_='1bdba247-a335-4ff9-872e-b8bb6a1de5b5', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 3, 'start_page_index': 2, 'start_page_label': 3, 'end_page_index': 2, 'end_page_label': 3, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 17226, 'end_char_idx': 21851}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0f146545-b3af-470e-8b39-57d35d7889af', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 2}, hash='f2842960bb2d79c11b589f7383db5c6527307654f23c40f658dbe32cba932d17')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"* We present Alita, a generalist agent that achieves scalable agentic reasoning with a radically simple design.\\n* We empirically demonstrate that Alita, despite using no complex predefined tools and workflows for specific tasks, outperforms many systems with significantly more handcrafted complexity on the GAIA benchmark. We achieve 75.15% pass@1 and 87.27% pass@3, surpassing OpenAI's Deep Research with 67.36% pass@1 and ranking top among all general-purpose agents.\\n\\n## 2 Related Works\\n\\n### 2.1 Generalist Agent\\n\\nThe concept of a Generalist Agent aims to construct an AI agent system capable of collaboratively completing a variety of complex tasks in a real-world environment. OWL [8] introduces a method that decomposes complex tasks into subtasks and dynamically allocates them to worker nodes with specialized toolkits. Omne [11] proposes a multi-agent collaborative development framework, where each agent possesses an independent system structure, enabling autonomous learning and the storage of a comprehensive world model to build an independent understanding of the environment. OpenAI Deep Research<sup>2</sup> employs reinforcement learning for training on real-world tasks, aiming to provide precise and reliable research reports for knowledge-intensive tasks. A-World [12] offers a highly configurable, modular, and scalable simulation environment, allowing developers to flexibly define and integrate different types of AI agents. The Magentic-One [13] framework merges the Magentic and Autogen systems, distinguishing between the micro-level LLM-driven function generation and the macro-level multi-agent orchestration, resulting in a clearer and more efficient construction of agent systems. Alita, also a Generalist Agent, allows for the minimal use of predefined tools and workflows for direct problem-solving, yet still achieves impressive performance across diverse tasks.\\n\\n### 2.2 Auto Generating Agent\\n\\nAuto-generating agents aim to enhance the versatility of agents by enabling them to autonomously generate tools, agents, or workflows tailored to specific tasks. AutoAgents [14], for instance, generate multiple agents, each playing a distinct role, to handle the corresponding subtasks. OpenHands [15] offers an event-driven architecture that allows agents to interact with the environment like human developers, thereby enabling the creation of custom workflows. AFlow [16] redefines workflow optimization as a search problem, where each workflow consists of several nodes invoking large LLMs, and the optimal workflow is identified and executed through a search process. AutoAgent [17], as an autonomous agent operating system, permits agents to manage system-level operations and file data autonomously. In Alita, agents are empowered to automatically generate diverse, specialized, and highly accurate MCPs to aid in the completion of specific tasks, while also providing resources for future executions.\\n\\n### 2.3 Tool Creation\\n\\nTool Creation enables agents to autonomously create tools to assist in task execution, either on their own or with external support. CRAFT [18] utilizes GPT-4 to generate a set of code snippets that function as tools, which are then retrieved and used in the system. TroVE [19] maintains a collection of high-level functions, which are automatically generated, extended, and periodically pruned to optimize program generation. CREATOR [20] decouples the abstraction of tool creation from the actual execution, allowing LLMs to address tasks at different levels of granularity. AutoAgent [17] enables agents to autonomously create new tools based on task requirements, incorporating information gathered through web searches and integrating these tools into their workflow. OpenHands [15] allows agents to create code scripts in a human-like manner during interaction with the environment to assist in task completion. In comparison, Alita enables MCP creation, which provides additional benefits, including better reusability and easy environment management over tool creation.\\n\\n### 2.4 MCP\\n\\nThe Model Context Protocol (MCP) is a standard proposed by Anthropic, designed to unify the connection between AI systems and external data sources and services. RAG-MCP [21] enhances the efficiency and accuracy of agents by retrieving the most relevant tools from a large collection, based on the task description, within the database composed of MCP descriptions. After tool generation, Alita wraps the generated valid tools into MCPs for subsequent use, facilitating reuse by itself and other agents.\\n\\n<sup>2</sup>https://openai.com/index/introducing-deep-research/\\n\\n3\", mimetype='text/plain', start_char_idx=2, end_char_idx=4628, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7327644),\n",
       " NodeWithScore(node=TextNode(id_='0f146545-b3af-470e-8b39-57d35d7889af', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 2, 'start_page_index': 1, 'start_page_label': 2, 'end_page_index': 1, 'end_page_label': 2, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 7801, 'end_char_idx': 12505}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c35f0a11-6235-472e-af32-99b3c2ae8421', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 1}, hash='e9edaa9a6f3ed724e359e5a68c9e33dbc601a1333c3718ae04d95b459c555624')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# 1 Introduction\\n\\n> \"Simplicity is the ultimate sophistication.\" — Leonardo da Vinci\\n\\nLarge language models (LLMs) have rapidly evolved from merely generating text to autonomous agents capable of independently planning and executing complex tasks on behalf of users with limited human oversight [2]. These capabilities have enabled a wide range of applications, ranging from travel planning [3], computer use [4, 5, 6], to the multi-step research tasks [7]. To support such diverse and demanding tasks, a new class of systems called generalist agents has emerged. These agents are designed to handle a wide range of domains and tasks through a unified architecture, allowing them to generalize beyond task-specific solutions, such as OpenAI Deep Research [1] and Manus.\\n\\nHowever, most of the current general-purpose agents heavily rely on large-scale manual engineering, including tediously designed workflows, considerable pre-defined tools, and hardcoded components [8, 9]. This reliance introduces several critical limitations: i) It is impractical, if not impossible, to predefine all the tools required for the wide variety of real-world tasks an agent might encounter (incomplete coverage); ii) Many complex tasks require agents to creatively compose new tools or leverage existing ones in novel ways while pre-designed workflow and hardcoded components constrain this compositional flexibility and inhibit the development of adaptive behaviors (limited creativity and flexibility); iii) It is not always the case that the interface or environment of different tools are compatible with the agent (mismatch). For example, many useful tools are not written in Python, which makes it difficult, though not entirely impossible, for them to be pre-connected to the mainstream agent frameworks that are primarily written in Python. Together, these challenges ultimately hinder the scalability, adaptability, and generalization of existing generalist agents.\\n\\nIn contrast to the prevailing trend of growing complexity, we propose a radically simple design philosophy built on two principles: i) Minimal Predefinition: Equip the agent with only a minimal set of core capabilities, avoiding manually engineered components for specific tasks or modalities; ii) Maximal Self-Evolution: Empower the agent to autonomously create, refine, and reuse external capabilities as needed. We instantiate this vision through Alita, a generalist agent built with a single core capability (i.e., the web agent) and a small set of general-purpose modules that enable self-directed capability expansion. Specifically, we take advantage of the Model Context Protocols (MCPs)<sup>1</sup> which is an open protocol that standardizes how different systems provide context to LLMs, and empower Alita to dynamically generate, adapt, and reuse MCPs based on the demands of each task rather than relying on static, predefined tools. This shift from manually designed capabilities to on-the-fly MCP construction unlocks a new path for building agents that are simple yet profoundly capable.\\n\\n<table>\\n<thead>\\n<tr>\\n<th>Agent Type</th>\\n<th>Components</th>\\n<th>Approach</th>\\n<th>Characteristics</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Traditional Generalist Agents</td>\\n<td>Url Text Extractor, Web Agent, Path Generalist Classifier, Image Captioner, Relevant Patch Zoomer, Other Agents, Manager Agent, Youtube Caption Crawler</td>\\n<td>Large-scale Manual Engineering</td>\\n<td>Incomplete Coverage, Limited Creativity & Flexibility, Mismatch</td>\\n</tr>\\n<tr>\\n<td>Alita (Ours)</td>\\n<td>Web Agent, Manager Agent</td>\\n<td>Minimal Predefinition → MCP Creation → Self Evolving → MCP Box → Maximal Self-Evolution</td>\\n<td>Scalable Dynamic Capability, Enhanced Creativity & Flexibility, Cross-ecosystem Compatibility</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nFigure 2: Comparison between Traditional Generalist Agents and Alita. Traditional generalist agents heavily rely on large-scale manual engineering while Alita adheres to minimal predefinition and maximal self-evolution.\\n\\nWe conduct comprehensive experiments on several benchmarks to assess Alita in real-world applications, especially on the most popular GAIA [10]. Alita proves that simplicity is not a constraint, but a strength, and that creative agent behavior can emerge from a design that prioritizes autonomy over manual engineering. To sum up, our key contributions can be summarized as follows.\\n\\n• We propose a new agent architecture centered on minimal predefinition and maximal self-evolution, challenging conventional design norms in generalist agents, aiming to call for a more scalable and generalizable agent framework.\\n\\n<sup>1</sup>https://www.anthropic.com/news/model-context-protocol\\n\\n2', mimetype='text/plain', start_char_idx=1, end_char_idx=4706, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7206637),\n",
       " NodeWithScore(node=TextNode(id_='c8acfed6-c282-4778-a819-4a8317ce79c5', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 9, 'start_page_index': 8, 'start_page_label': 9, 'end_page_index': 8, 'end_page_label': 9, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 69886, 'end_char_idx': 71582}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d90db199-6b8a-4bb4-b591-b0a427b8dbee', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 8}, hash='642087e1ccc06e93d8eddafc9fb20d77bff72fa00561c8db8486b411a150a1fa')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"<table>\\n<thead>\\n<tr>\\n<th>Model Configuration</th>\\n<th>Level 1</th>\\n<th>Level 2</th>\\n<th>Level 3</th>\\n<th>Total</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Alita (Claude-3.7-Sonnet, GPT-4o)</td>\\n<td>81.13%</td>\\n<td>75.58%</td>\\n<td>46.15%</td>\\n<td>72.73%</td>\\n</tr>\\n<tr>\\n<td>Alita (GPT-4o-mini)</td>\\n<td>54.72%</td>\\n<td>44.19%</td>\\n<td>19.23%</td>\\n<td>43.64%</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nTable 4: Comparison of performance between Alita(Claude-3.7-Sonnet,GPT-4o) and Alita(GPT-4o-mini). The results are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the performance at the respective GAIA levels. The integration of a smaller model significantly reduces the performance.\\n\\n### 5.3 Case Study\\n\\nTo investigate Alita's workflow when tackling tasks, we conducted a case study on its approach to solving a Level 3 difficult problem in GAIA. The details of this process are presented in Appendix A. From the case study, we observe that Alita is able to perform a structured MCP brainstorming session based on the task at hand, effectively identifying and utilizing relevant resources to implement a feasible MCP that aids in completing the task.\\n\\n## 6 Conclusion\\n\\nIn this work, we introduced Alita, a generalist agent designed with the principles of minimal predefinition and maximal self-evolution. By significantly reducing reliance on manually predefined tools and workflows for direct solving, Alita leverages creative, autonomous capabilities in real time, facilitating scalable agentic reasoning. Our approach demonstrates that simplicity in design does not undermine, but rather enhances, the performance and adaptability of generalist agents.\\n\\n9\", mimetype='text/plain', start_char_idx=2, end_char_idx=1699, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.638588)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a95e7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Response:** **Alita** is a general‑purpose AI agent that focuses on two core ideas:  \n",
       "1. **Minimal predefinition** – it starts with only a handful of built‑in components (a web‑search agent and a manager that orchestrates everything).  \n",
       "2. **Maximal self‑evolution** – it can create, refine, and reuse its own tools on the fly by generating *Model Context Protocols* (MCPs) from open‑source resources.\n",
       "\n",
       "---\n",
       "\n",
       "### How it works\n",
       "\n",
       "1. **Question intake** – The manager receives a user query and builds an augmented prompt.  \n",
       "2. **Iterative reasoning** – Using a Code‑ReAct style loop, the manager analyses the task, decomposes it into subtasks, and decides whether new tools are needed.  \n",
       "3. **Tool discovery & creation**  \n",
       "   * The web agent searches the internet for relevant libraries or code snippets.  \n",
       "   * The manager synthesizes these findings into executable scripts.  \n",
       "   * Scripts that prove useful are wrapped into MCPs, stored in an internal “MCP Box,” and can be invoked later.  \n",
       "4. **Execution** – Generated tools run in isolated virtual environments; any errors are fed back to the manager for correction.  \n",
       "5. **Output** – Once all subtasks are resolved, the manager aggregates the results and returns the final answer.\n",
       "\n",
       "Through this cycle, Alita continually expands its own capability set without relying on a large, hand‑crafted toolbox, enabling it to tackle a wide range of tasks with high adaptability and scalability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from langsmith import traceable\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "llm = Ollama(model=\"gpt-oss:20b\", temperature=0)\n",
    "alita_query_engine = alita_index.as_query_engine(llm=llm)\n",
    "\n",
    "@traceable(type=\"tool\", name=\"alita\")\n",
    "def alita_knowledge_base(query: str):\n",
    "    \"\"\"For traceability of the alita RAG engine\"\"\"\n",
    "    return alita_query_engine.query(query)\n",
    "    \n",
    "# response = alita_query_engine.query(query)\n",
    "response = alita_knowledge_base(query=query)\n",
    "\n",
    "display(Markdown(f\"**Response:** {response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e49b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_zero_index = LlamaCloudIndex(\n",
    "  name=\"mcp-zero-index\",\n",
    "  project_name=\"Default\",\n",
    "  organization_id=\"bf9b425c-54cb-4182-a93f-8ac6aed04348\",\n",
    "  api_key=os.environ.get(\"LLAMA_CLOUD_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f49db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Retriever(name='Alita and MCP Zero Retriever', pipelines=[RetrieverPipeline(name='alita-paper', description='Knowledge base for the Alita paradigm for agents', pipeline_id='6e287db8-a658-48c2-837f-1e13c85edc84', preset_retrieval_parameters=PresetRetrievalParams(dense_similarity_top_k=30, dense_similarity_cutoff=0.0, sparse_similarity_top_k=30, enable_reranking=True, rerank_top_n=6, alpha=0.5, search_filters=None, search_filters_inference_schema=None, files_top_k=1, retrieval_mode=<RetrievalMode.CHUNKS: 'chunks'>, retrieve_image_nodes=False, retrieve_page_screenshot_nodes=False, retrieve_page_figure_nodes=False, class_name='base_component')), RetrieverPipeline(name='mcp-zero-paper', description='Knowledge base of the (model context protocol) MCP zero paradigm', pipeline_id='1d5c48e0-9849-49a6-a59d-0af4eb09f794', preset_retrieval_parameters=PresetRetrievalParams(dense_similarity_top_k=30, dense_similarity_cutoff=0.0, sparse_similarity_top_k=30, enable_reranking=True, rerank_top_n=6, alpha=0.5, search_filters=None, search_filters_inference_schema=None, files_top_k=1, retrieval_mode=<RetrievalMode.CHUNKS: 'chunks'>, retrieve_image_nodes=False, retrieve_page_screenshot_nodes=False, retrieve_page_figure_nodes=False, class_name='base_component')), RetrieverPipeline(name='alita-index', description='Knowledge base for the Alita paradigm for agents', pipeline_id='e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', preset_retrieval_parameters=PresetRetrievalParams(dense_similarity_top_k=30, dense_similarity_cutoff=0.0, sparse_similarity_top_k=30, enable_reranking=True, rerank_top_n=6, alpha=0.5, search_filters=None, search_filters_inference_schema=None, files_top_k=1, retrieval_mode=<RetrievalMode.CHUNKS: 'chunks'>, retrieve_image_nodes=False, retrieve_page_screenshot_nodes=False, retrieve_page_figure_nodes=False, class_name='base_component')), RetrieverPipeline(name='mcp-zero-index', description='Knowledge base of the (model context protocol) MCP zero paradigm', pipeline_id='a8f66184-b5e1-487d-a65f-3a78c5b4ae1d', preset_retrieval_parameters=PresetRetrievalParams(dense_similarity_top_k=30, dense_similarity_cutoff=0.0, sparse_similarity_top_k=30, enable_reranking=True, rerank_top_n=6, alpha=0.5, search_filters=None, search_filters_inference_schema=None, files_top_k=1, retrieval_mode=<RetrievalMode.CHUNKS: 'chunks'>, retrieve_image_nodes=False, retrieve_page_screenshot_nodes=False, retrieve_page_figure_nodes=False, class_name='base_component'))], id='d2c4add1-f4cb-41a0-bcfd-58dac5293769', created_at=datetime.datetime(2025, 8, 13, 2, 38, 0, 856052, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 8, 24, 5, 24, 20, 81070, tzinfo=datetime.timezone.utc), project_id='6bdb9346-fa87-4a33-a621-f595ccbb5986')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_cloud import CompositeRetrievalMode\n",
    "from llama_index.indices.managed.llama_cloud import (\n",
    "    LlamaCloudCompositeRetriever,\n",
    ")\n",
    "\n",
    "retriever = LlamaCloudCompositeRetriever(\n",
    "    name=\"Alita and MCP Zero Retriever\",\n",
    "    api_key=os.environ.get(\"LLAMA_CLOUD_API_KEY\"),\n",
    "    create_if_not_exists=True,\n",
    "    mode=CompositeRetrievalMode.FULL,\n",
    "    rerank_top_n=6,\n",
    ")\n",
    "retriever.add_index(\n",
    "    alita_index, description=\"Knowledge base for the Alita paradigm for agents\"\n",
    ")\n",
    "retriever.add_index(\n",
    "    mcp_zero_index, description=\"Knowledge base of the (model context protocol) MCP zero paradigm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6496e898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 ms, sys: 5.01 ms, total: 26.7 ms\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(llm=llm)\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What is Alita and what is MCP Zero? Can Alita and MCP zero work together?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2d6ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Response:** **Alita** is a general‑purpose agent that focuses on minimal pre‑defined tooling.  \n",
       "It can generate its own MCPs (Model‑Context Protocols) on the fly, allowing it to add new capabilities during a task and to share those MCPs with other agents. The agent’s design emphasizes self‑evolution and low upfront complexity while still achieving strong performance on a wide range of problems.\n",
       "\n",
       "**MCP Zero** is a technique for efficient, on‑demand tool discovery.  \n",
       "It asks the language model to explicitly request the tool it needs, then matches that request against a lightweight, semantically indexed collection of existing MCPs. The approach cuts prompt length dramatically, keeps retrieval accuracy high even when the tool pool is large, and maintains consistency across multi‑turn interactions.\n",
       "\n",
       "**Combining the two** is natural.  \n",
       "MCP Zero can first search the existing MCP collection and supply the best match to Alita. If no suitable MCP is found, Alita can invoke its tool‑creation workflow to build a new MCP, register it, and then MCP Zero can retrieve it in subsequent steps. This creates a virtuous loop where the agent actively discovers and, when necessary, creates the tools it needs, leading to a self‑sustaining, cost‑aware agent ecosystem."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"**Response:** {response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a95c645",
   "metadata": {},
   "source": [
    "## Test Llama 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c1863be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "llm = OpenAILike(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    api_key=os.getenv(\"BENTO_CLOUD_API_KEY\"),\n",
    "    api_base=f'{os.getenv(\"llama3_endpoint_url\")}/v1',\n",
    "    is_chat_model=True,\n",
    "    is_function_calling_model=True,\n",
    "    temperature=0,\n",
    "    timeout=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be44c12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=\"It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={'prompt_tokens': 37, 'completion_tokens': 23, 'total_tokens': 60}, raw=ChatCompletion(id='chatcmpl-9a5b68fc0cdcecf38ca3f2774e120f6d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"It's nice to meet you. Is there something I can help you with or would you like to chat?\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None), stop_reason=None)], created=1756476633, model='meta-llama/Meta-Llama-3.1-8B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=37, total_tokens=60, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None, kv_transfer_params=None), logprobs=None, delta=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.complete(\"Hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f61a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-agents-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
