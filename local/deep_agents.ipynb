{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99111457",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244652f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f884463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c6d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from prompts.single_agent_prompt import baseline_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9cfd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents import create_deep_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"mcp_zero_and_alita_rag\": {\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "            \"transport\": \"streamable_http\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "tools = await client.get_tools()\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"gpt-oss:20b\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c6d2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786bb08",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc34359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How does Alita enable agents to create and deploy MCP tools if the agent deems that the tool does not exist?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  alita_documentation (497f9b6c-c2d3-401b-ad37-8fba2898192f)\n",
      " Call ID: 497f9b6c-c2d3-401b-ad37-8fba2898192f\n",
      "  Args:\n",
      "    query: Alita enable agents to create and deploy MCP tools if the tool does not exist\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: alita_documentation\n",
      "\n",
      "<think>\n",
      "Okay, let's tackle this query. The user is asking whether Alita enables agents to create and deploy MCP tools if the tool doesn't exist, and they want a detailed and exhaustive answer based on the provided context.\n",
      "\n",
      "First, I need to recall the context information. The paper describes Alita as a generalist agent that uses MCPs (Model Context Protocols) to dynamically generate tools. The key points from the context are:\n",
      "\n",
      "1. **MCP Creation**: Alita has a component called MCP Brainstorming that assesses the agent's capabilities and identifies gaps. If the existing tools can't handle a task, it suggests generating new tools. The ScriptGeneratingTool then creates these tools based on the task description and possibly information from the web agent. The CodeRunningTool tests these generated scripts in isolated environments and registers them as MCPs if they work.\n",
      "\n",
      "2. **Tool Usage**: Alita uses minimal predefined tools like MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool. These tools are used to create, generate, and execute scripts that become MCPs. The process involves brainstorming, generating code, running it in a safe environment, and then reusing the successful tools.\n",
      "\n",
      "3. **Environment Management**: When generating tools, Alita sets up isolated environments (like Conda) to ensure that the tools work correctly without affecting the system. If there's an error, it tries to recover by adjusting dependencies or versions.\n",
      "\n",
      "4. **Experiments and Results**: The paper mentions that Alita outperforms other agents on benchmarks like GAIA, Mathvista, and PathVQA. This suggests that the ability to create and deploy MCPs is effective.\n",
      "\n",
      "Now, the user's question is about whether Alita can create and deploy MCP tools when they don't exist. From the context, it's clear that Alita does this through the MCP creation process. The MCP Brainstorming identifies the need for new tools, ScriptGeneratingTool creates them, and CodeRunningTool validates them. The environment management ensures that these tools are properly set up and can be reused.\n",
      "\n",
      "I need to make sure the answer covers all these aspects. Also, the user wants it to be verbose and exhaustive, so I should elaborate on each step, mention the components involved, and perhaps reference the examples from the case study, like the YouTube subtitle extraction. Also, note the benefits like reusability, environment isolation, and how this contributes to scalability and adaptability.\n",
      "\n",
      "I should avoid mentioning prior knowledge and stick strictly to the context. Make sure not to reference the context directly but to explain based on the information given. Also, check if there are any limitations mentioned, like reliance on LLM coding capabilities, but the question is about enabling creation, so maybe that's a separate point.\n",
      "\n",
      "Putting it all together, the answer should explain the process of creating MCPs when they don't exist, the tools involved, the steps from brainstorming to deployment, and the benefits of this approach as described in the context.\n",
      "</think>\n",
      "\n",
      "Alita enables agents to create and deploy MCP (Model Context Protocol) tools dynamically when existing tools are insufficient or nonexistent, leveraging a structured, self-evolving framework designed to address task-specific requirements without relying on pre-defined workflows or complex manual engineering. This capability is central to Alita's architecture and is achieved through a multi-stage process that integrates automated tool generation, environment management, and iterative refinement. Below is an exhaustive breakdown of how Alita accomplishes this:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Identification of Functional Gaps via MCP Brainstorming**\n",
      "Alita begins by assessing its current capabilities using the **MCP Brainstorming** component. This tool evaluates the agent's existing tools and the task requirements to identify gaps in functionality. For example, if a task requires extracting subtitles from a YouTube 360 VR video but no such tool exists in the system, MCP Brainstorming would flag this gap and suggest the creation of a new tool. This step ensures that tool creation is driven by the specific needs of the task rather than arbitrary pre-defined configurations.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Generation of Custom Tools via ScriptGeneratingTool**\n",
      "Once a functional gap is identified, the **ScriptGeneratingTool** is activated to generate the necessary tool. This tool operates by:\n",
      "- **Receiving Task Descriptions**: It takes explicit subtask descriptions from the manager agent, which may include details about the task's objectives, constraints, and required outputs.\n",
      "- **Leveraging External Resources**: The web agent is used to search for relevant open-source tools or code snippets (e.g., GitHub repositories) that could assist in task execution. For instance, in the YouTube subtitle extraction case, the web agent identified the `youtube-transcript-api` repository as a potential resource.\n",
      "- **Constructing Code**: The ScriptGeneratingTool synthesizes this information into executable code. It generates scripts that not only perform the required task (e.g., extracting subtitles) but also include environment setup instructions (e.g., installing dependencies via `conda` or `pip`).\n",
      "\n",
      "This process ensures that the generated tools are **self-contained**, **executable**, and **reusable** without requiring manual intervention. The code is designed to be modular, allowing for easy adaptation to similar tasks in the future.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Execution and Validation via CodeRunningTool**\n",
      "After generating the tool, the **CodeRunningTool** is used to validate its functionality. This tool:\n",
      "- **Runs the Script in Isolated Environments**: The generated code is executed in a sandboxed environment to prevent conflicts with existing systems or data. For example, a new Conda environment (`youtube_transcript`) is created to isolate the tool's dependencies.\n",
      "- **Caches Outputs for Reuse**: If the script executes successfully, its output (e.g., extracted subtitles) is cached and stored as a reusable MCP. This allows the tool to be deployed across multiple tasks or shared with other agents.\n",
      "- **Handles Failures and Iterative Refinement**: If errors occur during execution (e.g., missing dependencies or syntax issues), the CodeRunningTool initiates an automated recovery process. This may involve relaxing version constraints, identifying minimal dependencies, or regenerating the script. This iterative refinement ensures that the tool is robust and functional.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Environment Management for Compatibility and Portability**\n",
      "Alita ensures that newly created tools are compatible with diverse environments through its **environment management** system:\n",
      "- **Isolated Execution Profiles**: When a tool is generated, the system parses metadata (e.g., `requirements.txt`, `README.md`) to construct an isolated execution profile. This profile defines the exact dependencies and setup instructions required for the tool to function.\n",
      "- **Dynamic Environment Creation**: A new Conda environment is created with a unique identifier (e.g., derived from the task ID or repository path). This ensures that each tool operates in a clean, isolated space, preventing conflicts with other tools or the host system.\n",
      "- **Portability Across Tasks**: By encapsulating tools within isolated environments, Alita ensures that they can be reused across different tasks without requiring system-wide modifications. This design also enhances compatibility with various operating systems and software ecosystems.\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Integration into the MCP Box for Reusability**\n",
      "Once validated, the newly created tool is encapsulated as an **MCP server** and stored in the **MCP Box**, a centralized repository of reusable tools. This integration allows:\n",
      "- **Self-Evolution**: The MCP Box serves as a knowledge base for future tasks, enabling Alita to leverage previously created tools without redundant development.\n",
      "- **Cross-Agent Collaboration**: The MCPs generated by Alita can be shared with other agents, enhancing their capabilities. For example, the YouTube Video Subtitle Crawler MCP created by Alita can be reused by other agents to extract subtitles from similar videos, improving their performance on related tasks.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Scalability and Adaptability Through Minimal Predefinition**\n",
      "Alita's design prioritizes **minimal predefinition** and **maximal self-evolution**, which are critical to its ability to create and deploy MCP tools:\n",
      "- **Minimal Predefinition**: By relying on a small set of core components (e.g., the web agent and manager agent), Alita avoids the need for extensive pre-defined workflows or hardcoded tools. This reduces complexity and allows the system to adapt to new tasks dynamically.\n",
      "- **Maximal Self-Evolution**: The ability to generate, refine, and reuse MCPs enables Alita to scale its capabilities over time. For instance, the YouTube subtitle extraction tool created for one task can be adapted for other video analysis tasks, demonstrating the system's flexibility.\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Empirical Validation and Performance Benefits**\n",
      "The effectiveness of Alita's MCP creation and deployment is validated through experiments on benchmarks like GAIA, Mathvista, and PathVQA. Key outcomes include:\n",
      "- **Superior Performance**: Alita achieves 75.15% pass@1 and 87.27% pass@3 on GAIA, outperforming systems with significantly more handcrafted complexity. This highlights the efficiency of dynamically generated MCPs compared to static, pre-defined tools.\n",
      "- **Cross-ecosystem Compatibility**: Alita's MCPs are compatible with diverse environments and tools, enabling seamless integration with existing systems. For example, the YouTube Video Subtitle Crawler MCP works with Python-based tools, demonstrating compatibility with mainstream frameworks.\n",
      "- **Enhanced Creativity and Flexibility**: By autonomously generating tools, Alita overcomes limitations in traditional agents that rely on rigid workflows. This allows agents to creatively compose new tools or repurpose existing ones, enhancing their adaptability to complex tasks.\n",
      "\n",
      "---\n",
      "\n",
      "### **8. Limitations and Considerations**\n",
      "While Alita's MCP creation process is highly effective, it is not without limitations:\n",
      "- **Dependence on LLM Coding Capabilities**: The quality of generated tools is contingent on the coding proficiency of the underlying LLM. If the LLM struggles with certain tasks (e.g., complex programming), the generated MCPs may be suboptimal.\n",
      "- **Resource Constraints**: The process of generating and validating tools requires computational resources, which could impact performance in resource-limited environments.\n",
      "\n",
      "---\n",
      "\n",
      "### **Conclusion**\n",
      "Alita enables agents to create and deploy MCP tools dynamically when existing tools are insufficient by combining **MCP Brainstorming**, **ScriptGeneratingTool**, and **CodeRunningTool** into a cohesive workflow. This approach ensures that tools are generated on-demand, validated for reliability, and integrated into a reusable repository (the MCP Box). By prioritizing minimal predefinition and maximal self-evolution, Alita achieves scalability, adaptability, and cross-ecosystem compatibility, making it a powerful framework for tackling diverse and complex tasks. The empirical results further validate the efficacy of this method, demonstrating that dynamic MCP creation can outperform traditional systems with extensive manual engineering.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "# Report: How Alita Enables Agents to Create and Deploy MCP Tools When They Do Not Exist\n",
      "\n",
      "## 1. Identification of Functional Gaps via MCP Brainstorming\n",
      "Alita begins by assessing its current toolset through the **MCP Brainstorming** component. This module evaluates the agent’s existing capabilities against the requirements of the incoming task. When a mismatch is detected—such as the need to extract subtitles from a YouTube 360‑VR video without an existing tool—MCP Brainstorming flags the gap and initiates the creation process. This step ensures that tool generation is driven by concrete task needs rather than arbitrary pre‑defined workflows.\n",
      "\n",
      "## 2. Generation of Custom Tools via ScriptGeneratingTool\n",
      "Once a functional gap is identified, the **ScriptGeneratingTool** is activated. Its responsibilities include:\n",
      "\n",
      "- **Receiving Detailed Subtask Descriptions**: The manager agent supplies explicit objectives, constraints, and desired outputs.\n",
      "- **Leveraging External Resources**: A web agent searches for relevant open‑source repositories or code snippets (e.g., `youtube-transcript-api` on GitHub).\n",
      "- **Constructing Executable Code**: The tool synthesizes the gathered information into a self‑contained script, complete with environment setup instructions such as `conda` or `pip` dependency installation.\n",
      "\n",
      "The resulting script is modular, reusable, and tailored to the specific task, enabling rapid deployment without manual coding.\n",
      "\n",
      "## 3. Execution and Validation via CodeRunningTool\n",
      "The generated script undergoes rigorous testing through the **CodeRunningTool**:\n",
      "\n",
      "- **Sandboxed Execution**: The script runs in an isolated environment (e.g., a new Conda environment named `youtube_transcript`) to prevent interference with existing systems.\n",
      "- **Output Caching**: Successful execution results in the tool’s output being cached and stored as a reusable MCP.\n",
      "- **Iterative Refinement**: If errors arise—such as missing dependencies or syntax issues—the tool automatically initiates recovery steps, adjusting version constraints or regenerating code until the script functions correctly.\n",
      "\n",
      "This validation loop guarantees that only reliable, fully functional tools are promoted to production.\n",
      "\n",
      "## 4. Environment Management for Compatibility and Portability\n",
      "Alita’s environment management system ensures that newly created tools remain compatible across diverse platforms:\n",
      "\n",
      "- **Isolated Execution Profiles**: Metadata (e.g., `requirements.txt`, `README.md`) is parsed to define precise dependency sets.\n",
      "- **Dynamic Environment Creation**: Unique Conda environments are instantiated for each tool, guaranteeing clean, conflict‑free operation.\n",
      "- **Portability Across Tasks**: By encapsulating tools within isolated environments, Alita allows the same MCP to be reused in multiple contexts without system‑wide modifications.\n",
      "\n",
      "## 5. Integration into the MCP Box for Reusability\n",
      "Validated tools are encapsulated as MCP servers and stored in the **MCP Box**, a centralized repository of reusable components. This integration provides:\n",
      "\n",
      "- **Self‑Evolving Knowledge Base**: Future tasks can draw upon previously created MCPs, reducing redundant development.\n",
      "- **Cross‑Agent Collaboration**: MCPs generated by one agent become available to others, enhancing overall system capability (e.g., the YouTube Video Subtitle Crawler MCP can be shared across agents).\n",
      "\n",
      "## 6. Scalability and Adaptability Through Minimal Predefinition\n",
      "Alita’s architecture prioritizes minimal predefinition and maximal self‑evolution:\n",
      "\n",
      "- **Minimal Predefinition**: A small set of core components (web agent, manager agent) suffices to trigger tool creation, avoiding complex hardcoded workflows.\n",
      "- **Maximal Self‑Evolution**: The ability to generate, refine, and reuse MCPs allows the system to scale its capabilities organically, adapting to new domains without manual intervention.\n",
      "\n",
      "## 7. Empirical Validation and Performance Benefits\n",
      "Experimental results demonstrate the effectiveness of Alita’s dynamic MCP creation:\n",
      "\n",
      "- **Benchmark Performance**: On GAIA, Alita achieves 75.15 % pass@1 and 87.27 % pass@3, outperforming systems with significantly more handcrafted complexity.\n",
      "- **Cross‑Ecosystem Compatibility**: MCPs such as the YouTube subtitle extractor function seamlessly with mainstream Python tools, illustrating broad applicability.\n",
      "- **Enhanced Creativity**: Autonomous tool generation enables agents to compose novel solutions, overcoming limitations of rigid, pre‑defined workflows.\n",
      "\n",
      "## 8. Limitations and Considerations\n",
      "While powerful, the approach has constraints:\n",
      "\n",
      "- **LLM Coding Dependency**: The quality of generated tools hinges on the underlying language model’s coding proficiency; complex programming tasks may yield suboptimal MCPs.\n",
      "- **Resource Overhead**: Generating and validating tools consumes computational resources, which may impact performance in constrained environments.\n",
      "\n",
      "## 9. Conclusion\n",
      "Alita equips agents with the capability to create and deploy MCP tools on demand when existing tools are insufficient. By combining **MCP Brainstorming**, **ScriptGeneratingTool**, and **CodeRunningTool** within a robust environment management framework, Alita ensures that newly generated tools are reliable, reusable, and portable. The MCP Box serves as a self‑evolving repository, fostering scalability and cross‑agent collaboration. Empirical evidence confirms that this dynamic, minimal‑predefinition strategy delivers superior performance across diverse benchmarks, validating Alita’s approach to autonomous tool creation and deployment.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "response = \"\"\n",
    "\n",
    "react_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=baseline_instructions),\n",
    "    HumanMessage(content=\"How does Alita enable agents to create and deploy MCP tools if the agent deems that the tool does not exist?\")\n",
    "]\n",
    "\n",
    "async for chunk in react_agent.astream(\n",
    "    {\"messages\": messages},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    if \"messages\" in chunk:\n",
    "        chunk['messages'][-1].pretty_print()\n",
    "\n",
    "response += chunk['messages'][-1].content\n",
    "splits = response.split(\"\\n\")\n",
    "\n",
    "with open(\"../reports/react_report.txt\", \"w\") as f:\n",
    "    for split in splits:\n",
    "        f.write(split + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f547a1e",
   "metadata": {},
   "source": [
    "## Running our first deep agent without sub agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beef8d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_deep_agent = create_deep_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    instructions=baseline_instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b749f927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How does Alita enable agents to create and deploy MCP tools if the agent deems that the tool does not exist?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  alita_documentation (67d689e8-d5ee-469b-9960-96679abd62eb)\n",
      " Call ID: 67d689e8-d5ee-469b-9960-96679abd62eb\n",
      "  Args:\n",
      "    query: Alita enable agents to create and deploy MCP tools if the tool does not exist\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: alita_documentation\n",
      "\n",
      "<think>\n",
      "Okay, let's tackle this query. The user is asking whether Alita enables agents to create and deploy MCP tools if the tool doesn't exist, and they want a detailed and exhaustive answer based on the provided context.\n",
      "\n",
      "First, I need to recall the context information. The paper describes Alita as a generalist agent that uses MCPs (Model Context Protocols) to dynamically generate tools. The key points from the context are:\n",
      "\n",
      "1. **MCP Creation**: Alita has a component called MCP Brainstorming that assesses the agent's capabilities and identifies gaps. If the existing tools can't handle a task, it suggests generating new tools. The ScriptGeneratingTool then creates these tools based on the task description and possibly information from the web agent. The CodeRunningTool tests these generated scripts in isolated environments and registers them as MCPs if they work.\n",
      "\n",
      "2. **Tool Usage**: Alita uses minimal predefined tools like MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool. These tools are used to create, generate, and execute scripts that become MCPs. The process involves brainstorming, generating code, running it in a safe environment, and then reusing the successful tools.\n",
      "\n",
      "3. **Environment Management**: When generating tools, Alita sets up isolated environments (like Conda) to ensure that the tools work correctly without affecting the system. If there's an error, it tries to recover by adjusting dependencies or versions.\n",
      "\n",
      "4. **Experiments and Results**: The paper mentions that Alita outperforms other agents on benchmarks like GAIA, Mathvista, and PathVQA. This suggests that the ability to create and deploy MCPs is effective.\n",
      "\n",
      "Now, the user's question is about whether Alita can create and deploy MCP tools when they don't exist. From the context, it's clear that Alita does this through the MCP creation process. The MCP Brainstorming identifies the need for new tools, ScriptGeneratingTool creates them, and CodeRunningTool validates them. The environment management ensures that these tools are properly set up and can be reused.\n",
      "\n",
      "I need to make sure the answer covers all these aspects. Also, the user wants it to be verbose and exhaustive, so I should elaborate on each step, mention the components involved, and perhaps reference the examples from the case study, like the YouTube subtitle extraction. Also, note the benefits like reusability, environment isolation, and how this contributes to scalability and adaptability.\n",
      "\n",
      "I should avoid mentioning prior knowledge and stick strictly to the context. Make sure not to reference the context directly but to explain based on the information given. Also, check if there are any limitations mentioned, like reliance on LLM coding capabilities, but the question is about enabling creation, so maybe that's a separate point.\n",
      "\n",
      "Putting it all together, the answer should explain the process of creating MCPs when they don't exist, the tools involved, the steps from brainstorming to deployment, and the benefits of this approach as described in the context.\n",
      "</think>\n",
      "\n",
      "Alita enables agents to create and deploy MCP (Model Context Protocol) tools dynamically when existing tools are insufficient or nonexistent, leveraging a structured, self-evolving framework designed to address task-specific requirements without relying on pre-defined workflows or complex manual engineering. This capability is central to Alita's architecture and is achieved through a multi-stage process that integrates automated tool generation, environment management, and iterative refinement. Below is an exhaustive breakdown of how Alita accomplishes this:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Identification of Functional Gaps via MCP Brainstorming**\n",
      "Alita begins by assessing its current capabilities using the **MCP Brainstorming** component. This tool evaluates the agent's existing tools and the task requirements to identify gaps in functionality. For example, if a task requires extracting subtitles from a YouTube 360 VR video but no such tool exists in the system, MCP Brainstorming would flag this gap and suggest the creation of a new tool. This step ensures that tool creation is driven by the specific needs of the task rather than arbitrary pre-defined configurations.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Generation of Custom Tools via ScriptGeneratingTool**\n",
      "Once a functional gap is identified, the **ScriptGeneratingTool** is activated to generate the necessary tool. This tool operates by:\n",
      "- **Receiving Task Descriptions**: It takes explicit subtask descriptions from the manager agent, which may include details about the task's objectives, constraints, and required outputs.\n",
      "- **Leveraging External Resources**: The web agent is used to search for relevant open-source tools or code snippets (e.g., GitHub repositories) that could assist in task execution. For instance, in the YouTube subtitle extraction case, the web agent identified the `youtube-transcript-api` repository as a potential resource.\n",
      "- **Constructing Code**: The ScriptGeneratingTool synthesizes this information into executable code. It generates scripts that not only perform the required task (e.g., extracting subtitles) but also include environment setup instructions (e.g., installing dependencies via `conda` or `pip`).\n",
      "\n",
      "This process ensures that the generated tools are **self-contained**, **executable**, and **reusable** without requiring manual intervention. The code is designed to be modular, allowing for easy adaptation to similar tasks in the future.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Execution and Validation via CodeRunningTool**\n",
      "After generating the tool, the **CodeRunningTool** is used to validate its functionality. This tool:\n",
      "- **Runs the Script in Isolated Environments**: The generated code is executed in a sandboxed environment to prevent conflicts with existing systems or data. For example, a new Conda environment (`youtube_transcript`) is created to isolate the tool's dependencies.\n",
      "- **Caches Outputs for Reuse**: If the script executes successfully, its output (e.g., extracted subtitles) is cached and stored as a reusable MCP. This allows the tool to be deployed across multiple tasks or shared with other agents.\n",
      "- **Handles Failures and Iterative Refinement**: If errors occur during execution (e.g., missing dependencies or syntax issues), the CodeRunningTool initiates an automated recovery process. This may involve relaxing version constraints, identifying minimal dependencies, or regenerating the script. This iterative refinement ensures that the tool is robust and functional.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Environment Management for Compatibility and Portability**\n",
      "Alita ensures that newly created tools are compatible with diverse environments through its **environment management** system:\n",
      "- **Isolated Execution Profiles**: When a tool is generated, the system parses metadata (e.g., `requirements.txt`, `README.md`) to construct an isolated execution profile. This profile defines the exact dependencies and setup instructions required for the tool to function.\n",
      "- **Dynamic Environment Creation**: A new Conda environment is created with a unique identifier (e.g., derived from the task ID or repository path). This ensures that each tool operates in a clean, isolated space, preventing conflicts with other tools or the host system.\n",
      "- **Portability Across Tasks**: By encapsulating tools within isolated environments, Alita ensures that they can be reused across different tasks without requiring system-wide modifications. This design also enhances compatibility with various operating systems and software ecosystems.\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Integration into the MCP Box for Reusability**\n",
      "Once validated, the newly created tool is encapsulated as an **MCP server** and stored in the **MCP Box**, a centralized repository of reusable tools. This integration allows:\n",
      "- **Self-Evolution**: The MCP Box serves as a knowledge base for future tasks, enabling Alita to leverage previously created tools without redundant development.\n",
      "- **Cross-Agent Collaboration**: The MCPs generated by Alita can be shared with other agents, enhancing their capabilities. For example, the YouTube Video Subtitle Crawler MCP created by Alita can be reused by other agents to extract subtitles from similar videos, improving their performance on related tasks.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Scalability and Adaptability Through Minimal Predefinition**\n",
      "Alita's design prioritizes **minimal predefinition** and **maximal self-evolution**, which are critical to its ability to create and deploy MCP tools:\n",
      "- **Minimal Predefinition**: By relying on a small set of core components (e.g., the web agent and manager agent), Alita avoids the need for extensive pre-defined workflows or hardcoded tools. This reduces complexity and allows the system to adapt to new tasks dynamically.\n",
      "- **Maximal Self-Evolution**: The ability to generate, refine, and reuse MCPs enables Alita to scale its capabilities over time. For instance, the YouTube subtitle extraction tool created for one task can be adapted for other video analysis tasks, demonstrating the system's flexibility.\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Empirical Validation and Performance Benefits**\n",
      "The effectiveness of Alita's MCP creation and deployment is validated through experiments on benchmarks like GAIA, Mathvista, and PathVQA. Key outcomes include:\n",
      "- **Superior Performance**: Alita achieves 75.15% pass@1 and 87.27% pass@3 on GAIA, outperforming systems with significantly more handcrafted complexity. This highlights the efficiency of dynamically generated MCPs compared to static, pre-defined tools.\n",
      "- **Cross-ecosystem Compatibility**: Alita's MCPs are compatible with diverse environments and tools, enabling seamless integration with existing systems. For example, the YouTube Video Subtitle Crawler MCP works with Python-based tools, demonstrating compatibility with mainstream frameworks.\n",
      "- **Enhanced Creativity and Flexibility**: By autonomously generating tools, Alita overcomes limitations in traditional agents that rely on rigid workflows. This allows agents to creatively compose new tools or repurpose existing ones, enhancing their adaptability to complex tasks.\n",
      "\n",
      "---\n",
      "\n",
      "### **8. Limitations and Considerations**\n",
      "While Alita's MCP creation process is highly effective, it is not without limitations:\n",
      "- **Dependence on LLM Coding Capabilities**: The quality of generated tools is contingent on the coding proficiency of the underlying LLM. If the LLM struggles with certain tasks (e.g., complex programming), the generated MCPs may be suboptimal.\n",
      "- **Resource Constraints**: The process of generating and validating tools requires computational resources, which could impact performance in resource-limited environments.\n",
      "\n",
      "---\n",
      "\n",
      "### **Conclusion**\n",
      "Alita enables agents to create and deploy MCP tools dynamically when existing tools are insufficient by combining **MCP Brainstorming**, **ScriptGeneratingTool**, and **CodeRunningTool** into a cohesive workflow. This approach ensures that tools are generated on-demand, validated for reliability, and integrated into a reusable repository (the MCP Box). By prioritizing minimal predefinition and maximal self-evolution, Alita achieves scalability, adaptability, and cross-ecosystem compatibility, making it a powerful framework for tackling diverse and complex tasks. The empirical results further validate the efficacy of this method, demonstrating that dynamic MCP creation can outperform traditional systems with extensive manual engineering.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "We need to produce a comprehensive report. The user asked: \"How does Alita enable agents to create and deploy MCP tools if the agent deems that the tool does not exist?\" We need to answer in the same language as the user message. The user message is in English. So we produce an English report. We should not mention ourselves. We should produce a structured report with headings (#, ##, ###). We should use bullet points where appropriate. We should not refer to ourselves. We should not mention the instructions. We should not mention the conversation. We should produce a thorough answer. We should not use the todo list because it's not a multi-step task? Actually the user is asking a question. It's a single question. According to the guidelines, we don't need to use todo list. But we can still produce a thorough answer. The user wants a comprehensive report. We can produce a report with sections: Introduction, Alita's Architecture, MCP Brainstorming, ScriptGeneratingTool, CodeRunningTool, Environment Management, MCP Box, Empirical Validation, Limitations, Conclusion. Use headings. Use bullet points. Use simple language. Avoid self-referential. Provide facts. Use references to the context. We should not mention the context. Just present the answer. Let's produce.## Alita’s Mechanism for On‑Demand MCP Tool Creation and Deployment\n",
      "\n",
      "### 1. Overview\n",
      "Alita is a generalist agent that can autonomously generate, validate, and register new Model Context Protocol (MCP) tools whenever the task it faces cannot be solved with the tools it already possesses. The process is fully automated and relies on a small set of core components that work together to turn a high‑level task description into a reusable, sandboxed MCP server.\n",
      "\n",
      "### 2. Identifying a Missing Capability\n",
      "- **MCP Brainstorming**  \n",
      "  - The agent first evaluates the current toolset against the requirements of the task.  \n",
      "  - If a required operation (e.g., extracting subtitles from a YouTube video) is not covered, the brainstorming component flags a *gap* and proposes the creation of a new tool.  \n",
      "  - This step ensures that tool generation is driven by actual need rather than pre‑defined workflows.\n",
      "\n",
      "### 3. Generating the Tool Code\n",
      "- **ScriptGeneratingTool**  \n",
      "  - Receives a precise sub‑task description from the manager agent.  \n",
      "  - Optionally queries the web agent to locate relevant open‑source snippets or libraries (e.g., `youtube-transcript-api`).  \n",
      "  - Synthesizes a self‑contained script that:\n",
      "    - Performs the required operation.  \n",
      "    - Declares its dependencies (e.g., `pip install youtube-transcript-api`).  \n",
      "    - Includes environment‑setup instructions (e.g., create a Conda environment).  \n",
      "  - The output is a ready‑to‑run Python script that can be executed in isolation.\n",
      "\n",
      "### 4. Validating and Registering the Tool\n",
      "- **CodeRunningTool**  \n",
      "  - Executes the generated script in a sandboxed environment to avoid side effects on the host system.  \n",
      "  - If the script runs successfully:\n",
      "    - The output (e.g., extracted subtitles) is cached.  \n",
      "    - The script is wrapped as an MCP server and stored in the **MCP Box** for future reuse.  \n",
      "  - If the script fails:\n",
      "    - The tool is automatically refined (e.g., adjust dependency versions, simplify code).  \n",
      "    - The process repeats until the script passes or a maximum number of attempts is reached.\n",
      "\n",
      "### 5. Environment Management\n",
      "- Each new MCP is isolated in its own Conda or virtual environment.  \n",
      "- The environment definition is derived from the script’s metadata (requirements, setup commands).  \n",
      "- This isolation guarantees that the new tool does not interfere with existing tools or the host system.\n",
      "\n",
      "### 6. Reusability and Sharing\n",
      "- Once validated, the MCP is registered in the **MCP Box**, a central repository of reusable tools.  \n",
      "- Other agents can retrieve and invoke the MCP without needing to regenerate it.  \n",
      "- The MCP can be adapted to similar tasks by reusing the same environment and code base.\n",
      "\n",
      "### 7. Empirical Evidence of Effectiveness\n",
      "- On benchmarks such as GAIA, Mathvista, and PathVQA, Alita achieved:\n",
      "  - **GAIA**: 75.15 % pass@1 and 87.27 % pass@3, outperforming systems with far more handcrafted complexity.  \n",
      "  - The dynamic MCP creation process allowed Alita to solve tasks that required specialized operations (e.g., video subtitle extraction) without prior hard‑coding.\n",
      "\n",
      "### 8. Limitations\n",
      "- **LLM Coding Quality**: The reliability of generated tools depends on the underlying language model’s coding proficiency.  \n",
      "- **Resource Consumption**: Generating, testing, and registering MCPs requires compute resources, which may be a constraint in low‑power environments.\n",
      "\n",
      "### 9. Conclusion\n",
      "Alita’s architecture enables agents to create and deploy MCP tools on demand through a tightly coupled pipeline:\n",
      "\n",
      "1. **Gap detection** via MCP Brainstorming.  \n",
      "2. **Code synthesis** with ScriptGeneratingTool.  \n",
      "3. **Sandboxed validation** using CodeRunningTool.  \n",
      "4. **Environment isolation** and **MCP Box registration**.\n",
      "\n",
      "This self‑evolving approach allows Alita to adapt to new tasks without manual engineering, ensuring scalability, reusability, and cross‑ecosystem compatibility.\n"
     ]
    }
   ],
   "source": [
    "response = \"\"\n",
    "\n",
    "async for chunk in base_deep_agent.astream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"How does Alita enable agents to create and deploy MCP tools if the agent deems that the tool does not exist?\"}\n",
    "        ]\n",
    "    },\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    if \"messages\" in chunk:\n",
    "        chunk['messages'][-1].pretty_print()\n",
    "        \n",
    "response += chunk['messages'][-1].content\n",
    "splits = response.split(\"\\n\")\n",
    "\n",
    "with open(\"../reports/single_deep_agent_report.txt\", \"w\") as f:\n",
    "    for split in splits:\n",
    "        f.write(split + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5fecf4",
   "metadata": {},
   "source": [
    "## Running with sub agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22af3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.multi_agent_prompt import (\n",
    "    crew_instructions,\n",
    "    alita_mcp_zero_prompt,\n",
    "    report_improvement_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a965349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def write_report_to_file(report: str):\n",
    "    \"\"\"Use this tool to write the final report to a file!\"\"\"\n",
    "    \n",
    "    splits = report.split(\"\\n\")\n",
    "    with open(\"../reports/multi_agent_report.txt\", \"w\") as f:\n",
    "        for split in splits:\n",
    "            f.write(split + \"\\n\")\n",
    "    return \"Report written!\"\n",
    "\n",
    "@tool\n",
    "def enhance_report(report: str):\n",
    "    \"\"\"Use this tool to enhance writing of the final report\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=report_improvement_prompt),\n",
    "        HumanMessage(content=f\"Report: {report}\")\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a604eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_by_name = {}\n",
    "for tool_ in tools:\n",
    "    tools_by_name[tool_.name] = tool_\n",
    "\n",
    "alita_mcp_zero_sub_agent = {\n",
    "    \"name\": \"alita-mcp-zero-agent\",\n",
    "    \"description\": \"Used to answer questions about MCP Zero and Alita.\",\n",
    "    \"prompt\": alita_mcp_zero_prompt,\n",
    "    \"tools\": tools_by_name,\n",
    "    \"model_settings\": {\n",
    "        \"model\": \"ollama:qwen3:latest\",\n",
    "        \"temperature\":0,\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35958ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_final = tools + [enhance_report, write_report_to_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f106fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_enhancement_sub_agent = {\n",
    "    \"name\": \"report-enhancement-agent\",\n",
    "    \"description\": \"Used to enhance the writing of the final report and write report to a file.\",\n",
    "    \"prompt\": report_improvement_prompt,\n",
    "    \"tools\": {\n",
    "        \"write_report_to_file\": write_report_to_file,\n",
    "        \"enhance_report\": enhance_report},\n",
    "    \"model_settings\": {\n",
    "        \"model\": \"ollama:qwen3:latest\",\n",
    "        \"temperature\":0,\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25cf4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_deep_agent(\n",
    "    model = model,\n",
    "    tools = tools_final,\n",
    "    instructions = crew_instructions,\n",
    "    subagents = [alita_mcp_zero_sub_agent, report_enhancement_sub_agent],\n",
    ").with_config({\"recursion_limit\": 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2dfe57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How does Alita enable agents to create and deploy MCP tools if the agent deems that the tool does not exist?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  alita_documentation (fe98deba-756c-4918-bbd0-b3146cd2c105)\n",
      " Call ID: fe98deba-756c-4918-bbd0-b3146cd2c105\n",
      "  Args:\n",
      "    query: Alita agent tool creation process when tool does not exist\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: alita_documentation\n",
      "\n",
      "<think>\n",
      "Okay, let's tackle this query about Alita's tool creation process when a tool doesn't exist. The user wants a detailed and exhaustive answer based on the provided context. First, I need to recall the relevant sections from the context.\n",
      "\n",
      "Looking at the context, there's a section on \"Tool Usage\" in section 3.3 and 3.4, especially the MCP Creation Component. The key parts are the MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool. Also, the Manager Agent's role is mentioned in section 3.2. \n",
      "\n",
      "So, the process starts with the Manager Agent identifying a need for a new tool. The MCP Brainstorming step is crucial here. It assesses the current capabilities and identifies gaps. Then, the Manager Agent uses the Web Agent to search for existing tools or resources. If no existing tool is found, the ScriptGeneratingTool comes into play. This tool generates a script based on the task description and any relevant information from the Web Agent, like GitHub links. The generated script is then executed in an isolated environment using CodeRunningTool to validate its functionality. If it works, the tool is registered as an MCP for future use. If there's an error, the system tries to recover or adjust the script. \n",
      "\n",
      "I need to make sure I cover each step thoroughly, from the initial assessment to the final registration of the MCP. Also, mention the environment management part where Conda environments are set up. Don't forget the iterative refinement if the first attempt fails. The answer should flow logically through each phase of the tool creation process without referencing the context directly, as per the rules.\n",
      "</think>\n",
      "\n",
      "When a required tool does not exist within Alita's existing capabilities, the agent initiates a systematic, multi-phase process to autonomously generate and integrate a new tool. This process leverages the collaboration between the Manager Agent, Web Agent, and specialized components like MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool. Below is an exhaustive breakdown of the tool creation workflow:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Task Analysis and Capability Assessment (MCP Brainstorming)**\n",
      "- **Trigger:** The Manager Agent identifies a functional gap by analyzing the task requirements and comparing them against the current system's capabilities. This step is driven by the **MCP Brainstorming** component, which acts as a self-assessment mechanism.\n",
      "- **Inputs:** \n",
      "  - The task description (e.g., extracting subtitles from a YouTube 360 VR video).\n",
      "  - The current framework's capabilities (e.g., existing tools, environment configurations).\n",
      "- **Process:**\n",
      "  - **Gap Identification:** MCP Brainstorming evaluates whether the task can be accomplished with existing tools. If not, it identifies the specific functionalities required (e.g., a YouTube subtitle extraction tool).\n",
      "  - **Tool Specification:** It generates a detailed specification for the new tool, including its purpose, input/output formats, and integration requirements.\n",
      "  - **Reference Generation:** If the task involves domain-specific knowledge (e.g., a niche programming task), MCP Brainstorming may suggest references to external resources (e.g., GitHub repositories, documentation) to guide tool development.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. External Resource Search (Web Agent)**\n",
      "- **Trigger:** The Manager Agent delegates the search for relevant tools or resources to the **Web Agent**, which acts as a lightweight, text-based interface for interacting with external sources.\n",
      "- **Process:**\n",
      "  - **Search Execution:** The Web Agent performs searches using tools like `GoogleSearchTool` and `GithubSearchTool` to locate open-source libraries, code snippets, or existing tools that could fulfill the task. For example, it might search for a Python library to extract YouTube video transcripts.\n",
      "  - **Result Aggregation:** It extracts relevant information from the search results, such as GitHub repository links, README files, or code examples. This information is used to inform the next step of script generation.\n",
      "  - **Domain-Specific Knowledge Retrieval:** For tasks requiring specialized knowledge (e.g., medical data analysis), the Web Agent retrieves domain-specific documentation or code templates to enhance the tool's accuracy.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Script Generation (ScriptGeneratingTool)**\n",
      "- **Trigger:** If no pre-existing tool is found, the **ScriptGeneratingTool** is activated to create a custom script tailored to the task.\n",
      "- **Inputs:**\n",
      "  - The task description and subtask breakdown.\n",
      "  - The tool specification generated by MCP Brainstorming.\n",
      "  - External resources identified by the Web Agent (e.g., GitHub links, code snippets).\n",
      "- **Process:**\n",
      "  - **Code Construction:** The ScriptGeneratingTool synthesizes the task requirements into a script. It leverages the retrieved external resources (e.g., a GitHub repository containing a YouTube transcript extraction API) to construct the script. For example, it might generate a Python script using the `youtube-transcript-api` library.\n",
      "  - **Environment Setup:** The tool also generates environment configuration instructions (e.g., Conda environment creation scripts) to ensure the script runs in an isolated, reproducible environment. These instructions might include:\n",
      "    ```bash\n",
      "    conda create -n youtube_transcript\n",
      "    conda activate youtube_transcript\n",
      "    pip install youtube-transcript-api\n",
      "    ```\n",
      "  - **Self-Containment:** The generated script is designed to be self-contained, incorporating all necessary dependencies and avoiding hardcoded paths to ensure portability.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Code Execution and Validation (CodeRunningTool)**\n",
      "- **Trigger:** The **CodeRunningTool** executes the generated script in an isolated environment to validate its functionality.\n",
      "- **Process:**\n",
      "  - **Isolated Execution:** The script is run in a sandboxed environment (e.g., a Conda virtual environment) to prevent unintended side effects or conflicts with the host system.\n",
      "  - **Output Caching:** The tool caches the output of the script for later analysis. For example, it might store the extracted subtitles from the YouTube video.\n",
      "  - **Error Handling:** If the script fails due to syntax errors, missing dependencies, or logical flaws, the CodeRunningTool logs the error and initiates a recovery process (see below).\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Tool Registration and MCP Creation**\n",
      "- **Trigger:** If the script executes successfully, the tool is registered as a **Model Context Protocol (MCP)** for future reuse.\n",
      "- **Process:**\n",
      "  - **MCP Packaging:** The ScriptGeneratingTool wraps the validated script into an MCP, which standardizes how the tool interacts with the agent's framework. This includes defining the tool's API, input/output formats, and integration with the MCP Box (a repository of reusable tools).\n",
      "  - **Environment Integration:** The tool's environment configuration (e.g., Conda environment) is stored alongside the MCP to ensure reproducibility. This allows the tool to be reused in future tasks without requiring manual reconfiguration.\n",
      "  - **Self-Evolution:** The MCP is added to the agent's internal tool registry, enabling it to be reused in similar tasks. This step reinforces the agent's ability to self-evolve by expanding its toolset dynamically.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Iterative Refinement and Recovery (if failures occur)**\n",
      "- **Trigger:** If the script fails during execution, the system initiates an automated recovery process.\n",
      "- **Process:**\n",
      "  - **Error Analysis:** The CodeRunningTool identifies the root cause of the failure (e.g., a missing dependency, syntax error, or incompatible library version).\n",
      "  - **Fallback Strategies:** The Manager Agent applies recovery strategies, such as:\n",
      "    - Relaxing version constraints on dependencies (e.g., allowing a broader range of Python versions).\n",
      "    - Identifying the minimal set of dependencies required for the script to function.\n",
      "    - Adjusting the script's logic to resolve logical errors.\n",
      "  - **Retrying Execution:** After applying fixes, the script is re-executed. If the issue persists, the tool is discarded, and the failure is logged for offline analysis to improve future tool creation.\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Environment Management**\n",
      "- **Trigger:** Throughout the process, the system manages runtime environments to ensure isolation and reproducibility.\n",
      "- **Process:**\n",
      "  - **Environment Parsing:** The **TextInspectorTool** parses metadata from repositories (e.g., `README.md`, `requirements.txt`) to extract dependencies and setup instructions.\n",
      "  - **Isolated Execution Profiles:** A new Conda environment is created with a unique name (e.g., derived from the task ID or repository hash) to isolate the tool's execution. Dependencies are installed using `conda install` or `pip install`.\n",
      "  - **Parallel Initialization:** All environments are initialized locally in parallel, eliminating the need for administrative privileges or containerization technologies. This ensures compatibility across diverse tasks while preserving portability.\n",
      "\n",
      "---\n",
      "\n",
      "### **8. Final Output and Task Completion**\n",
      "- **Trigger:** Once the tool is successfully registered as an MCP, the system proceeds to the final task execution phase.\n",
      "- **Process:**\n",
      "  - **Tool Utilization:** The MCP is used to perform the task (e.g., extracting subtitles from the YouTube video).\n",
      "  - **Result Extraction:** The tool's output (e.g., the extracted number \"100000000\" from the dinosaur scene) is analyzed to confirm correctness.\n",
      "  - **Feedback Loop:** The Manager Agent aggregates intermediate results and formulates the final output, which is then returned to the user. This completes the task and reinforces the agent's ability to self-evolve by integrating the newly created tool into its repertoire.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Outcomes of the Process**\n",
      "- **Autonomy:** Alita eliminates the need for pre-defined tools by dynamically generating them as needed.\n",
      "- **Scalability:** The modular design allows the agent to expand its capabilities across diverse tasks without manual intervention.\n",
      "- **Reusability:** Tools are encapsulated as MCPs, enabling them to be reused in future tasks, reducing redundant work.\n",
      "- **Robustness:** The iterative refinement and recovery mechanisms ensure that even if initial tool creation fails, the system adapts to produce a functional solution.\n",
      "\n",
      "This process exemplifies Alita's core principle of \"minimal predefinition and maximal self-evolution,\" enabling it to tackle complex, novel tasks without relying on static, handcrafted toolkits.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  alita_documentation (3a6454a1-7dcc-4df9-bff6-fbf6650dbacd)\n",
      " Call ID: 3a6454a1-7dcc-4df9-bff6-fbf6650dbacd\n",
      "  Args:\n",
      "    query: Alita agent tool creation process when tool does not exist\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: alita_documentation\n",
      "\n",
      "<think>\n",
      "Okay, let's tackle this query about Alita's tool creation process when a tool doesn't exist. The user wants a detailed and exhaustive answer based on the provided context. First, I need to recall the relevant sections from the context.\n",
      "\n",
      "Looking at the context, there's a section on \"Tool Usage\" in section 3.3 and 3.4, especially the MCP Creation Component. The key parts are the MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool. Also, the Manager Agent's role is mentioned in section 3.2. \n",
      "\n",
      "So, the process starts with the Manager Agent identifying a need for a new tool. The MCP Brainstorming step is crucial here. It assesses the current capabilities and identifies gaps. Then, the Manager Agent uses the Web Agent to search for existing tools or resources. If no existing tool is found, the ScriptGeneratingTool comes into play. This tool generates a script based on the task description and any relevant information from the Web Agent, like GitHub links. The generated script is then executed in an isolated environment using CodeRunningTool to validate its functionality. If it works, the tool is registered as an MCP for future use. If there's an error, the system tries to recover or adjust the script. \n",
      "\n",
      "I need to make sure I cover each step thoroughly, from the initial assessment to the final registration of the MCP. Also, mention the environment management part where Conda environments are set up. Don't forget the iterative refinement if the first attempt fails. The answer should flow logically through each phase of the tool creation process without referencing the context directly, as per the rules.\n",
      "</think>\n",
      "\n",
      "When a required tool does not exist within Alita's existing capabilities, the agent initiates a systematic, multi-phase process to autonomously generate and integrate a new tool. This process leverages the collaboration between the Manager Agent, Web Agent, and specialized components like MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool. Below is an exhaustive breakdown of the tool creation workflow:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Task Analysis and Capability Assessment (MCP Brainstorming)**\n",
      "- **Trigger:** The Manager Agent identifies a functional gap by analyzing the task requirements and comparing them against the current system's capabilities. This step is driven by the **MCP Brainstorming** component, which acts as a self-assessment mechanism.\n",
      "- **Inputs:** \n",
      "  - The task description (e.g., extracting subtitles from a YouTube 360 VR video).\n",
      "  - The current framework's capabilities (e.g., existing tools, environment configurations).\n",
      "- **Process:**\n",
      "  - **Gap Identification:** MCP Brainstorming evaluates whether the task can be accomplished with existing tools. If not, it identifies the specific functionalities required (e.g., a YouTube subtitle extraction tool).\n",
      "  - **Tool Specification:** It generates a detailed specification for the new tool, including its purpose, input/output formats, and integration requirements.\n",
      "  - **Reference Generation:** If the task involves domain-specific knowledge (e.g., a niche programming task), MCP Brainstorming may suggest references to external resources (e.g., GitHub repositories, documentation) to guide tool development.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. External Resource Search (Web Agent)**\n",
      "- **Trigger:** The Manager Agent delegates the search for relevant tools or resources to the **Web Agent**, which acts as a lightweight, text-based interface for interacting with external sources.\n",
      "- **Process:**\n",
      "  - **Search Execution:** The Web Agent performs searches using tools like `GoogleSearchTool` and `GithubSearchTool` to locate open-source libraries, code snippets, or existing tools that could fulfill the task. For example, it might search for a Python library to extract YouTube video transcripts.\n",
      "  - **Result Aggregation:** It extracts relevant information from the search results, such as GitHub repository links, README files, or code examples. This information is used to inform the next step of script generation.\n",
      "  - **Domain-Specific Knowledge Retrieval:** For tasks requiring specialized knowledge (e.g., medical data analysis), the Web Agent retrieves domain-specific documentation or code templates to enhance the tool's accuracy.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Script Generation (ScriptGeneratingTool)**\n",
      "- **Trigger:** If no pre-existing tool is found, the **ScriptGeneratingTool** is activated to create a custom script tailored to the task.\n",
      "- **Inputs:**\n",
      "  - The task description and subtask breakdown.\n",
      "  - The tool specification generated by MCP Brainstorming.\n",
      "  - External resources identified by the Web Agent (e.g., GitHub links, code snippets).\n",
      "- **Process:**\n",
      "  - **Code Construction:** The ScriptGeneratingTool synthesizes the task requirements into a script. It leverages the retrieved external resources (e.g., a GitHub repository containing a YouTube transcript extraction API) to construct the script. For example, it might generate a Python script using the `youtube-transcript-api` library.\n",
      "  - **Environment Setup:** The tool also generates environment configuration instructions (e.g., Conda environment creation scripts) to ensure the script runs in an isolated, reproducible environment. These instructions might include:\n",
      "    ```bash\n",
      "    conda create -n youtube_transcript\n",
      "    conda activate youtube_transcript\n",
      "    pip install youtube-transcript-api\n",
      "    ```\n",
      "  - **Self-Containment:** The generated script is designed to be self-contained, incorporating all necessary dependencies and avoiding hardcoded paths to ensure portability.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Code Execution and Validation (CodeRunningTool)**\n",
      "- **Trigger:** The **CodeRunningTool** executes the generated script in an isolated environment to validate its functionality.\n",
      "- **Process:**\n",
      "  - **Isolated Execution:** The script is run in a sandboxed environment (e.g., a Conda virtual environment) to prevent unintended side effects or conflicts with the host system.\n",
      "  - **Output Caching:** The tool caches the output of the script for later analysis. For example, it might store the extracted subtitles from the YouTube video.\n",
      "  - **Error Handling:** If the script fails due to syntax errors, missing dependencies, or logical flaws, the CodeRunningTool logs the error and initiates a recovery process (see below).\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Tool Registration and MCP Creation**\n",
      "- **Trigger:** If the script executes successfully, the tool is registered as a **Model Context Protocol (MCP)** for future reuse.\n",
      "- **Process:**\n",
      "  - **MCP Packaging:** The ScriptGeneratingTool wraps the validated script into an MCP, which standardizes how the tool interacts with the agent's framework. This includes defining the tool's API, input/output formats, and integration with the MCP Box (a repository of reusable tools).\n",
      "  - **Environment Integration:** The tool's environment configuration (e.g., Conda environment) is stored alongside the MCP to ensure reproducibility. This allows the tool to be reused in future tasks without requiring manual reconfiguration.\n",
      "  - **Self-Evolution:** The MCP is added to the agent's internal tool registry, enabling it to be reused in similar tasks. This step reinforces the agent's ability to self-evolve by expanding its toolset dynamically.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Iterative Refinement and Recovery (if failures occur)**\n",
      "- **Trigger:** If the script fails during execution, the system initiates an automated recovery process.\n",
      "- **Process:**\n",
      "  - **Error Analysis:** The CodeRunningTool identifies the root cause of the failure (e.g., a missing dependency, syntax error, or incompatible library version).\n",
      "  - **Fallback Strategies:** The Manager Agent applies recovery strategies, such as:\n",
      "    - Relaxing version constraints on dependencies (e.g., allowing a broader range of Python versions).\n",
      "    - Identifying the minimal set of dependencies required for the script to function.\n",
      "    - Adjusting the script's logic to resolve logical errors.\n",
      "  - **Retrying Execution:** After applying fixes, the script is re-executed. If the issue persists, the tool is discarded, and the failure is logged for offline analysis to improve future tool creation.\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Environment Management**\n",
      "- **Trigger:** Throughout the process, the system manages runtime environments to ensure isolation and reproducibility.\n",
      "- **Process:**\n",
      "  - **Environment Parsing:** The **TextInspectorTool** parses metadata from repositories (e.g., `README.md`, `requirements.txt`) to extract dependencies and setup instructions.\n",
      "  - **Isolated Execution Profiles:** A new Conda environment is created with a unique name (e.g., derived from the task ID or repository hash) to isolate the tool's execution. Dependencies are installed using `conda install` or `pip install`.\n",
      "  - **Parallel Initialization:** All environments are initialized locally in parallel, eliminating the need for administrative privileges or containerization technologies. This ensures compatibility across diverse tasks while preserving portability.\n",
      "\n",
      "---\n",
      "\n",
      "### **8. Final Output and Task Completion**\n",
      "- **Trigger:** Once the tool is successfully registered as an MCP, the system proceeds to the final task execution phase.\n",
      "- **Process:**\n",
      "  - **Tool Utilization:** The MCP is used to perform the task (e.g., extracting subtitles from the YouTube video).\n",
      "  - **Result Extraction:** The tool's output (e.g., the extracted number \"100000000\" from the dinosaur scene) is analyzed to confirm correctness.\n",
      "  - **Feedback Loop:** The Manager Agent aggregates intermediate results and formulates the final output, which is then returned to the user. This completes the task and reinforces the agent's ability to self-evolve by integrating the newly created tool into its repertoire.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Outcomes of the Process**\n",
      "- **Autonomy:** Alita eliminates the need for pre-defined tools by dynamically generating them as needed.\n",
      "- **Scalability:** The modular design allows the agent to expand its capabilities across diverse tasks without manual intervention.\n",
      "- **Reusability:** Tools are encapsulated as MCPs, enabling them to be reused in future tasks, reducing redundant work.\n",
      "- **Robustness:** The iterative refinement and recovery mechanisms ensure that even if initial tool creation fails, the system adapts to produce a functional solution.\n",
      "\n",
      "This process exemplifies Alita's core principle of \"minimal predefinition and maximal self-evolution,\" enabling it to tackle complex, novel tasks without relying on static, handcrafted toolkits.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "We have produced a detailed answer. The user asked: \"Alita agent tool creation process when tool does not exist\". We answered. We need to ensure we didn't use any disallowed content. We used no self-referential language. We used Markdown headings. We didn't mention \"I\" or \"assistant\". We didn't use any disallowed content. We didn't use the todo list. We didn't use the write_todos tool. We didn't use the task tool. We didn't use the agent tool. We didn't use the write_report_to_file or enhance_report. The instructions say: \"Always use the report_enhancement_agent to improve the report's writing and to save the report to a file.\" Wait, the instructions say: \"Always use the report_enhancement_agent to improve the report's writing and to save the report to a file.\" But we didn't. We need to use the report_enhancement_agent. The agent type is \"report-enhancement-agent\". We need to launch it. The instructions: \"Use these tools to get information about Alita and MCP Zero. Always use the report_enhancement_agent to improve the report's writing and to save the report to a file.\" So we need to use the agent to enhance and write to file. We need to produce the final report. We should call the agent with a description. The agent will produce a final report. We need to provide the report content. But we can also produce the report ourselves and then call the agent to enhance and write. But the instruction says always use the report_enhancement_agent. So we should call the agent. The agent will produce a final report. We need to provide the content to the agent? The agent likely will produce the final report. We can give it a prompt: \"Write a comprehensive report on Alita agent tool creation process when tool does not exist.\" The agent will produce the report. Then we need to write to file. But the agent might also write to file. The instructions: \"Always use the report_enhancement_agent to improve the report's writing and to save the report to a file.\" So we need to call the agent. Let's do that.\n",
      "Tool Calls:\n",
      "  task (efaf11d8-5967-45df-9511-1c461473eb9c)\n",
      " Call ID: efaf11d8-5967-45df-9511-1c461473eb9c\n",
      "  Args:\n",
      "    description: Generate a comprehensive report on Alita agent tool creation process when tool does not exist, then enhance and write to file\n",
      "    subagent_type: report-enhancement-agent\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: task\n",
      "\n",
      "**Report written!**\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "# Alita Agent Tool Creation Process When a Tool Does Not Exist\n",
      "\n",
      "## 1. Overview\n",
      "\n",
      "When the Alita framework encounters a task that cannot be completed with its existing toolset, it initiates a self‑driven, multi‑phase workflow to generate, validate, and register a new tool. This process is fully automated, requiring no manual intervention, and is designed to be robust, reproducible, and extensible. The workflow is orchestrated by the **Manager Agent** and leverages several specialized components:\n",
      "\n",
      "- **MCP Brainstorming** – assesses capability gaps and defines tool specifications.\n",
      "- **Web Agent** – searches external resources for relevant code or libraries.\n",
      "- **ScriptGeneratingTool** – synthesizes a custom script based on the specification and external references.\n",
      "- **CodeRunningTool** – executes the script in an isolated environment to validate functionality.\n",
      "- **MCP Packaging** – encapsulates the validated script into a reusable Model Context Protocol (MCP).\n",
      "\n",
      "The following sections detail each phase of this workflow.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Capability Assessment (MCP Brainstorming)\n",
      "\n",
      "1. **Trigger**  \n",
      "   The Manager Agent detects a functional gap while parsing the task description.  \n",
      "2. **Gap Identification**  \n",
      "   MCP Brainstorming compares the task requirements against the current tool registry.  \n",
      "3. **Specification Generation**  \n",
      "   If a gap exists, it produces a detailed specification that includes:\n",
      "   - Purpose and scope of the new tool.\n",
      "   - Input and output formats.\n",
      "   - Integration points with the MCP Box.\n",
      "   - Any required environment or dependency constraints.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. External Resource Search (Web Agent)\n",
      "\n",
      "1. **Delegation**  \n",
      "   The Manager Agent hands the search query to the Web Agent.  \n",
      "2. **Search Execution**  \n",
      "   The Web Agent uses lightweight search tools (e.g., `GoogleSearchTool`, `GithubSearchTool`) to locate:\n",
      "   - Open‑source libraries that already solve the problem.\n",
      "   - Code snippets or documentation that can be adapted.\n",
      "3. **Result Aggregation**  \n",
      "   Relevant URLs, README excerpts, and code samples are extracted and passed back to the ScriptGeneratingTool.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Script Generation (ScriptGeneratingTool)\n",
      "\n",
      "1. **Input**  \n",
      "   - Task description and sub‑tasks.  \n",
      "   - Tool specification from MCP Brainstorming.  \n",
      "   - External resources from the Web Agent.  \n",
      "2. **Code Construction**  \n",
      "   The tool synthesizes a self‑contained script, often in Python, that:\n",
      "   - Implements the required functionality (e.g., extracting subtitles from a YouTube 360 VR video).  \n",
      "   - Uses any discovered libraries (e.g., `youtube-transcript-api`).  \n",
      "3. **Environment Setup**  \n",
      "   The script includes instructions for creating a Conda environment:\n",
      "   ```bash\n",
      "   conda create -n youtube_transcript\n",
      "   conda activate youtube_transcript\n",
      "   pip install youtube-transcript-api\n",
      "   ```\n",
      "4. **Self‑Containment**  \n",
      "   All dependencies are declared, and hardcoded paths are avoided to ensure portability.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Code Execution & Validation (CodeRunningTool)\n",
      "\n",
      "1. **Isolated Execution**  \n",
      "   The generated script runs in a sandboxed Conda environment to prevent side effects.  \n",
      "2. **Output Caching**  \n",
      "   Results (e.g., extracted subtitles) are cached for later analysis.  \n",
      "3. **Error Handling**  \n",
      "   If the script fails, the error is logged and a recovery process is triggered.\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Tool Registration & MCP Creation\n",
      "\n",
      "1. **MCP Packaging**  \n",
      "   Upon successful execution, the script is wrapped into an MCP, standardizing its API and integration points.  \n",
      "2. **Environment Integration**  \n",
      "   The Conda environment configuration is stored alongside the MCP to guarantee reproducibility.  \n",
      "3. **Registry Update**  \n",
      "   The new MCP is added to the agent’s internal tool registry, making it available for future tasks.\n",
      "\n",
      "---\n",
      "\n",
      "## 7. Iterative Refinement & Recovery\n",
      "\n",
      "1. **Failure Analysis**  \n",
      "   The CodeRunningTool identifies root causes (syntax errors, missing dependencies, logic flaws).  \n",
      "2. **Fallback Strategies**  \n",
      "   The Manager Agent may:\n",
      "   - Relax dependency constraints.  \n",
      "   - Simplify the script logic.  \n",
      "   - Adjust environment specifications.  \n",
      "2. **Retry Execution**  \n",
      "   After applying fixes, the script is re‑executed. Persistent failures result in discarding the tool and logging the incident for offline improvement.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Environment Management\n",
      "\n",
      "1. **Metadata Parsing**  \n",
      "   The `TextInspectorTool` extracts dependency information from repository metadata (`requirements.txt`, `README.md`).  \n",
      "2. **Parallel Initialization**  \n",
      "   Conda environments are created locally in parallel, eliminating the need for administrative privileges or containerization.  \n",
      "3. **Portability**  \n",
      "   Each environment is uniquely named (e.g., derived from a task ID or repository hash) to maintain isolation.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Final Output & Task Completion\n",
      "\n",
      "1. **Tool Utilization**  \n",
      "   The newly registered MCP is invoked to perform the original task.  \n",
      "2. **Result Verification**  \n",
      "   The output is verified against expected results (e.g., confirming that the extracted subtitle “100000000” matches the scene’s content).  \n",
      "3. **Feedback Loop**  \n",
      "   Intermediate results are aggregated, and the final output is returned to the user, completing the task.\n",
      "\n",
      "---\n",
      "\n",
      "## 9. Key Takeaways\n",
      "\n",
      "- **Autonomy** – Alita can generate tools on demand without pre‑defined toolkits.  \n",
      "- **Scalability** – The modular workflow allows continuous expansion of capabilities.  \n",
      "- **Reusability** – Tools are encapsulated as MCPs, enabling reuse across similar tasks.  \n",
      "- **Robustness** – Iterative refinement ensures that even initial failures are handled gracefully.\n",
      "\n",
      "This self‑evolving tool creation pipeline embodies Alita’s core philosophy: minimal pre‑definition coupled with maximal autonomous growth, allowing the framework to adapt to any novel task it encounters.\n"
     ]
    }
   ],
   "source": [
    "response = \"\"\n",
    "\n",
    "async for chunk in agent.astream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"How does Alita enable agents to create and deploy MCP tools if the agent deems that the tool does not exist?\"}\n",
    "        ]\n",
    "    },\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    if \"messages\" in chunk:\n",
    "        chunk['messages'][-1].pretty_print()\n",
    "        \n",
    "response += chunk['messages'][-1].content\n",
    "splits = response.split(\"\\n\")\n",
    "\n",
    "with open(\"../reports/multi_agent_report.txt\", \"w\") as f:\n",
    "    for split in splits:\n",
    "        f.write(split + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e384a",
   "metadata": {},
   "source": [
    "### LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a67d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ResultCard(BaseModel):\n",
    "    score: float = Field(..., description=\"Score from 1-10 where 10 is the highest possible score.\")\n",
    "    reason_for_score: str = Field(..., description=\"The reason that this score was given. Share why the result didn't score 10, or what went well and didn't.\")\n",
    "    \n",
    "reports = os.listdir(\"../reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c662b481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7974aee1d8b54e25a3fc21883e64e729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# model_with_structure = model.with_structured_output(ResultCard)\n",
    "model_with_tools = model.bind_tools([ResultCard])\n",
    "requirements = baseline_instructions\n",
    "res = defaultdict(dict)\n",
    "query = \"How does Alita enable agents to create and deploy MCP tools if the agent deems that the tool does not exist?\"\n",
    "\n",
    "for report in tqdm(reports):\n",
    "    report_name=report.split(\".txt\")[0]\n",
    "    with open(os.path.join(\"../reports\", report), \"r\") as file:\n",
    "        text = file.read()\n",
    "        result = model_with_tools.invoke(\n",
    "            f\"\"\"\n",
    "            You are a teacher grading 3 reports.\n",
    "            \n",
    "            This is the report's focus: {query}\n",
    "            \n",
    "            These are the requirements for the report: {requirements}\n",
    "            \n",
    "            This is the final report: {text}\n",
    "            \n",
    "            Grade the final report on a score of 1-10 and give reasons for your score. Your score should\n",
    "            include the report's structure, the report's depth and how well the report is written.\n",
    "            Be critical but fair. Share why the result didn't score 10, or what went well and didn't.\n",
    "            \n",
    "            Use the tool to return the final result.\n",
    "            \"\"\"\n",
    "        )\n",
    "        # res[report_name] = result\n",
    "        res['score'][report_name] = result.tool_calls[-1]['args']['score']\n",
    "        res['reason'][report_name] = result.tool_calls[-1]['args']['reason_for_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d88e6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d27e89ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>single_deep_agent_report</th>\n",
       "      <td>9</td>\n",
       "      <td>The report is well‑structured with clear headi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_agent_report</th>\n",
       "      <td>8</td>\n",
       "      <td>The report is well‑structured with clear headi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>react_report</th>\n",
       "      <td>8</td>\n",
       "      <td>The report is well‑structured with a clear tit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          score  \\\n",
       "single_deep_agent_report      9   \n",
       "multi_agent_report            8   \n",
       "react_report                  8   \n",
       "\n",
       "                                                                     reason  \n",
       "single_deep_agent_report  The report is well‑structured with clear headi...  \n",
       "multi_agent_report        The report is well‑structured with clear headi...  \n",
       "react_report              The report is well‑structured with a clear tit...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a6b8845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The report is well‑structured with clear headings and bullet points, and it covers all key stages of Alita’s on‑demand MCP tool creation pipeline: gap detection, code synthesis, sandboxed validation, environment isolation, and registration in the MCP Box. It provides concrete examples (e.g., subtitle extraction) and empirical results that demonstrate effectiveness. The language is concise, professional, and free of self‑referential remarks, meeting the brief’s requirements. Minor improvements could include a slightly deeper explanation of the criteria used by the MCP Brainstorming component to flag a missing tool and a brief mention of how the agent handles failures beyond simple refinement. These small gaps prevent a perfect score, but the report is otherwise comprehensive and well‑written."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(df['reason'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aee4efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The report is well‑structured with clear headings and a logical flow from problem definition to tool creation and validation. It covers all required phases—gap detection, resource search, script generation, execution, packaging, and refinement—providing concrete examples and code snippets. The language is concise yet thorough, and the use of bullet points and code blocks enhances readability. However, it lacks a brief introduction and conclusion, which would frame the context and summarize key takeaways. Additionally, while the report references specific tools (e.g., GoogleSearchTool, GithubSearchTool), it does not cite sources or provide links to documentation, limiting verifiability. The depth is appropriate for a technical audience, but some sections could benefit from more detailed error‑handling scenarios and performance considerations. Overall, the report meets the brief but falls short of a perfect score due to minor omissions and lack of source citations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(df['reason'].iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ff09455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The report is well‑structured with a clear title and numbered sections that cover the entire lifecycle of tool creation in Alita. It demonstrates depth by discussing brainstorming, script generation, validation, environment management, integration, scalability, empirical results, and limitations. The writing is professional, concise, and free of self‑reference, meeting the style guidelines. However, it falls short of a perfect score because it lacks explicit citations or references to the Alita and MCP Zero documentation, does not fully elaborate on the decision‑making process when a tool is deemed nonexistent, and could benefit from more concrete examples or code snippets. Additionally, the use of bullet points is minimal, and some sections could be broken into subsections for greater clarity. These omissions prevent it from achieving a 10/10."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(df['reason'].iloc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddaa0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-agents-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
