{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0dbdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c9c6b",
   "metadata": {},
   "source": [
    "## Ingesting documents into Llama Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54286449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
    "\n",
    "LLAMA_CLOUD_API_KEY = os.environ['LLAMA_CLOUD_API_KEY']\n",
    "\n",
    "kwargs = {\n",
    "    'dense_similarity_top_k': 10,\n",
    "    'sparse_similarity_top_k': 20,\n",
    "    'enable_reranking': True,\n",
    "    'alpha': 0.5,\n",
    "    'rerank_top_n': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798f4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='52b51eed-96c4-4511-aec5-0bbc03fbac4d', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 1, 'start_page_index': 0, 'start_page_label': 1, 'end_page_index': 0, 'end_page_label': 1, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 1, 'end_char_idx': 2707}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84'}, hash='bbcdcd86b4c0e95a360e2602e6c6dda97f54a45b1da78c3bc12dfa390163a621')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# ALITA: GENERALIST AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL SELF-EVOLUTION\\n\\nJiahao Qiu*¹, Xuan Qi*², Tongcheng Zhang*³, Xinzhe Juan³⁴, Jiacheng Guo¹, Yifu Lu¹, Yimin Wang³⁴, Zixin Yao¹,  \\nQihan Ren³, Xun Jiang⁵, Xing Zhou⁵, Dongrui Liu³, Ling Yang¹, Yue Wu¹, Kaixuan Huang¹, Shilong Liu¹,  \\nHongru Wang⁶, Mengdi Wang¹\\n\\n¹ AI Lab, Princeton University  \\n² IIIS, Tsinghua University  \\n³ Shanghai Jiao Tong University  \\n⁴ University of Michigan  \\n⁵ Tianqiao and Chrissy Chen Institute  \\n⁶ The Chinese University of Hong Kong\\n\\n<table>\\n<thead>\\n<tr>\\n<th colspan=\"4\">GAIA Benchmark</th>\\n</tr>\\n<tr>\\n<th></th>\\n<th>Alita</th>\\n<th>manus.ai</th>\\n<th>OpenAI DeepResearch</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Level 1</td>\\n<td>88.7%</td>\\n<td>86.5%</td>\\n<td>74.3%</td>\\n</tr>\\n<tr>\\n<td>Level 2</td>\\n<td>89.5%</td>\\n<td>70.1%</td>\\n<td>69.1%</td>\\n</tr>\\n<tr>\\n<td>Level 3</td>\\n<td>76.9%</td>\\n<td>57.7%</td>\\n<td>47.6%</td>\\n</tr>\\n<tr>\\n<td>Average</td>\\n<td>87.3%</td>\\n<td>73.3%</td>\\n<td>67.4%</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n> Figure 1: Performance of Alita, manus.ai, and OpenAI DeepResearch[1]\\n\\n## ABSTRACT\\n\\nRecent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce **Alita**—a generalist agent designed with the principle of *\"Simplicity is the ultimate sophistication,\"* enabling scalable agentic reasoning through **minimal predefinition** and **maximal self-evolution**. \\n\\nFor minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. \\n\\nFor *Maximal self-evolution*, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. \\n\\nNotably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at https://github.com/CharlesQ9/Alita.\\n\\n\\\\* These authors contributed equally to this work.', mimetype='text/plain', start_char_idx=1, end_char_idx=2708, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.838376),\n",
       " NodeWithScore(node=TextNode(id_='302d113a-111a-42d1-b53e-c52a34d136ef', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 4, 'start_page_index': 3, 'start_page_label': 4, 'end_page_index': 3, 'end_page_label': 4, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 25705, 'end_char_idx': 30324}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84'}, hash='bbcdcd86b4c0e95a360e2602e6c6dda97f54a45b1da78c3bc12dfa390163a621'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3eaabf58-d3ba-4ba6-b8fc-1b8eda20c274', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 3}, hash='47774dc9bf72b6fadb754058cdb1739b6150fa052eefce60a883841005a4c23d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# 3 Methods\\n\\nWe propose Alita, a generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal self-evolution to tackle diverse and complex tasks. Figure 3 illustrates the framework of Alita. In contrast to generalist agents that typically depend on extensive manually-designed tools and workflows [8, 9], the manager agent in Alita solely orchestrates the web agent using only basic tools. Through this approach, our framework enables Alita to plan task-specific tools through brainstorming. It then utilizes a Web Agent to search for helpful open-source libraries and other resources related to these tools. Leveraging the search results, Alita autonomously generates new tools and configures the necessary environments to enhance its capabilities and effectively solve tasks. During this process, if any issues arise with the newly generated tools or their environments, Alita can provide feedback and self-correct, improving the quality of the generated tools. Furthermore, the new tools can be encapsulated as MCP servers for future reuse. With the aid of MCPs, Alita can generate increasingly powerful, diverse, and complex MCPs, thus establishing a self-reinforcing cycle. Therefore, Alita autonomously expands its capabilities through continuous MCP integration.\\n\\n<table>\\n<thead>\\n<tr>\\n<th colspan=\"9\" style=\"text-align:center;\">Question</th>\\n<th colspan=\"3\" style=\"text-align:center;\"><b>CodeReAct Loop</b></th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td colspan=\"2\" rowspan=\"3\" style=\"text-align:center;\">Web Agent</td>\\n<td colspan=\"3\" rowspan=\"3\" style=\"text-align:center;\">Manager Agent</td>\\n<td colspan=\"2\" style=\"text-align:center; border: 1px solid black; background-color: #d9b3ff;\">MCP Brainstorming</td>\\n<td colspan=\"3\" rowspan=\"2\" style=\"text-align:center; border: 1px solid black; background-color: #ffdb99;\">\\n<ul>\\n<li>Open-source Searching</li>\\n<li>Script Generating</li>\\n<li>Virtual Env Execution</li>\\n</ul>\\n</td>\\n<td rowspan=\"3\" style=\"text-align:center;\">MCP Box</td>\\n</tr>\\n<tr>\\n<td colspan=\"2\" style=\"text-align:center; border: 1px solid black; background-color: #d9b3ff;\">MCP Creation</td>\\n</tr>\\n<tr>\\n<td colspan=\"2\" style=\"text-align:center;\">Encapsulate</td>\\n</tr>\\n<tr>\\n<td colspan=\"8\" style=\"text-align:center; border: 1px solid black; background-color: #c2c2d6;\">Self Evolving</td>\\n<td colspan=\"3\" style=\"text-align:center;\">Output</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n**Figure 3:** The architecture of Alita. Upon receiving a question, the Manager Agent initiates an iterative CodeReAct loop to analyze tasks, identify functional gaps, and trigger MCP Brainstorming for creative synthesis. The system dynamically performs open-source searching, script generation, and virtual environment execution to construct task-related functions. Useful ones are encapsulated into reusable MCPs and stored in the MCP Box. Throughout this process, the Manager Agent collaborates with the Web Agent for external information retrieval and continuously integrates intermediate results until a final output is produced. This process enables Alita to self-evolve without relying on a huge hand-crafted, elaborate tools and workflows.\\n\\n## 3.1 Execution Pipeline\\n\\nEach task commences with the construction of an augmented prompt that incorporates the original query. The manager agent (Sec. 3.2) then initiates a multi-step reasoning process to address the task at hand. Throughout this process, the agent may query external sources via the web agent (Sec. 3.3), plan and synthesize new tools (Sec. 3.4), and execute them within isolated environments (Sec. 3.4.4).\\n\\nUpon successful tool generation and accurate result formulation, the corresponding script is transformed into an MCP and stored in the internal tool registry for future reuse. All reasoning steps, intermediate code, and final outputs are systematically logged to facilitate comprehensive analysis.\\n\\n## 3.2 Manager Agent\\n\\nThe Manager Agent functions as the central coordinator within framework of Alita. When receiving a task prompt, the manager agent initially calls the MCP Brainstorming to determine whether additional tools are needed and which specific tools are required. Then the manager agent decomposes the task into subtasks and dispatches them to web agent or generates the required external tools to complete the subtask. When necessary, the manager agent utilizes the information retrieved by the web agent to generate the required new tools along with their corresponding environment configuration instructions. After collecting all intermediate results, the manager performs final aggregation and response formulation.', mimetype='text/plain', start_char_idx=1, end_char_idx=4621, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7409441),\n",
       " NodeWithScore(node=TextNode(id_='20428334-8600-4dc7-a625-cbb3c353ea37', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 2, 'start_page_index': 1, 'start_page_label': 2, 'end_page_index': 1, 'end_page_label': 2, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 5429, 'end_char_idx': 10941}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84'}, hash='bbcdcd86b4c0e95a360e2602e6c6dda97f54a45b1da78c3bc12dfa390163a621'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='52b51eed-96c4-4511-aec5-0bbc03fbac4d', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 1}, hash='64b5eb9fcb78ede5560a319b923bfa4a3a0f15d0b4ccb20bf9d824ff616e6763')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# 1 Introduction\\n\\n> \"Simplicity is the ultimate sophistication.\"  \\n> — Leonardo da Vinci\\n\\nLarge language models (LLMs) have rapidly evolved from merely generating text to autonomous agents capable of independently planning and executing complex tasks on behalf of users with limited human oversight [2]. These capabilities have enabled a wide range of applications, ranging from travel planning [3], computer use [4, 5, 6], to the multi-step research tasks [7]. To support such diverse and demanding tasks, a new class of systems called generalist agents has emerged. These agents are designed to handle a wide range of domains and tasks through a unified architecture, allowing them to generalize beyond task-specific solutions, such as OpenAI Deep Research [1] and Manus.\\n\\nHowever, most of the current general-purpose agents heavily rely on large-scale manual engineering, including tediously designed workflows, considerable pre-defined tools, and hardcoded components [8, 9]. This reliance introduces several critical limitations:  \\ni) It is impractical, if not impossible, to predefine all the tools required for the wide variety of real-world tasks an agent might encounter (*incomplete coverage*);  \\nii) Many complex tasks require agents to creatively compose new tools or leverage existing ones in novel ways while pre-designed workflow and hardcoded components constrain this compositional flexibility and inhibit the development of adaptive behaviors (*limited creativity and flexibility*);  \\niii) It is not always the case that the interface or environment of different tools are compatible with the agent (*mismatch*). For example, many useful tools are not written in Python, which makes it difficult, though not entirely impossible, for them to be pre-connected to the mainstream agent frameworks that are primarily written in Python. Together, these challenges ultimately hinder the scalability, adaptability, and generalization of existing generalist agents.\\n\\nIn contrast to the prevailing trend of growing complexity, we propose a radically simple design philosophy built on two principles:  \\ni) *Minimal Predefinition*: Equip the agent with only a minimal set of core capabilities, avoiding manually engineered components for specific tasks or modalities;  \\nii) *Maximal Self-Evolution*: Empower the agent to autonomously create, refine, and reuse external capabilities as needed. We instantiate this vision through Alita, a generalist agent built with a single core capability (i.e., the web agent) and a small set of general-purpose modules that enable self-directed capability expansion. Specifically, we take advantage of the Model Context Protocols (MCPs) [1] which is an open protocol that standardizes how different systems provide context to LLMs, and empower Alita to dynamically generate, adapt, and reuse MCPs based on the demands of each task rather than relying on static, predefined tools. This shift from manually designed capabilities to on-the-fly MCP construction unlocks a new path for building agents that are simple yet profoundly capable.\\n\\n<table>\\n<thead>\\n<tr>\\n  <th colspan=\"6\">Traditional Generalist Agents</th>\\n  <th></th>\\n  <th colspan=\"3\">Large-scale Manual Engineering</th>\\n  <th></th>\\n  <th colspan=\"3\">Alita (Ours)</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n  <td>Url Text Extractor</td>\\n  <td>URL TEXT</td>\\n  <td>Image Captioner</td>\\n  <td>Relevant Patch Zoomer</td>\\n  <td>Other Agents</td>\\n  <td>Youtube Caption Crawler</td>\\n  <td></td>\\n  <td>Incomplete Coverage</td>\\n  <td>Limited Creativity & Flexibility</td>\\n  <td>Mismatch</td>\\n  <td></td>\\n  <td>Web Agent</td>\\n  <td>Manager Agent</td>\\n  <td>MCP Creation</td>\\n</tr>\\n<tr>\\n  <td>Web Agent</td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td>Self Evolving</td>\\n  <td>MCP Box</td>\\n</tr>\\n<tr>\\n  <td>Path Generalist Classifier</td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td>Manager Agent</td>\\n  <td></td>\\n  <td></td>\\n  <td>Minimal Predefinition</td>\\n  <td></td>\\n  <td>Maximal Self-Evolution</td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n</tr>\\n<tr>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td>SELF-EVOLUTION</td>\\n  <td></td>\\n</tr>\\n<tr>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td>Scalable Dynamic Capability</td>\\n  <td>Enhanced Creativity & Flexibility</td>\\n  <td colspan=\"2\">Cross-ecosystem Compatibility</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n**Figure 2:** Comparison between Traditional Generalist Agents and Alita. Traditional generalist agents heavily rely on large-scale manual engineering while Alita adheres to minimal predefinition and maximal self-evolution.\\n\\nWe conduct comprehensive experiments on several benchmarks to assess Alita in real-world applications, especially on the most popular GAIA [10]. Alita proves that simplicity is not a constraint, but a strength, and that creative agent behavior can emerge from a design that prioritizes autonomy over manual engineering. To sum up, our key contributions can be summarized as follows.\\n\\n* We propose a new agent architecture centered on minimal predefinition and maximal self-evolution, challenging conventional design norms in generalist agents, aiming to call for a more scalable and generalizable agent framework.\\n\\n----\\n\\n[1]: https://www.anthropic.com/news/model-context-protocol', mimetype='text/plain', start_char_idx=1, end_char_idx=5514, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.734139),\n",
       " NodeWithScore(node=TextNode(id_='3eaabf58-d3ba-4ba6-b8fc-1b8eda20c274', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 3, 'start_page_index': 2, 'start_page_label': 3, 'end_page_index': 2, 'end_page_label': 3, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 16469, 'end_char_idx': 21079}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84'}, hash='bbcdcd86b4c0e95a360e2602e6c6dda97f54a45b1da78c3bc12dfa390163a621'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20428334-8600-4dc7-a625-cbb3c353ea37', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 2}, hash='e7657b24c0907aa73748817a618a21a53132bb1fb519fbb4248412ee25d2c46d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* We present Alita, a generalist agent that achieves scalable agentic reasoning with a radically simple design.  \\n* We empirically demonstrate that Alita, despite using no complex predefined tools and workflows for specific tasks, outperforms many systems with significantly more handcrafted complexity on the GAIA benchmark. We achieve 75.15% pass@1 and 87.27% pass@3, surpassing OpenAI’s Deep Research with 67.36% pass@1 and ranking top among all general-purpose agents.\\n\\n## 2 Related Works\\n\\n### 2.1 Generalist Agent\\n\\nThe concept of a Generalist Agent aims to construct an AI agent system capable of collaboratively completing a variety of complex tasks in a real-world environment. OWL [8] introduces a method that decomposes complex tasks into subtasks and dynamically allocates them to worker nodes with specialized toolkits. Omne [11] proposes a multi-agent collaborative development framework, where each agent possesses an independent system structure, enabling autonomous learning and the storage of a comprehensive world model to build an independent understanding of the environment. OpenAI Deep Research[^2] employs reinforcement learning for training on real-world tasks, aiming to provide precise and reliable research reports for knowledge-intensive tasks. A-World [12] offers a highly configurable, modular, and scalable simulation environment, allowing developers to flexibly define and integrate different types of AI agents. The Magentic-One [13] framework merges the Magentic and Autogen systems, distinguishing between the micro-level LLM-driven function generation and the macro-level multi-agent orchestration, resulting in a clearer and more efficient construction of agent systems. Alita, also a Generalist Agent, allows for the minimal use of predefined tools and workflows for direct problem-solving, yet still achieves impressive performance across diverse tasks.\\n\\n### 2.2 Auto Generating Agent\\n\\nAuto-generating agents aim to enhance the versatility of agents by enabling them to autonomously generate tools, agents, or workflows tailored to specific tasks. AutoAgents [14], for instance, generate multiple agents, each playing a distinct role, to handle the corresponding subtasks. OpenHands [15] offers an event-driven architecture that allows agents to interact with the environment like human developers, thereby enabling the creation of custom workflows. AFlow [16] redefines workflow optimization as a search problem, where each workflow consists of several nodes invoking large LLMs, and the optimal workflow is identified and executed through a search process. AutoAgent [17], as an autonomous agent operating system, permits agents to manage system-level operations and file data autonomously. In Alita, agents are empowered to automatically generate diverse, specialized, and highly accurate MCPs to aid in the completion of specific tasks, while also providing resources for future executions.\\n\\n### 2.3 Tool Creation\\n\\nTool Creation enables agents to autonomously create tools to assist in task execution, either on their own or with external support. CRAFT [18] utilizes GPT-4 to generate a set of code snippets that function as tools, which are then retrieved and used in the system. TroVE [19] maintains a collection of high-level functions, which are automatically generated, extended, and periodically pruned to optimize program generation. CREATOR [20] decouples the abstraction of tool creation from the actual execution, allowing LLMs to address tasks at different levels of granularity. AutoAgent [17] enables agents to autonomously create new tools based on task requirements, incorporating information gathered through web searches and integrating these tools into their workflow. OpenHands [15] allows agents to create code scripts in a human-like manner during interaction with the environment to assist in task completion. In comparison, Alita enables MCP creation, which provides additional benefits, including better reusability and easy environment management over tool creation.\\n\\n### 2.4 MCP\\n\\nThe Model Context Protocol (MCP) is a standard proposed by Anthropic, designed to unify the connection between AI systems and external data sources and services. RAG-MCP [21] enhances the efficiency and accuracy of agents by retrieving the most relevant tools from a large collection, based on the task description, within the database composed of MCP descriptions. After tool generation, Alita wraps the generated valid tools into MCPs for subsequent use, facilitating reuse by itself and other agents.\\n\\n[^2]: https://openai.com/index/introducing-deep-research/', mimetype='text/plain', start_char_idx=1, end_char_idx=4612, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.72698855),\n",
       " NodeWithScore(node=TextNode(id_='b66cc474-c072-4f2a-9dff-d4c9c99bbb30', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 9, 'start_page_index': 8, 'start_page_label': 9, 'end_page_index': 8, 'end_page_label': 9, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 70728, 'end_char_idx': 72433}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84'}, hash='bbcdcd86b4c0e95a360e2602e6c6dda97f54a45b1da78c3bc12dfa390163a621'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='74e3de3d-0ea9-4cbe-ae9f-2086cebd1062', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 8}, hash='fa73f1fb1e7babe2c275d407a08b22e8e31e3184b663b5746ccaf2153ddbe03a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='<table>\\n<thead>\\n<tr>\\n<th>Model Configuration</th>\\n<th>Level 1</th>\\n<th>Level 2</th>\\n<th>Level 3</th>\\n<th>Total</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Alita (Claude-3.7-Sonnet, GPT-4o)</td>\\n<td>81.13%</td>\\n<td>75.58%</td>\\n<td>46.15%</td>\\n<td><b>72.73%</b></td>\\n</tr>\\n<tr>\\n<td>Alita (GPT-4o-mini)</td>\\n<td>54.72%</td>\\n<td>44.19%</td>\\n<td>19.23%</td>\\n<td>43.64%</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nTable 4: Comparison of performance between Alita(Claude-3.7-Sonnet,GPT-4o) and Alita(GPT-4o-mini). The results are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the performance at the respective GAIA levels. The integration of a smaller model significantly reduces the performance.\\n\\n### 5.3 Case Study\\n\\nTo investigate Alita’s workflow when tackling tasks, we conducted a case study on its approach to solving a Level 3 difficult problem in GAIA. The details of this process are presented in Appendix A. From the case study, we observe that Alita is able to perform a structured MCP brainstorming session based on the task at hand, effectively identifying and utilizing relevant resources to implement a feasible MCP that aids in completing the task.\\n\\n### 6 Conclusion\\n\\nIn this work, we introduced **Alita**, a generalist agent designed with the principles of minimal predefinition and maximal self-evolution. By significantly reducing reliance on manually predefined tools and workflows for direct solving, Alita leverages creative, autonomous capabilities in real time, facilitating scalable agentic reasoning. Our approach demonstrates that simplicity in design does not undermine, but rather enhances, the performance and adaptability of generalist agents.', mimetype='text/plain', start_char_idx=2, end_char_idx=1708, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6625569),\n",
       " NodeWithScore(node=TextNode(id_='876e1445-8cc9-4d70-b89a-a24f16b39528', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 12, 'start_page_index': 11, 'start_page_label': 12, 'end_page_index': 11, 'end_page_label': 12, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 85449, 'end_char_idx': 88334}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84'}, hash='bbcdcd86b4c0e95a360e2602e6c6dda97f54a45b1da78c3bc12dfa390163a621'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2f0b06d9-e6d5-487a-b453-8a9d9a501a2e', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 11}, hash='4582f40015c8305c938991843a37e0c8f26ca9ee91e89d31f8ab21e8c90adcea')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# A Detailed Case Study\\n\\n> **Case Study:** YouTube 360 VR Video Subtitle Extraction\\n\\n| **Question ID:** | 0512426f-4d28-49f0-be77-06d05daec096 |\\n|------------------|---------------------------------------|\\n| **Question:**    | In the YouTube 360 VR video from March 2018 narrated by the voice actor of Lord of the Rings’ Gollum, what number was mentioned by the narrator directly after dinosaurs were first shown in the video? |\\n| **Our Answer:**  | 100000000                             |\\n| **Correct Answer:** | 100000000                          |\\n| **Is Correct:**  | Yes                                  |\\n| **Generated MCP:** | YouTube Video Subtitle Crawler     |\\n\\n### Alita Workflow:\\n\\n1. **MCP Brainstorming:**  \\n   Alita propose the development of a \"YouTube Video Subtitle Crawler\" MCP, which should automate the extraction of subtitles from a given YouTube video. This involves scraping the subtitles of the video and processing them to isolate the relevant text after the event in question.\\n\\n2. **Web Agent Execution:**  \\n   To implement the subtitle extraction, a search is conducted in open-source repositories to find relevant tools that can assist in extracting YouTube video transcripts. An appropriate tool, the youtube-transcript-api, is identified from the following GitHub repository:  \\n   `https://github.com/jdepoix/youtube-transcript-api`\\n\\n3. **Manager Agent:**  \\n   The Manager Agent synthesizes the information from the GitHub repository and proceeds to write a Python function that leverages the youtube-transcript-api to retrieve the transcript of the video with corresponding environment setup instructions.  \\n   The environment setup and installation steps are defined as follows:\\n\\n   ```bash\\n   conda create -n youtube_transcript\\n   conda activate youtube_transcript\\n   pip install youtube-transcript-api\\n   ```\\n\\n   The Python code to retrieve the video transcript is as follows:\\n\\n   ```python\\n   from youtube_transcript_api import YouTubeTranscriptApi\\n   # Initialize the API\\n   ytt_api = YouTubeTranscriptApi()\\n   # Retrieve the transcript\\n   video_id = ...\\n   transcript_list = ytt_api.list(\\'video_id\\')\\n   ...\\n   ```\\n\\n4. **Manager Agent Execution:**  \\n   Leveraging the Python code and the established environment, the Manager Agent successfully packaged the YouTube Video Subtitle Crawler MCP. Subsequently, this MCP was employed to efficiently scrape the subtitles from the video, enabling the extraction of the relevant content. After analyzing the content, the correct number (100000000) mentioned by the narrator following the dinosaur scene is extracted from the transcript.\\n\\n5. **Final Output:**  \\n   The number \"100000000\" is identified as the correct answer.\\n\\n# B Limitations\\n\\nAlita highly relies on the coding capability of LLM. When the LLM’s coding capability is really poor, our method will perform worse than traditional generalist agent.', mimetype='text/plain', start_char_idx=1, end_char_idx=2887, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6158511),\n",
       " NodeWithScore(node=TextNode(id_='f2c12fef-2e3a-47f4-a932-96022c112d72', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 10, 'start_page_index': 9, 'start_page_label': 10, 'end_page_index': 9, 'end_page_label': 10, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 74155, 'end_char_idx': 78791}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84'}, hash='bbcdcd86b4c0e95a360e2602e6c6dda97f54a45b1da78c3bc12dfa390163a621'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b66cc474-c072-4f2a-9dff-d4c9c99bbb30', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 9}, hash='e39434cd63d5e30022e91de73a66843e9837c7d884b6b6dc59847d8f0c71e84c')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# References\\n\\n[1] OpenAI. Introducing deep research.  \\n[2] Noam Kolt. Governing ai agents. *arXiv preprint arXiv:2501.07913*, 2025.  \\n[3] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, and Yu Su. Travelplanner: A benchmark for real-world planning with language agents. *arXiv preprint arXiv:2402.01622*, 2024.  \\n[4] Tianbao Xie, Danyang Zhang, Jixuan Chen, Xiaochuan Li, Siheng Zhao, Ruisheng Cao, Toh J Hua, Zhoujun Cheng, Dongchan Shin, Fangyu Lei, et al. Osworld: Benchmarking multimodal agents for open-ended tasks in real computer environments. *Advances in Neural Information Processing Systems*, 37:52040–52094, 2024.  \\n[5] Hongru Wang, Rui Wang, Boyang Xue, Heming Xia, Jingtao Cao, Zeming Liu, Jeff Z. Pan, and Kam-Fai Wong. AppBench: Planning of multiple APIs from various APPs for complex user instruction. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, editors, *Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing*, pages 15322–15336, Miami, Florida, USA, November 2024. Association for Computational Linguistics.  \\n[6] Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin Li, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli Ma, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao Wang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, and Guang Shi. Ui-tars: Pioneering automated gui interaction with native agents, 2025.  \\n[7] Junde Wu, Jiayuan Zhu, and Yuyuan Liu. Agentic reasoning: Reasoning llms with tools for the deep research. *arXiv preprint arXiv:2502.04644*, 2025.  \\n[8] Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru Li, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Ping Luo, and Guohao Li. Owl: Optimized workforce learning for general multi-agent assistance in real-world task automation, 2025.  \\n[9] Pan Lu, Bowen Chen, Sheng Liu, Rahul Thapa, Joseph Boen, and James Zou. Octotools: An agentic framework with extensible tools for complex reasoning. *arXiv preprint arXiv:2502.11271*, 2025.  \\n[10] Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a benchmark for general ai assistants. In *The Twelfth International Conference on Learning Representations*, 2023.  \\n[11] Xun Jiang, Feng Li, Han Zhao, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize Chen, et al. Long term memory: The foundation of ai self-evolution. *arXiv preprint arXiv:2410.15665*, 2024.  \\n[12] Agent Team at Ant Group. Aworld: A unified agent playground for computer and phone use tasks, 2025.  \\n[13] Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang, Zhu, Friederike Niedtner, Grace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor Dibia, Ahmed Awadallah, Ece Kamar, Rafah Hosn, and Saleema Amershi. Magentic-one: A generalist multi-agent system for solving complex tasks, 2024.  \\n[14] Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, Börje F Karlsson, Jie Fu, and Yemin Shi. Autoagents: A framework for automatic agent generation. *arXiv preprint arXiv:2309.17288*, 2023.  \\n[15] Xingyao Wang, Boxuan Li, Yufan Song, Frank F Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, et al. Openhands: An open platform for ai software developers as generalist agents. In *The Thirteenth International Conference on Learning Representations*, 2024.  \\n[16] Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, et al. Aflow: Automating agentic workflow generation. *arXiv preprint arXiv:2410.10762*, 2024.  \\n[17] Jiabin Tang, Tianyu Fan, and Chao Huang. Autoagent: A fully-automated and zero-code framework for llm agents. *arXiv e-prints*, pages arXiv–2502, 2025.  \\n[18] Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R Fung, Hao Peng, and Heng Ji. Craft: Customizing llms by creating and retrieving from specialized toolsets. *arXiv preprint arXiv:2309.17428*, 2023.  \\n[19] Zhiruo Wang, Daniel Fried, and Graham Neubig. Trove: Inducing verifiable and efficient toolboxes for solving programmatic tasks. *arXiv preprint arXiv:2401.12869*, 2024.  \\n[20] Cheng Qian, Chi Han, Yi R Fung, Yujia Qin, Zhiyuan Liu, and Heng Ji. Creator: Tool creation for disentangling abstract and concrete reasoning of large language models. *arXiv preprint arXiv:2305.14318*, 2023.', mimetype='text/plain', start_char_idx=1, end_char_idx=4638, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.61251885),\n",
       " NodeWithScore(node=TextNode(id_='c1cd3d80-9dcf-46c0-a9e1-118bcea0a0d6', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 7, 'start_page_index': 6, 'start_page_label': 7, 'end_page_index': 6, 'end_page_label': 7, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 52629, 'end_char_idx': 56803}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84'}, hash='bbcdcd86b4c0e95a360e2602e6c6dda97f54a45b1da78c3bc12dfa390163a621'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='39614102-905d-4b8f-87c2-dbbfe049aba4', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 6}, hash='07a6de4aba54d6d1082453a4efd63c4dac48aec015dc0c9d4ddd89d20010da6b')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='framework excels in generating comprehensive reports on complex topics and has shown superior performance on benchmarks.\\n\\n## 4.2 Results\\n\\nWe run three rounds of testing on GAIA and achieved the best performance on the GAIA leaderboard, surpassing other agent systems. Alita with Claude-Sonnet-4 and GPT-4o achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking on the GAIA benchmark validation dataset, outperforming many agent systems with far greater complexity. Alita with Claude 3.7 Sonnet + GPT-4o achieves 72.73% pass@1 and 86.06% pass@3 on GAIA, and further attains 74.00% and 52.00% pass@1 on the Mathvista and PathVQA benchmarks, respectively, outperforming Octotools and Open Deep Research by smolagents. More detailed results are shown in Table 1.\\n\\n<table>\\n<thead>\\n<tr>\\n<th rowspan=\"2\">Agent</th>\\n<th colspan=\"4\">GAIA</th>\\n<th>Mathvista</th>\\n<th>PathVQA</th>\\n</tr>\\n<tr>\\n<th>level1</th>\\n<th>level2</th>\\n<th>level3</th>\\n<th>total</th>\\n<th></th>\\n<th></th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><i>Alita (Claude-3.7-Sonnet, GPT-4o) (%)</i></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>pass@1</td>\\n<td>81.13</td>\\n<td>75.58</td>\\n<td>46.15</td>\\n<td>72.73</td>\\n<td><b>74</b></td>\\n<td><b>52</b></td>\\n</tr>\\n<tr>\\n<td>pass@2</td>\\n<td>88.68</td>\\n<td>80.23</td>\\n<td>53.85</td>\\n<td>78.79</td>\\n<td>-</td>\\n<td>-</td>\\n</tr>\\n<tr>\\n<td>pass@3</td>\\n<td>96.23</td>\\n<td>86.04</td>\\n<td>65.38</td>\\n<td><b>86.06</b></td>\\n<td>-</td>\\n<td>-</td>\\n</tr>\\n<tr>\\n<td><i>Alita (Claude-Sonnet-4, GPT-4o) (%)</i></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>pass@1</td>\\n<td>77.36</td>\\n<td>76.74</td>\\n<td>65.38</td>\\n<td>75.15</td>\\n<td>-</td>\\n<td>-</td>\\n</tr>\\n<tr>\\n<td>pass@3</td>\\n<td>88.68</td>\\n<td>89.53</td>\\n<td>76.92</td>\\n<td><b>87.27</b></td>\\n<td>-</td>\\n<td>-</td>\\n</tr>\\n<tr>\\n<td><i>Baselines (%)</i></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td>Octotools</td>\\n<td>-</td>\\n<td>-</td>\\n<td>-</td>\\n<td>18.40</td>\\n<td>68</td>\\n<td>47</td>\\n</tr>\\n<tr>\\n<td>ODR-smolagents</td>\\n<td>67.92</td>\\n<td>53.49</td>\\n<td>34.62</td>\\n<td>55.15</td>\\n<td>65</td>\\n<td>42</td>\\n</tr>\\n<tr>\\n<td>AutoAgent</td>\\n<td>71.70</td>\\n<td>53.49</td>\\n<td>26.92</td>\\n<td>55.15</td>\\n<td>-</td>\\n<td>-</td>\\n</tr>\\n<tr>\\n<td>OWL</td>\\n<td>84.91</td>\\n<td>67.44</td>\\n<td>42.31</td>\\n<td>69.09</td>\\n<td>-</td>\\n<td>-</td>\\n</tr>\\n<tr>\\n<td>A-World</td>\\n<td>86.79</td>\\n<td>69.77</td>\\n<td>34.62</td>\\n<td>69.70</td>\\n<td>-</td>\\n<td>-</td>\\n</tr>\\n<tr>\\n<td>OpenAI-DR</td>\\n<td>74.29</td>\\n<td>69.06</td>\\n<td>47.60</td>\\n<td>67.36</td>\\n<td>-</td>\\n<td>-</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nTable 1: Performance comparison of Alita and baseline agent systems on the GAIA, Mathvista, and PathVQA benchmarks. ODR-Smolagents refers to the Open Deep Research agent in the Smolagents framework. OpenAI-DR refers to OpenAI’s Deep Research. The table presents the accuracy at different levels of difficulty for GAIA, as well as the overall performance on Mathvista and PathVQA. The pass@1, pass@2, and pass@3 denote the accuracy achieved by running the Alita framework 1, 2, and 3 times, respectively, and selecting the best answer. Alita outperforms all baseline agents across the GAIA levels, achieving the highest total accuracy.\\n\\n# 5 Analysis\\n\\n## 5.1 Reuse of Alita-Generated MCPs\\n\\n### 5.1.1 Overview\\n\\nWe collect the MCPs generated from running the GAIA dataset using Alita in conjunction with powerful models (Claude-3.7-Sonnet and GPT-4o). The benefits of reusing Alita-generated MCPs are **two-fold**. First, these MCPs can be reused by other agent frameworks and improve their performance since Alita, instead of human developers, designs a set of useful MCPs fit to GAIA by trial and error. Second, these MCPs can be reused by agents with smaller LLMs and **significantly** improve the performance. The reuse of auto-generated MCPs for agents with smaller LLMs can be viewed as a new way of distillation from larger LLMs. Traditionally, distillation might be fine-tuning smaller LLMs on data generated by larger LLMs. In comparison, the reuse of MCPs generated from agents with larger LLMs is much easier, cheaper, and faster than traditional distillation.', mimetype='text/plain', start_char_idx=1, end_char_idx=4176, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.56661874)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alita_index = LlamaCloudIndex(\n",
    "  name=\"alita-paper\",\n",
    "  project_name=\"Default\",\n",
    "  organization_id=\"bf9b425c-54cb-4182-a93f-8ac6aed04348\",\n",
    "  api_key=LLAMA_CLOUD_API_KEY,\n",
    ")\n",
    "alita_retriever = alita_index.as_retriever(**kwargs)\n",
    "alita_retriever.retrieve(\n",
    "    \"What is Alita and how does it work?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc8b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='491b9cbd-4978-4ef1-bf2f-1bf3564e9c13', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 1, 'start_page_index': 0, 'start_page_label': 1, 'end_page_index': 0, 'end_page_label': 1, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 1, 'end_char_idx': 3753}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', node_type='4', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794'}, hash='d8d6705e8da1c0b9ae29887d9045e0e119e7a2b90437b0e5d6ca008157702071')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# MCP-Zero: Active Tool Discovery for Autonomous LLM Agents\\n\\n**Xiang Fei**  \\nxiangf@stu.xmu.edu.cn  \\n\\n**Xiawu Zheng***  \\nzhengxiawu@xmu.edu.cn  \\n\\n**Hao Feng**  \\nhaof@mail.ustc.edu.cn  \\n\\n----\\n\\n<table>\\n<thead>\\n<tr>\\n<th colspan=\"3\">(a) MCP info in system prompt</th>\\n<th colspan=\"4\">(b) Retrieval-augmented tool selection</th>\\n<th>(c) Our method</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>MCPs</td>\\n<td>+</td>\\n<td>LLM</td>\\n<td>MCPs</td>\\n<td>Retriever</td>\\n<td>Query</td>\\n<td>= Tool</td>\\n<td rowspan=\"5\" style=\"vertical-align:top;\">\\n[Image of a bowl of food with chopsticks and a drink]<br><b>Finish!</b>\\n</td>\\n</tr>\\n<tr>\\n<td colspan=\"3\" style=\"text-align:center;\">= LLM (Long Context)</td>\\n<td colspan=\"3\" style=\"text-align:center;\">= Not Enough</td>\\n</tr>\\n<tr>\\n<td colspan=\"2\" style=\"text-align:center;\">LLM + Query</td>\\n<td></td>\\n<td colspan=\"2\" style=\"text-align:center;\">MCPs + Retriever</td>\\n<td></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td colspan=\"2\" style=\"text-align:center;\">\\n[Robot icon]  \\nRequest →  \\n&lt;Need&gt; Fork\\n</td>\\n<td></td>\\n<td colspan=\"2\" style=\"text-align:center;\">\\n[Document icon] + [Magnifying glass icon]  \\nResponse →  \\n&lt;Need&gt; Knife\\n</td>\\n<td></td>\\n<td></td>\\n</tr>\\n<tr>\\n<td colspan=\"2\" style=\"text-align:center;\">\\n[Robot icon]  \\n&lt;Need&gt; Spoon\\n</td>\\n<td></td>\\n<td colspan=\"2\" style=\"text-align:center;\"></td>\\n<td></td>\\n<td></td>\\n</tr>\\n</tbody>\\n</table>\\n\\n> **Figure 1.** Comparison of tool selection paradigms for LLM agents.  \\n> (a) System-prompt-based methods inject all MCP tool schemas into the context, resulting in excessive prompt length and inefficiency.  \\n> (b) Retrieval-augmented approaches select tools by matching the user query once, which may lead to inaccurate or insufficient tool selection, especially in multi-turn scenarios.  \\n> (c) MCP-Zero enables the LLM to actively analyze the task, iteratively request the most relevant tools as needed, and dynamically construct a multi-step toolchain with minimal context overhead and high accuracy.\\n\\n----\\n\\n## Abstract\\n\\n*True intelligence requires active capability acquisition, yet current LLM agents inject pre-defined tool schemas into prompts, reducing models to passive selectors and falling short of robust general-purpose agency. We introduce MCP-Zero, an active agent framework that restores tool discovery autonomy to LLMs themselves. Instead of overwhelming models with all available tools, MCP-Zero enables agents to actively identify capability gaps, and request specific tools on-demand, transforming them from large-scale retrievers into genuine autonomous agents. The framework operates through three core mechanisms:*\\n\\n1. *Active Tool Request, where models autonomously generate structured requests specifying their exact tool requirements;*  \\n2. *Hierarchical Semantic Routing, a two-stage algorithm that matches requests to relevant servers and tools through improved semantic alignment;*  \\n3. *Iterative Capability Extension, enabling agents to progressively build cross-domain toolchains while maintaining minimal context footprint.*\\n\\n*We construct MCP-tools, a comprehensive dataset of 308 MCP servers and 2,797 tools from the official Model-Context-Protocol repository. Experiments demonstrate that MCP-Zero preserves agent autonomy while achieving substantial efficiency gains:*\\n\\n- *(i) accurate tool selection from nearly 3k candidates across 248.1k tokens;*  \\n- *(ii) 98% reduction in token consumption on APIBank while maintaining high accuracy;*  \\n- *(iii) consistent multi-turn performance that scales with tool ecosystem growth.*\\n\\n*This work establishes active tool discovery as a fundamental design pattern for scalable autonomous agent systems. The code and dataset is released at* `https://github.com/xfey/MCP-Zero`.\\n\\n----\\n\\n*Corresponding author*', mimetype='text/plain', start_char_idx=1, end_char_idx=3754, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8703443),\n",
       " NodeWithScore(node=TextNode(id_='459548b3-ca6c-462d-961e-88025d69199d', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 4, 'start_page_index': 3, 'start_page_label': 4, 'end_page_index': 3, 'end_page_label': 4, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 29263, 'end_char_idx': 33383}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', node_type='4', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794'}, hash='d8d6705e8da1c0b9ae29887d9045e0e119e7a2b90437b0e5d6ca008157702071'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dc0e85d7-acce-4ae7-aeaf-7a22b2d4c90c', node_type='1', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 3}, hash='190c1f63545401d8b0cfbe436b0dc1c619c69a4486e45dec298da888c2bd121a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='```plaintext\\nDebug my code: `src/train.py`\\n\\nOkay, I’ll fix that. First, let me read the file.\\n<tool_assistant>\\nServer: File system allowing file operations\\n        and management.\\nTool: Read file by filename.\\n</tool_assistant>\\n\\nSemantic Matching\\n<tool_response>\\nServer: Filesystem\\nTool: `read_file`\\nParams: {\"path\": \"path of the target file\"}\\n</tool_response>\\n\\n<function_call>\\n<invoke name=\"read_file\">\\n<parameter name=\"path\">src/train.py</parameter>\\n</invoke>\\n</function_call>\\n\\n<function_call_response>\\nimport numpy as np\\n...\\nif __name__ == \"__main__\":\\n    main()\\n</function_call_response>\\n\\nGreat, I have found the issue. Let me fix the code.\\n<tool_assistant>\\nServer: File system allowing file operations\\n        and management.\\nTool: Edit target file with new string.\\n</tool_assistant>\\n\\n<tool_response> `edit_file` </tool_response>\\n\\n<function_call> `edit_file` </function_call>\\n\\n<function_call_response> ... </function_call_response>\\n\\nFinally, I’ll run this code and check if the issue is solved now.\\n<tool_assistant>\\nServer: Terminal environment to execute command.\\nTool: Run command and get return value.\\n</tool_assistant>\\n\\n<tool_response> `run_cmd` </tool_response>\\n\\n<function_call> `run_cmd` </function_call>\\n\\n<function_call_response> ... </function_call_response>\\n\\nGreat! The bug is now fixed :)\\n\\nFigure 3. Illustrative example of MCP-Zero’s iterative active invocation. The model progressively identifies capability gaps and requests tools across three domains on-demand.\\n```\\n\\nmore critically, user requests are often broad and composite in nature (e.g., “write and run code to crawl AI repositories from GitHub”), requiring decomposition into multiple subtasks that cannot be solved by any single tool. Such scenarios demand progressive task breakdown where the model iteratively identifies capability gaps and requests appropriate tools on-demand, a challenge that current “query-once, retrieve-once” paradigms cannot adequately address.\\n\\n## 2.3. Model Context Protocol\\n\\nThe Model Context Protocol (MCP) is an open standard introduced in 2024 to enable secure and uniform access to external tools and services for large language models [2]. By defining a standardized interface through JSON-RPC message exchange, MCP addresses the fragmentation problem in AI tool integration, where different platforms previously required custom connectors and proprietary protocols. This standardization has led to rapid adoption across major AI platforms and development environments, facilitating the creation of hundreds of MCP servers spanning diverse domains including file systems, databases, web services, and specialized APIs.\\n\\nHowever, this expansion creates significant context overhead, as traditional approaches inject all server JSON-Schemas into system prompts simultaneously. Current solutions for MCP context optimization remain limited and follow conventional retrieval paradigms [7]. Given the enhanced capabilities of modern LLMs and MCP’s potential for agentic AI, we argue that existing methods fail to fully leverage contemporary language models’ tool-calling capabilities, motivating our MCP-Zero framework for dynamic, on-demand tool discovery.\\n\\n# 3. Method: MCP-Zero\\n\\nWe introduce MCP-Zero through two key aspects: the comprehensive framework design (Section 3.1) and theoretical analysis of active retrieval (Section 3.2). Our approach fundamentally shifts from passive tool injection to active tool discovery, enabling LLMs to dynamically construct task-specific toolchains across diverse domains with minimal context overhead.\\n\\n## 3.1. Active Tool Discovery Framework\\n\\nMCP-Zero is a active agent framework that enables LLMs to dynamically construct task-specific toolchains through on-demand tool retrieval. The framework operates through three core components that work synergistically to address the context overhead and multi-domain coordination challenges of existing approaches.\\n\\n**Overall Workflow.** Given a user query such as “Debug my code: `src/train.py`”, the LLM analyzes the task and autonomously determines when external tool assistance is needed. As shown in Figure 3, the model pro-', mimetype='text/plain', start_char_idx=1, end_char_idx=4122, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8170061),\n",
       " NodeWithScore(node=TextNode(id_='f0a38948-49c1-4ea8-a123-e1eacd90bc7a', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 2, 'start_page_index': 1, 'start_page_label': 2, 'end_page_index': 1, 'end_page_label': 2, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 7521, 'end_char_idx': 13004}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', node_type='4', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794'}, hash='d8d6705e8da1c0b9ae29887d9045e0e119e7a2b90437b0e5d6ca008157702071'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='491b9cbd-4978-4ef1-bf2f-1bf3564e9c13', node_type='1', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 1}, hash='043ee23b3deeb8e544df32fdda8e9b3f252a07f4b554436a1639be0c4e884787')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# 1. Introduction\\n\\n> *We only think when we are confronted with a problem.*  \\n> — John Dewey\\n\\nTrue thinking emerges not from passive consumption but from active engagement with challenges. Intelligence manifests through the capacity to actively seek solutions rather than merely selecting from predetermined options.\\n\\nLarge language models (LLMs) have evolved rapidly, demonstrating increasingly sophisticated reasoning and problem-solving capabilities [1, 8, 30]. The emergence of function-calling mechanisms has enabled large language models (LLMs) to transcend their parametric boundaries, leveraging external tools, APIs, and execution environments to accomplish complex real-world tasks [14, 18, 21, 26].\\n\\nHowever, current tool integration architectures fundamentally compromise agent autonomy. The dominant paradigm injects comprehensive tool schemas into system prompts, forcing agents into a passive role where they select from pre-defined options rather than actively discovering capabilities as needed (Figure 1a). This approach creates two critical problems: **massive context overhead** and **constrained decision autonomy**. For instance, the GitHub MCP server requires over 4,600 tokens for 26 tools, while comprehensive tool ecosystems can exceed 248k tokens—effectively transforming capable reasoning models into overwhelmed database query systems.\\n\\nRecent retrieval-based approaches attempt to reduce context overhead by pre-selecting relevant tools based on semantic similarity with user queries [7, 15]. While these methods address the scaling problem, they perpetuate the fundamental issue of passive tool consumption. Query like “Debug the file” requires filesystem access, code analysis, and command execution (Figure 1b): static retrieval based on initial queries cannot anticipate the evolving tool needs that emerge during task execution. More critically, this paradigm violates a core principle of autonomous agents—the ability to actively shape their environment based on dynamic assessment of their own capabilities.\\n\\nThe limitations of current approaches stem from three architectural constraints that prevent genuine agent autonomy:  \\n* (1) external decision authority—tool selection is delegated to retrieval systems rather than the agent itself;  \\n* (2) semantic distribution gaps—user queries and formal tool specifications exist in different semantic spaces, reducing matching precision; and  \\n* (3) static capability assumptions—tools are selected once rather than discovered iteratively as task understanding evolves.\\n\\n**Toward Active Tool Discovery:** True autonomous agents must retain authority over their capability acquisition. Modern LLMs possess sophisticated reasoning, self-reflection, and planning capabilities that enable them to assess their own limitations and articulate specific tool requirements. Rather than constraining agents to pre-selected tool sets, we propose active tool discovery—a paradigm where agents autonomously identify capability gaps and request appropriate tools on-demand. Based on this principle, we introduce MCP-Zero (Figure 1c), an active agent framework that restores tool discovery autonomy to LLMs through three core mechanisms:\\n\\n**Active Tool Request.** Instead of passive tool consumption, agents generate structured requests that specify their exact requirements:\\n\\n```xml\\n<tool assistant>\\nserver: ...   # Platform/permission domain\\ntool: ...     # Operation type + target\\n</tool assistant>\\n```\\n\\nThis approach ensures semantic alignment between agent needs and tool documentation while preserving decision autonomy.\\n\\n**Hierarchical Semantic Routing.** A two-stage matching algorithm first filters candidate servers by platform requirements, then ranks tools within selected servers based on semantic similarity. This hierarchical approach reduces search complexity while maintaining precision.\\n\\n**Iterative Capability Extension.** Agents can discover and integrate tools throughout task execution, building cross-domain capabilities dynamically. When initial tools prove insufficient, agents can refine their requests and discover alternatives, providing natural fault tolerance.\\n\\nTo support systematic evaluation, we also construct MCP-tools, a comprehensive dataset comprising 308 servers and 2,797 tools from the official Model-Context-Protocol repository[^1]. Experiments demonstrate that MCP-Zero maintains agent autonomy while achieving substantial efficiency gains: 98% reduction in token consumption with preserved accuracy across multi-turn conversations and large-scale tool ecosystems.\\n\\n[^1]: github.com/modelcontextprotocol/servers\\n\\n----\\n\\n<function>\\n```json\\n{\\n  \"description\": \"Search for GitHub repositories\",\\n  \"name\": \"mcp_github_search_repositories\",\\n  \"parameters\": {\\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\\n    \"additionalProperties\": false,\\n    \"properties\": {\\n      \"page\": {\\n        \"description\": \"Page number for pagination (default: 1)\",\\n        \"type\": \"number\"\\n      },\\n      \"perPage\": {\\n        \"description\": \"Number of results per page (default: 30, max: 100)\",\\n        \"type\": \"number\"\\n      },\\n      \"query\": {\\n        \"description\": \"Search query (see GitHub search syntax)\",\\n        \"type\": \"string\"\\n      }\\n    },\\n    \"required\": [\"query\"],\\n    \"type\": \"object\"\\n  }\\n}\\n```\\n</function>\\n\\n**Figure 2.** Example of a single MCP tool definition from the GitHub MCP server. This tool requires 143 tokens, while the complete server requires over 4,600 tokens.', mimetype='text/plain', start_char_idx=1, end_char_idx=5485, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.81665546),\n",
       " NodeWithScore(node=TextNode(id_='c054398b-b7d1-4e5a-8a7e-7c7fa35610ac', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 9, 'start_page_index': 8, 'start_page_label': 9, 'end_page_index': 8, 'end_page_label': 9, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 70935, 'end_char_idx': 76101}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', node_type='4', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794'}, hash='d8d6705e8da1c0b9ae29887d9045e0e119e7a2b90437b0e5d6ca008157702071'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1c098ca1-926d-4e45-a73a-43374725a062', node_type='1', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 8}, hash='524a5c05541b6df8a391ff567f19bbc520f68f7342b426342a212d221c32cc41')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* **Extreme Context Efficiency.** MCP-Zero cuts prompt length by **60–98%** across all settings (e.g. 111 vs. 6.3k tokens in the full single-turn case), validating its ability to ”pay for tools only when they are needed”.\\n\\n* **Robust Scalability.** When moving from a hand-curated *Domain* subset to the *Full* tool pool (40x more APIs), standard schema-injection accuracy on Claude-3.5 plummets from 97.60 to 69.23 (single-turn) and 100.00 to 60.22 (multi-turn); MCP-Zero instead keeps accuracy at 95.19 / 90.32 respectively, demonstrating strong resilience to attention dilution.\\n\\n* **Multi-turn Consistency.** MCP-Zero maintains high accuracy over conversation rounds (≤3% drop from single- to multi-turn), whereas standard methods degrade sharply once the context accumulates previous calls and larger tool sets.\\n\\n* **Necessity of Active Requests.** Pure query-retrieval baselines stall at 65–72 % accuracy, confirming that letting the model *author* semantically aligned requests is crucial.\\n\\nExperiments on APIBank corroborate our claims: MCP-Zero delivers near-optimal or superior tool-selection accuracy while slashing context usage by up to two orders of magnitude, remaining robust in both single- and multi-turn conversations and under massive tool-pool scaling. These results highlight active, iterative tool discovery as a practical path toward scalable, cost-efficient agent systems.\\n\\n## 6. Conclusion\\n\\nThis work establishes active tool discovery as a fundamental paradigm for autonomous agent systems, enabling models to maintain decision autonomy while addressing critical scalability challenges in tool-calling architectures. MCP-Zero demonstrates that shifting from passive tool consumption to agent-driven capability acquisition achieves substantial efficiency gains—98% token reduction with preserved accuracy—while restoring the core principle of autonomous agency: the ability to assess limitations and actively acquire necessary resources. Our theoretical framework, empirical validation, and the MCP-tools dataset provide both the foundation and infrastructure for advancing autonomous agent architectures as tool ecosystems continue expanding exponentially.\\n\\n## 7. Discussion\\n\\nIn this section we reflect on how the MCP-Zero paradigm can be adopted by other researchers (§7.1), analyse the surprisingly gain from a single in–context example (§7.2), and position MCP-Zero with respect to the contemporaneous *Alita* system, outlining a promising path toward self-improving agentic AI (§7.3).\\n\\n### 7.1. Cookbook: Integrate MCP-Zero Into Agent\\n\\nMCP-Zero is fundamentally a simple yet effective approach that we hope will benefit the broader MCP community. The core methodology distills into three straightforward steps: prompting models to actively request tools, maintaining a lightweight tool index with semantic descriptions, and leveraging the improved semantic alignment for high-precision retrieval. Below we provide a practical guide for integrating these ideas into existing agent frameworks.\\n\\n**Step 1 – Prompting the LLM to ask for tools.**  \\nGive the model an explicit “permission” to declare missing capabilities. In practice this is a `system` instruction such as:\\n\\n```text\\nIf the current task cannot be solved with your\\nown knowledge, emit a <tool assistant> block\\nspecifying the server domain and the tool\\noperation you require.\\n```\\n\\nIn addition, the output structure needs to be specified as we mentioned in Section 3.1. This step aims to stimulate the model’s ability to ”actively” propose requirements.\\n\\n**Step 2 – Curate a lightweight MCP-style tool index.**  \\nFirstly, choose a scope based on your needs: the entire MCP-tools collection, a vertical slice (e.g. databases only), or your in-house APIs. Then, for every server/tool:  \\n* extract the name and description from metadata;  \\n* optionally let a strong LLM generate an *enhanced summary* that emphasises capabilities and usage patterns;  \\n* store all texts in a vector store with pre-computed embeddings such as `text-embedding-3-large`.\\n\\n**Step 3 – Marry model output and retrieval.**  \\nWhen the agent emits a `<tool assistant>` block:  \\n* Match the `server` field against server descriptions and summaries; take top-*m* candidates.  \\n* Within each candidate server, rank tools by the `tool` field with the tool description embeddings.  \\n* Feed the best (or top-*k*) JSON-schemas back to the LLM.\\n\\nBecause the request text is already semantically aligned with the documents, retrieval precision is higher than “user query → API doc” matching, maintaining performances while significantly conserving context.\\n\\n### 7.2. Why Does a Single ICL Example Help?\\n\\nIn §5.2 we observed that adding **one** in-context example (“ICL-1”) helps lifting needle-in-haystack accuracy marginally. We hypothesise two simple but potent effects:  \\n1. **Stylistic anchor.** Our base prompt merely says “output the server and tool you need”, but gives no example of *how* the sentence should look like. The single in-context sample provides the writing style as the reference, helping the generated requests land much closer to the curated descriptions, thus semantic matching becomes easier.', mimetype='text/plain', start_char_idx=1, end_char_idx=5168, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7591723),\n",
       " NodeWithScore(node=TextNode(id_='1c098ca1-926d-4e45-a73a-43374725a062', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 8, 'start_page_index': 7, 'start_page_label': 8, 'end_page_index': 7, 'end_page_label': 8, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 60116, 'end_char_idx': 65517}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', node_type='4', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794'}, hash='d8d6705e8da1c0b9ae29887d9045e0e119e7a2b90437b0e5d6ca008157702071'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='426ffe59-f0a7-4117-abcd-e1ec86bf898e', node_type='1', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 7}, hash='1b0d9929a33a39d357a7894b8e22a0b4aab64fc06b0173e14e7aa4723cc1e5a5')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='<table>\\n<thead>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th colspan=\"4\">Collection</th>\\n<th colspan=\"4\">Method</th>\\n<th>Claude-3.5</th>\\n<th>GPT-4.1</th>\\n<th>Gemini-2.5</th>\\n<th>Avg. Tokens ↓</th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th colspan=\"4\">Single-turn Conversation</th>\\n<th colspan=\"4\"></th>\\n<th colspan=\"4\"></th>\\n<th></th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th>Domain</th>\\n<th>Q.Retrieval</th>\\n<th>Standard</th>\\n<th>MCP-Zero</th>\\n<th>97.60</th>\\n<th>98.08</th>\\n<th>92.79</th>\\n<th>312.4</th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th></th>\\n<th></th>\\n<th>96.15</th>\\n<th>96.62</th>\\n<th>97.12</th>\\n<th><b>111.0</b><br>(-64.47%)</th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th>Full</th>\\n<th>Q.Retrieval</th>\\n<th>Standard</th>\\n<th>MCP-Zero</th>\\n<th>69.23</th>\\n<th>94.71</th>\\n<th>94.23</th>\\n<th>6308.2</th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th></th>\\n<th></th>\\n<th>95.19</th>\\n<th>95.19</th>\\n<th>96.63</th>\\n<th><b>111.0</b><br>(-98.24%)</th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th colspan=\"4\">Multi-turn Conversation</th>\\n<th colspan=\"4\"></th>\\n<th colspan=\"4\"></th>\\n<th></th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th>Domain</th>\\n<th>Q.Retrieval</th>\\n<th>Standard</th>\\n<th>MCP-Zero</th>\\n<th>100.00</th>\\n<th>65.05</th>\\n<th>99.46</th>\\n<th>91.40</th>\\n<th>406.4</th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th></th>\\n<th></th>\\n<th>91.40</th>\\n<th>93.01</th>\\n<th>93.01</th>\\n<th><b>159.0</b><br>(-60.84%)</th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th>Full</th>\\n<th>Q.Retrieval</th>\\n<th>Standard</th>\\n<th>MCP-Zero</th>\\n<th>60.22</th>\\n<th>93.01</th>\\n<th>92.47</th>\\n<th>6402.2</th>\\n</tr>\\n<tr>\\n<th colspan=\"4\"></th>\\n<th></th>\\n<th></th>\\n<th>90.32</th>\\n<th>92.47</th>\\n<th>94.62</th>\\n<th><b>159.0</b><br>(-97.52%)</th>\\n</tr>\\n</thead>\\n</table>\\n\\n> **Figure 6.** Token efficiency comparison in needle-in-a-haystack experiments. The graph shows the average token cost per successful retrieval across different collection sizes.\\n\\n----\\n\\n**API-Bank** [12] provides tool information with multi-turn conversations and human-annotated test sets, making it the most suitable existing dataset for our evaluation.  \\n**ToolBench** [20] collected 16,464 REST APIs from RapidAPI Hub but many APIs lack essential descriptions.  \\n**ToolBank** [15] improved upon ToolBench but relies on model-generated data.  \\n**ToolAlpaca** [28] synthesized 3,938 instances from 400 APIs but targets scenarios mismatched with contemporary use cases.  \\nThe **APIBench1** from Gorilla [18] contains 1,645 APIs but uses entirely GPT-synthesized conversations.  \\nAnother **APIBench2** [19] is proposed, but its application scenarios have low relevance to MCP tool calls.\\n\\nExisting datasets have limitations for evaluating MCP-Zero: API scenarios differ from contemporary MCP use cases, lack hierarchical server-tool organization, or miss critical evaluation fields. Therefore, we use API-Bank as a reference and create the MCP-tools dataset for comprehensive evaluation. We are continuing to investigate other available datasets and conducting further validation.\\n\\n## 5.2. Needle-in-a-Haystack Evaluation\\n\\nTo evaluate MCP-Zero’s ability to accurately retrieve tools from large-scale collections under extreme context conditions, we conduct needle-in-a-haystack experiments on our MCP-tools dataset.\\n\\n**Experimental Setup.**  \\nWe construct test scenarios by injecting 1 to 2,797 tools into the environment, selecting task descriptions from various positions as queries, and requiring models to retrieve the target tool. This setup simulates the challenging scenario where relevant tools are buried within massive tool collections. We compare three approaches:  \\n* **Baseline:** Standard tool call schemas with all tools injected into context  \\n* **MCP-Zero:** Our active retrieval approach  \\n* **MCP-Zero + ICL:** MCP-Zero enhanced with one in-context learning example to guide description generation  \\n\\n**Results Analysis.**  \\nAs shown in Figure 5, our method demonstrates significant performance gains on Claude-3.5-Sonnet and Gemini-2.5-Flash, while GPT-4.1 shows no improvement due to its already strong baseline performance across all tool collection sizes. Figure 6 illustrates the dramatic difference in token consumption between traditional approaches and MCP-Zero. While standard tool call methods exhibit exponential growth in token costs as the number of MCP tools increases, MCP-Zero maintains consistently low token usage.\\n\\n## 5.3. APIBank Evaluation\\n\\nTo validate MCP-Zero’s effectiveness in realistic conversational tool retrieval scenarios, we conduct comprehensive experiments on the APIBank dataset.\\n\\n**Experimental Setup.**  \\nWe extract description information from the APIBank level-1 dataset for retrieval tasks, get 48 unique tools in total, and process it for our evaluation framework. Since APIBank organizes data by individual APIs without server-level hierarchy, we directly retrieve tools without the server filtering stage.\\n\\nWe evaluate across two key dimensions: conversation context and tool collection scope. For conversation context, we test both single-turn scenarios (one user query for one response) and multi-turn scenarios (extended conversations with multiple exchanges). For tool collection scope, we examine both domain collections (using a curated subset of tools relevant to the specific domain) and full collections (retrieving from the complete set of all available tools).\\n\\n**Results Analysis.**  \\nAs shown in Table 1, we can conclude the following findings:', mimetype='text/plain', start_char_idx=2, end_char_idx=5404, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.72605723),\n",
       " NodeWithScore(node=TextNode(id_='fa68d205-ad84-4a62-8afb-97b25c808ae2', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 5, 'start_page_index': 4, 'start_page_label': 5, 'end_page_index': 4, 'end_page_label': 5, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 37519, 'end_char_idx': 43245}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', node_type='4', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794'}, hash='d8d6705e8da1c0b9ae29887d9045e0e119e7a2b90437b0e5d6ca008157702071'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='459548b3-ca6c-462d-961e-88025d69199d', node_type='1', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 4}, hash='08b9eacc030abeb948cce29b419d619acc14c2ac6e2ac75d58a37bf40ed7e7a6')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='gressively breaks down the complex debugging task into subtasks: reading the file, analyzing and fixing the code, and validating the fix through execution. At each step, instead of relying on pre-injected tool schemas, the model actively generates structured tool requests. These requests are processed through hierarchical vector routing to retrieve the most relevant tools, which are then injected into the context for immediate use. The model iteratively repeats this process throughout the conversation, constructing a cross-domain toolchain spanning filesystem operations, code editing, and command execution.\\n\\n**Active Tool Request.** The foundation of our framework lies in returning tool requirement specification authority to the LLM itself. When the model identifies a capability gap that requires external assistance, it generates a structured request block:\\n\\n```xml\\n<tool assistant>\\nserver:        ...  #  Platform/permission domain\\ntool:          ...  #  Operation type + target\\n</tool assistant>\\n```\\n\\nThis mechanism enables the model to express tool needs spontaneously as they arise during task execution. Compared to raw user queries, the model-generated requests ensures better semantic alignment with tool documentation. The `server` field specifies the platform or permission domain requirements, while the `tool` field describes the desired operation type and target.\\n\\nWe design our framework around these two fields because they align naturally with the MCP specification, which mandates that all servers and tools provide descriptive documentation. This inherent requirement ensures consistent semantic information availability across the entire MCP ecosystem, making our retrieval approach universally applicable without additional metadata engineering.\\n\\nImportantly, the model can generate multiple such requests throughout a single conversation, with each request triggering an independent retrieval process.\\n\\n**Hierarchical Vector Routing.** To efficiently locate relevant tools from thousands of candidates, we employ a two-stage coarse-to-fine retrieval algorithm, using OpenAI `text-embedding-3-large` embeddings for semantic similarity matching.\\n\\nThe system first filters candidate MCP servers by matching the `server` field against server descriptions. Since server descriptions are typically brief single sentences, we construct extended summaries that include comprehensive usage examples essential for accurate matching (detailed in Section 4). We then perform matching against both the original descriptions and these enhanced summaries, taking the higher similarity score between the two approaches. This dual-matching strategy leverages both original MCP documentation and enhanced summaries to improve retrieval precision.\\n\\nSubsequently, tools within selected servers are ranked based on semantic similarity between the `tool` field and tool descriptions. The final ranking score combines both server-level and tool-level similarities:\\n\\n$$\\n\\\\text{score} = (s_{\\\\text{server}} \\\\times s_{\\\\text{tool}}) \\\\times \\\\max(s_{\\\\text{server}}, s_{\\\\text{tool}}) \\\\tag{1}\\n$$\\n\\nwhere \\\\( s_{\\\\text{server}} \\\\) and \\\\( s_{\\\\text{tool}} \\\\) represent cosine similarities at server and tool levels respectively. This scoring mechanism ensures that high similarity in either dimension contributes significantly to the final ranking, enabling effective recall of highly relevant tools. The system returns the top-\\\\( k \\\\) tools, with dynamic adjustment possible when similarity scores are closely clustered. In our experiments, we achieve high accuracy with top-1 retrieval, though we can configure larger \\\\( k \\\\) values to enhance fault tolerance when needed.\\n\\n**Iterative Active Invocation.** Unlike traditional single-round retrieval approaches, MCP-Zero supports iterative tool discovery throughout task execution. After receiving retrieved tools, the model autonomously evaluates their adequacy for the current subtask. If the returned tools are insufficient or inappropriate, the model can refine its request specification and reinitiate retrieval, providing natural fault tolerance and self-correction capabilities. This iterative process continues until the model determines that either (1) suitable tools have been found and the task can proceed, or (2) no appropriate tools exist and the task should rely on the model’s parametric knowledge.\\n\\nThe framework’s key advantage lies in its ability to construct cross-domain toolchains dynamically. For complex tasks requiring coordination across multiple domains (e.g., filesystem access, code generation, and command execution in Figure 3), the model can progressively identify and request tools from different servers as subtask requirements become clear, avoiding the context overhead of pre-loading comprehensive tool collections while maintaining high task completion accuracy. MCP-Zero represents a fundamental shift from “predefined toolset” to “dynamic on-demand tool discovery” for the community.\\n\\n### 3.2. Theoretical Analysis\\n\\nWe provide a theoretical analysis of MCP-Zero’s advantages over traditional approaches through formal modeling that connects to established theories in active learning and information acquisition.\\n\\n**Problem Formulation.** Let \\\\( T = \\\\{t_1, t_2, ..., t_n\\\\} \\\\) denote the complete tool collection, \\\\( q \\\\) represent the user query, \\\\( s_t \\\\) the current conversation state, and \\\\( t^* \\\\) the optimal tool selection. Traditional approaches require simultaneous evaluation over the entire collection:\\n\\n$$\\nP_{\\\\text{passive}}(t^*|q, T) = \\\\frac{P(q|t^*, T) P(t^*|T)}{\\\\sum_{t_i \\\\in T} P(q|t_i, T) P(t_i|T)} \\\\tag{2}\\n$$\\n\\nMCP-Zero employs active information acquisition where agents generate requests \\\\( r \\\\) based on their current state', mimetype='text/plain', start_char_idx=1, end_char_idx=5728, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.72325134),\n",
       " NodeWithScore(node=TextNode(id_='dc0e85d7-acce-4ae7-aeaf-7a22b2d4c90c', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 3, 'start_page_index': 2, 'start_page_label': 3, 'end_page_index': 2, 'end_page_label': 3, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 18503, 'end_char_idx': 23875}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', node_type='4', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794'}, hash='d8d6705e8da1c0b9ae29887d9045e0e119e7a2b90437b0e5d6ca008157702071'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f0a38948-49c1-4ea8-a123-e1eacd90bc7a', node_type='1', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 2}, hash='af24c766d8d5ce94fb47358cf60bf29e4e7c081439a937d1b2245278768af70d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Our main contributions establish active tool discovery as a fundamental design pattern for autonomous agent systems:  \\n* We propose MCP-Zero, enabling agents to maintain decision autonomy through active tool discovery, transforming them from passive selectors to autonomous capability architects.  \\n* We design hierarchical semantic routing that preserves semantic alignment between agent requests and tool specifications while reducing computational complexity.  \\n* We construct and release MCP-tools, providing the research community with a comprehensive evaluation framework for tool discovery systems.  \\n* We demonstrate that active discovery paradigms scale effectively with tool ecosystem growth while maintaining the autonomous decision-making that defines genuine agent systems.  \\n\\n## 2. Related Work\\n\\n### 2.1. Tool-Augmented LLMs\\n\\nThe evolution of tool-augmented large language models has progressed through distinct paradigms, each addressing different aspects of the fundamental challenge: how to effectively integrate external capabilities with language model reasoning.  \\n\\n**Early Task-Specific Integration.** Initial approaches focused on hard-coding specific tools into language models. MRKL [10] introduced modular reasoning by combining neural networks with symbolic modules like calculators, while WebGPT [16] demonstrated web browsing capabilities for information retrieval tasks. Though effective within their domains, these systems suffered from limited scalability and poor generalization to new tool types.  \\n\\n**Universal Agent Protocols.** The introduction of ReAct [31] marked a paradigm shift by establishing the “observation-action-thought” pattern, creating a universal protocol for tool-augmented reasoning. This framework became the foundation for modern agent systems including LangChain Agents [4] and AutoGen [29], enabling flexible and extensible tool integration architectures.  \\n\\n**Training-Based Tool Learning.** Parallel developments explored learning tool usage through model training. Toolformer [26] pioneered self-supervised learning for API call generation, teaching models to insert tool invocation markers within natural text generation. Gorilla [18] extended this approach by constructing large-scale instruction datasets with tool calls, enabling supervised learning of query-to-tool mappings across diverse API collections.  \\n\\n**Context-Based Tool Injection.** The emergence of ChatGPT Function Calling and systems like HuggingGPT [27] introduced context-based approaches, which inject JSON-Schema tool descriptions into system prompts, eliminating the need for specialized training. ART [17] further refined this paradigm by constructing demonstration libraries in chain-of-thought format, leveraging in-context learning for tool selection and usage.  \\n\\n**Fundamental Limitations.** Despite these advances, existing approaches face critical scalability challenges. Training-based methods require expensive retraining for each toolset update, limiting their adaptability to evolving tool ecosystems. Context-based methods, while more flexible, suffer from prohibitive context overhead when injecting comprehensive tool descriptions—a problem that becomes acute as tool collections scale to thousands of APIs. Most critically, when relevant tools are absent from the predefined context, task completion becomes impossible, highlighting the need for dynamic, on-demand tool discovery mechanisms that can adapt to diverse and evolving task requirements.  \\n\\n### 2.2. Tool Retrieval for LLMs\\n\\nThe success of Retrieval-Augmented Generation (RAG) in addressing knowledge limitations through the “retrieve-insert-generate” paradigm has inspired its adaptation to tool selection for LLMs [11]. Classical RAG frameworks like REALM [9], RETRO [3] and In-Context RALM [25] demonstrated the effectiveness of dynamically incorporating external knowledge into generation processes. Recent work has extended this paradigm to tool selection, aiming to reduce context overhead by retrieving only the most relevant tools for a given query.  \\n\\n**Semantic Similarity-Based Retrieval.** Early approaches focused on direct semantic matching between user queries and tool descriptions. Gorilla [18] constructed vector databases from API documentation and usage examples, employing semantic similarity to retrieve relevant tools. Tool2Vec [15] addressed the semantic gap between user requests and formal API descriptions by pre-collecting diverse user invocation patterns and computing averaged embeddings, though this approach requires extensive user interaction datasets for training. RAG-MCP [7] performs server-level matching between user queries and documentation from MCPBench [13], returning all tools from the most similar server as the context of LLMs.  \\n\\n**Hierarchical Tool Retrieval.** Recognizing the limitations of flat retrieval, several works have explored coarse-to-fine approaches. AnyTool [6] implemented a multi-level retrieval system based on the RapidAPI dataset, constructing separate retrievers for “category-tool-API” hierarchies. ToolRerank [32] leveraged pre-trained BERT models for semantic matching, while COLT [23] employed specialized language models for tool selection. Re-Invoke [5] introduced key information extraction from user queries before tool matching.  \\n\\n**Limitations of Current Approaches.** Despite reduc-', mimetype='text/plain', start_char_idx=1, end_char_idx=5374, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.69049704),\n",
       " NodeWithScore(node=TextNode(id_='54677edb-b7af-4214-a0fe-f1dcb4b8c59b', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 11, 'start_page_index': 10, 'start_page_label': 11, 'end_page_index': 10, 'end_page_label': 11, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 91887, 'end_char_idx': 97271}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', node_type='4', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794'}, hash='d8d6705e8da1c0b9ae29887d9045e0e119e7a2b90437b0e5d6ca008157702071'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6a1dd7bd-f6ac-4bc2-8aa7-990bf711b39a', node_type='1', metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 10}, hash='ceddb59a7091c6718d5ef08b85cbff06ed8696f40f1b420266e9c8cec00a3824')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. *Advances in neural information processing systems*, 33:9459–9474, 2020. 3\\n\\n[12] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. *arXiv preprint arXiv:2304.08244*, 2023. 8\\n\\n[13] Zhiling Luo, Xiaorong Shi, Xuanrui Lin, and Jinyang Gao. Evaluation report on mcp servers. *arXiv preprint arXiv:2504.11094*, 2025. 3, 6, 7\\n\\n[14] Tula Masterman, Sandi Besen, Mason Sawtell, and Alex Chao. The landscape of emerging ai agent architectures for reasoning, planning, and tool calling: A survey. *arXiv preprint arXiv:2404.11584*, 2024. 2\\n\\n[15] Suhong Moon, Siddharth Jha, Lutfi Eren Erdogan, Sehoon Kim, Woosang Lim, Kurt Keutzer, and Amir Gholami. Efficient and scalable estimation of tool representations in vector space. *arXiv preprint arXiv:2409.02141*, 2024. 2, 3, 8\\n\\n[16] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. *arXiv preprint arXiv:2112.09332*, 2021. 3\\n\\n[17] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. Art: Automatic multi-step reasoning and tool-use for large language models. *arXiv preprint arXiv:2303.09014*, 2023. 3\\n\\n[18] Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. Gorilla: Large language model connected with massive apis. *Advances in Neural Information Processing Systems*, 37:126544–126565, 2024. 2, 3, 8\\n\\n[19] Yun Peng, Shuqing Li, Wenwei Gu, Yichen Li, Wenxuan Wang, Cuiyun Gao, and Michael R Lyu. Revisiting, benchmarking and exploring api recommendation: How far are we? *IEEE Transactions on Software Engineering*, 49(4):1876–1897, 2022. 8\\n\\n[20] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. Toolllm: Facilitating large language models to master 16000+ real-world apis. *arXiv preprint arXiv:2307.16789*, 2023. 8\\n\\n[21] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Xuanhe Zhou, Yufei Huang, Chaojun Xiao, et al. Tool learning with foundation models. *ACM Computing Surveys*, 57(4):1–40, 2024. 2\\n\\n[22] Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, et al. Alita: Generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal self-evolution. *arXiv preprint arXiv:2505.20286*, 2025. 10\\n\\n[23] Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, and Ji-Rong Wen. Colt: Towards completeness-oriented tool retrieval for large language models. *arXiv e-prints*, pages arXiv–2405, 2024. 3\\n\\n[24] Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report, 2025. 7\\n\\n[25] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. In-context retrieval-augmented language models. *Transactions of the Association for Computational Linguistics*, 11:1316–1331, 2023. 3\\n\\n[26] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. *Advances in Neural Information Processing Systems*, 36:68539–68551, 2023. 2, 3\\n\\n[27] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face. *Advances in Neural Information Processing Systems*, 36:38154–38180, 2023. 3\\n\\n[28] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, Boxi Cao, and Le Sun. Toolalpaca: Generalized tool learning for language models with 3000 simulated cases. *arXiv preprint arXiv:2306.05301*, 2023. 8\\n\\n[29] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, et al. Autogen: Enabling next-gen llm applications via multi-agent conversation. *arXiv preprint arXiv:2308.08155*, 2023. 3\\n\\n[30] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. *arXiv preprint arXiv:2505.09388*, 2025. 2\\n\\n[31] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In *International Conference on Learning Representations (ICLR)*, 2023. 3\\n\\n[32] Yuanhang Zheng, Peng Li, Wei Liu, Yang Liu, Jian Luan, and Bin Wang. Toolrerank: Adaptive and hierarchy-aware reranking for tool retrieval. *arXiv preprint arXiv:2403.06551*, 2024. 3', mimetype='text/plain', start_char_idx=1, end_char_idx=5386, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.66308063)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcp_zero_index = LlamaCloudIndex(\n",
    "  name=\"mcp-zero-paper\",\n",
    "  project_name=\"Default\",\n",
    "  organization_id=\"bf9b425c-54cb-4182-a93f-8ac6aed04348\",\n",
    "  api_key=LLAMA_CLOUD_API_KEY,\n",
    ")\n",
    "mcp_zero_retriever = mcp_zero_index.as_retriever(**kwargs)\n",
    "mcp_zero_retriever.retrieve(\"what is MCP Zero?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cc41bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"gpt-oss:20b\", request_timeout = 600)\n",
    "mcp_zero_engine = mcp_zero_index.as_query_engine(llm=llm, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a466aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = mcp_zero_engine.query(\"What is MCP zero and how does it work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "173bd19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**MCP‑Zero** is an agent framework that lets a large language model (LLM) discover and call external tools on its own instead of being handed a huge list of tool descriptions up front.  \n",
       "It addresses two common bottlenecks in today’s tool‑augmented LLMs:\n",
       "\n",
       "| Problem | Conventional approach | MCP‑Zero solution |\n",
       "|---------|-----------------------|-------------------|\n",
       "| **Context bloat** – all JSON‑schema definitions are injected, consuming tens of thousands of tokens | Inject the whole tool ecosystem into the prompt | The LLM requests only the tools it needs, so only a few relevant schemas are added |\n",
       "| **Passive selection** – the model simply picks from a pre‑selected set | A single query is matched to the whole tool set | The model actively asks for a tool, can refine its request, and can request new tools in later turns |\n",
       "\n",
       "### Core ideas\n",
       "\n",
       "1. **Active Tool Request**  \n",
       "   The LLM emits a tiny, structured block that states what it needs.  \n",
       "   ```xml\n",
       "   <tool assistant>\n",
       "   server: <domain or permission>\n",
       "   tool:   <operation type + target>\n",
       "   </tool assistant>\n",
       "   ```\n",
       "   Because the request is generated by the model itself, it matches the semantics of the tool documentation more closely than a raw user query.\n",
       "\n",
       "2. **Hierarchical Semantic Routing**  \n",
       "   The request is handled in two stages using semantic embeddings:\n",
       "\n",
       "   * **Server filtering** – match the `server` field against short server descriptions (often just one sentence).  \n",
       "   * **Tool ranking** – within each chosen server, rank tools by similarity between the `tool` field and the tool’s description.  \n",
       "   A combined score (product × max of the two similarities) selects the top‑k schemas to feed back to the LLM.\n",
       "\n",
       "3. **Iterative Capability Extension**  \n",
       "   After a tool is used, the LLM checks whether the task is still incomplete.  \n",
       "   If more capability is required, it emits another request; if not, it proceeds.  \n",
       "   This loop allows the agent to build a cross‑domain chain of tools (e.g., filesystem access → code editing → command execution) while never loading the full tool collection into the prompt.\n",
       "\n",
       "### How it works in practice\n",
       "\n",
       "1. **User asks**: “Debug my code in `src/train.py`.”  \n",
       "2. **LLM** → notices it lacks filesystem, code‑analysis, and shell execution tools.  \n",
       "3. **LLM** emits a request for a filesystem read tool.  \n",
       "4. **System** finds the best matching server (e.g., “File System”) and the specific read tool, returns the JSON‑schema.  \n",
       "5. **LLM** calls the tool, gets the file, then requests a code‑analysis tool, and so on.  \n",
       "6. **Once all needed tools are called**, the LLM solves the problem and produces the final answer.\n",
       "\n",
       "Because only the schemas of the actually used tools are sent back, the prompt stays tiny (often a few hundred tokens) even when the total tool ecosystem contains thousands of APIs. The agent remains fully autonomous: it decides *when* and *what* to request, can refine its requests in subsequent turns, and can grow a customized toolchain on the fly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65bac49",
   "metadata": {},
   "source": [
    "## Composite retrieval\n",
    "Not recommended. It's better to break the question into sub parts and query the correct index with each part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "643b2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cloud import CompositeRetrievalMode, RetrieverPipeline\n",
    "from llama_index.indices.managed.llama_cloud import (\n",
    "    LlamaCloudIndex,\n",
    "    LlamaCloudCompositeRetriever,\n",
    ")\n",
    "\n",
    "retriever = LlamaCloudCompositeRetriever(\n",
    "    name=\"Alita and MCP Zero Retriever\",\n",
    "    api_key=LLAMA_CLOUD_API_KEY,\n",
    "    create_if_not_exists=True,\n",
    "    mode=CompositeRetrievalMode.FULL,\n",
    "    rerank_top_n=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c832a872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Retriever(name='Alita and MCP Zero Retriever', pipelines=[RetrieverPipeline(name='alita-paper', description='Knowledge base for the Alita paradigm for agents', pipeline_id='6e287db8-a658-48c2-837f-1e13c85edc84', preset_retrieval_parameters=PresetRetrievalParams(dense_similarity_top_k=30, dense_similarity_cutoff=0.0, sparse_similarity_top_k=30, enable_reranking=True, rerank_top_n=6, alpha=0.5, search_filters=None, search_filters_inference_schema=None, files_top_k=1, retrieval_mode=<RetrievalMode.CHUNKS: 'chunks'>, retrieve_image_nodes=False, retrieve_page_screenshot_nodes=False, retrieve_page_figure_nodes=False, class_name='base_component')), RetrieverPipeline(name='mcp-zero-paper', description='Knowledge base of the (model context protocol) MCP zero paradigm', pipeline_id='1d5c48e0-9849-49a6-a59d-0af4eb09f794', preset_retrieval_parameters=PresetRetrievalParams(dense_similarity_top_k=30, dense_similarity_cutoff=0.0, sparse_similarity_top_k=30, enable_reranking=True, rerank_top_n=6, alpha=0.5, search_filters=None, search_filters_inference_schema=None, files_top_k=1, retrieval_mode=<RetrievalMode.CHUNKS: 'chunks'>, retrieve_image_nodes=False, retrieve_page_screenshot_nodes=False, retrieve_page_figure_nodes=False, class_name='base_component'))], id='d2c4add1-f4cb-41a0-bcfd-58dac5293769', created_at=datetime.datetime(2025, 8, 13, 2, 38, 0, 856052, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 8, 13, 2, 39, 23, 685850, tzinfo=datetime.timezone.utc), project_id='6bdb9346-fa87-4a33-a621-f595ccbb5986')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.add_index(\n",
    "    alita_index, description=\"Knowledge base for the Alita paradigm for agents\"\n",
    ")\n",
    "retriever.add_index(\n",
    "    mcp_zero_index, description=\"Knowledge base of the (model context protocol) MCP zero paradigm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "863cfa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(\n",
    "    \"What is Alita and what is MCP Zero? Can Alita and MCP zero work together?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5ce16e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='014911b9-3bda-45c1-901f-2c96a94b2295', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 10, 'start_page_index': 9, 'start_page_label': 10, 'end_page_index': 9, 'end_page_label': 10, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 81283, 'end_char_idx': 86577, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'mcp-zero-paper'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='**2. Semantic grounding.** The example also clarifies the *meaning* of each field, helping the model understand the specific definitions of MCP server and tool, thereby limiting its expression scope. After seeing this, the model reliably emits phrases such as `filesystem.read` instead of a vague “read the file”, sharply reducing semantic mismatch.\\n\\nIn short, a tiny demonstration patch acts as a *schema anchor*; future work could replace ICL with a short grammar-based decoder rule, but the one-shot approach is free and highly effective.\\n\\n### 7.3. Synergy with Alita: Using *and* Making Tools\\n\\nConcurrently, **Alita** [22] proposes a united manager agent that *creates* its own toolchain: it web-searches for code, clones GitHub repos, builds environments, and executes the resulting programs to accomplish tasks. We were pleasantly surprised by the contribution of this article, and found that the two lines of work are complementary:  \\n* MCP-Zero: *efficiently finds and invokes* existing tools  \\n* Alita: *automatically builds missing tools on-the-fly*\\n\\nMCP-Zero and Alita address complementary halves of the same problem: the former maximises *tool discovery* while the latter maximises *tool creation*. When combined, they form a virtuous loop: an agent first actively discovers tools from *all* available resources; if none fits, it switches to Alita’s workflow to synthesize a new one, then registers the freshly built tool for the community. We believe such a pipeline is a compelling direction toward self-evolving, cost-aware agentic AI systems.\\n\\n### 7.4. Future Work\\n\\nWhile MCP-Zero demonstrates significant improvements in tool retrieval efficiency and accuracy, several promising directions warrant further investigation:\\n\\n**Enhanced Experimental Validation.** Future work should expand evaluation across diverse domains. We plan to conduct comprehensive experiments on additional datasets to validate generalizability.\\n\\n**Advanced Matching Algorithms.** The current semantic similarity approach could be enhanced. We envision incorporating multi-modal descriptions (e.g., code examples, usage patterns, parameter schemas) into the retrieval process, and exploring usage co-occurrence patterns for improved contextual understanding.\\n\\n**MCP Server Implementation.** A natural extension involves packaging MCP-Zero as a dedicated MCP server providing tool discovery services. This ”meta-server” would expose standardized APIs for active tool retrieval, enabling seamless integration into existing MCP ecosystems and serving as a centralized discovery hub for distributed tool collections.\\n\\n**Multi-Agent Orchestration.** MCP-Zero’s active discovery approach could enable better multi-agent collaboration. Future work could investigate how different agents can automatically discover and share tools with each other, allowing them to work together more effectively on complex tasks that require diverse capabilities.\\n\\n----\\n\\n## References\\n\\n[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. GPT-4 technical report. *arXiv preprint arXiv:2303.08774*, 2023. 2\\n\\n[2] Anthropic. Model context protocol. https://docs.anthropic.com/en/docs/agents-and-tools/mcp, 2024. Accessed: June 25, 2025. 4\\n\\n[3] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. Improving language models by retrieving from trillions of tokens. In *International conference on machine learning*, pages 2206–2240. PMLR, 2022. 3\\n\\n[4] Harrison Chase. Langchain. https://github.com/langchain-ai/langchain, 2022. Python framework for developing applications powered by language models. 3\\n\\n[5] Yanfei Chen, Jinsung Yoon, Devendra Singh Sachan, Qingze Wang, Vincent Cohen-Addad, Mohammadhossein Bateni, Chen-Yu Lee, and Tomas Pfister. Re-invoke: Tool invocation rewriting for zero-shot tool retrieval. *arXiv preprint arXiv:2408.01875*, 2024. 3\\n\\n[6] Yu Du, Fangyun Wei, and Hongyang Zhang. Anytool: Self-reflective, hierarchical agents for large-scale api calls. *arXiv preprint arXiv:2402.04253*, 2024. 3\\n\\n[7] Tiantian Gan and Qiyao Sun. Rag-mcp: Mitigating prompt bloat in llm tool selection via retrieval-augmented generation. *arXiv preprint arXiv:2505.03275*, 2025. 2, 3, 4\\n\\n[8] Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. The llama 3 herd of models. *arXiv preprint arXiv:2407.21783*, 2024. 2\\n\\n[9] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. Retrieval augmented language model pretraining. In *International conference on machine learning*, pages 3929–3938. PMLR, 2020. 3\\n\\n[10] Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, et al. Mrkl systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. *arXiv preprint arXiv:2205.00445*, 2022. 3\\n\\n[11] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.81875163),\n",
       " NodeWithScore(node=TextNode(id_='c134ff1b-8bc1-4974-8db3-aeb258edb0cf', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 9, 'start_page_index': 8, 'start_page_label': 9, 'end_page_index': 8, 'end_page_label': 9, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 70935, 'end_char_idx': 76101, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'mcp-zero-paper'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* **Extreme Context Efficiency.** MCP-Zero cuts prompt length by **60–98%** across all settings (e.g. 111 vs. 6.3k tokens in the full single-turn case), validating its ability to ”pay for tools only when they are needed”.\\n\\n* **Robust Scalability.** When moving from a hand-curated *Domain* subset to the *Full* tool pool (40x more APIs), standard schema-injection accuracy on Claude-3.5 plummets from 97.60 to 69.23 (single-turn) and 100.00 to 60.22 (multi-turn); MCP-Zero instead keeps accuracy at 95.19 / 90.32 respectively, demonstrating strong resilience to attention dilution.\\n\\n* **Multi-turn Consistency.** MCP-Zero maintains high accuracy over conversation rounds (≤3% drop from single- to multi-turn), whereas standard methods degrade sharply once the context accumulates previous calls and larger tool sets.\\n\\n* **Necessity of Active Requests.** Pure query-retrieval baselines stall at 65–72 % accuracy, confirming that letting the model *author* semantically aligned requests is crucial.\\n\\nExperiments on APIBank corroborate our claims: MCP-Zero delivers near-optimal or superior tool-selection accuracy while slashing context usage by up to two orders of magnitude, remaining robust in both single- and multi-turn conversations and under massive tool-pool scaling. These results highlight active, iterative tool discovery as a practical path toward scalable, cost-efficient agent systems.\\n\\n## 6. Conclusion\\n\\nThis work establishes active tool discovery as a fundamental paradigm for autonomous agent systems, enabling models to maintain decision autonomy while addressing critical scalability challenges in tool-calling architectures. MCP-Zero demonstrates that shifting from passive tool consumption to agent-driven capability acquisition achieves substantial efficiency gains—98% token reduction with preserved accuracy—while restoring the core principle of autonomous agency: the ability to assess limitations and actively acquire necessary resources. Our theoretical framework, empirical validation, and the MCP-tools dataset provide both the foundation and infrastructure for advancing autonomous agent architectures as tool ecosystems continue expanding exponentially.\\n\\n## 7. Discussion\\n\\nIn this section we reflect on how the MCP-Zero paradigm can be adopted by other researchers (§7.1), analyse the surprisingly gain from a single in–context example (§7.2), and position MCP-Zero with respect to the contemporaneous *Alita* system, outlining a promising path toward self-improving agentic AI (§7.3).\\n\\n### 7.1. Cookbook: Integrate MCP-Zero Into Agent\\n\\nMCP-Zero is fundamentally a simple yet effective approach that we hope will benefit the broader MCP community. The core methodology distills into three straightforward steps: prompting models to actively request tools, maintaining a lightweight tool index with semantic descriptions, and leveraging the improved semantic alignment for high-precision retrieval. Below we provide a practical guide for integrating these ideas into existing agent frameworks.\\n\\n**Step 1 – Prompting the LLM to ask for tools.**  \\nGive the model an explicit “permission” to declare missing capabilities. In practice this is a `system` instruction such as:\\n\\n```text\\nIf the current task cannot be solved with your\\nown knowledge, emit a <tool assistant> block\\nspecifying the server domain and the tool\\noperation you require.\\n```\\n\\nIn addition, the output structure needs to be specified as we mentioned in Section 3.1. This step aims to stimulate the model’s ability to ”actively” propose requirements.\\n\\n**Step 2 – Curate a lightweight MCP-style tool index.**  \\nFirstly, choose a scope based on your needs: the entire MCP-tools collection, a vertical slice (e.g. databases only), or your in-house APIs. Then, for every server/tool:  \\n* extract the name and description from metadata;  \\n* optionally let a strong LLM generate an *enhanced summary* that emphasises capabilities and usage patterns;  \\n* store all texts in a vector store with pre-computed embeddings such as `text-embedding-3-large`.\\n\\n**Step 3 – Marry model output and retrieval.**  \\nWhen the agent emits a `<tool assistant>` block:  \\n* Match the `server` field against server descriptions and summaries; take top-*m* candidates.  \\n* Within each candidate server, rank tools by the `tool` field with the tool description embeddings.  \\n* Feed the best (or top-*k*) JSON-schemas back to the LLM.\\n\\nBecause the request text is already semantically aligned with the documents, retrieval precision is higher than “user query → API doc” matching, maintaining performances while significantly conserving context.\\n\\n### 7.2. Why Does a Single ICL Example Help?\\n\\nIn §5.2 we observed that adding **one** in-context example (“ICL-1”) helps lifting needle-in-haystack accuracy marginally. We hypothesise two simple but potent effects:  \\n1. **Stylistic anchor.** Our base prompt merely says “output the server and tool you need”, but gives no example of *how* the sentence should look like. The single in-context sample provides the writing style as the reference, helping the generated requests land much closer to the curated descriptions, thus semantic matching becomes easier.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.72768575),\n",
       " NodeWithScore(node=TextNode(id_='fcd6b416-ba60-46d5-aaf0-ecd93807a04e', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-13T02:23:02', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '1c2460ac-3fe0-4394-ace3-d4b2df4559e3', 'pipeline_id': '1d5c48e0-9849-49a6-a59d-0af4eb09f794', 'page_label': 11, 'start_page_index': 10, 'start_page_label': 11, 'end_page_index': 10, 'end_page_label': 11, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 91887, 'end_char_idx': 97271, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'mcp-zero-paper'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. *Advances in neural information processing systems*, 33:9459–9474, 2020. 3\\n\\n[12] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. *arXiv preprint arXiv:2304.08244*, 2023. 8\\n\\n[13] Zhiling Luo, Xiaorong Shi, Xuanrui Lin, and Jinyang Gao. Evaluation report on mcp servers. *arXiv preprint arXiv:2504.11094*, 2025. 3, 6, 7\\n\\n[14] Tula Masterman, Sandi Besen, Mason Sawtell, and Alex Chao. The landscape of emerging ai agent architectures for reasoning, planning, and tool calling: A survey. *arXiv preprint arXiv:2404.11584*, 2024. 2\\n\\n[15] Suhong Moon, Siddharth Jha, Lutfi Eren Erdogan, Sehoon Kim, Woosang Lim, Kurt Keutzer, and Amir Gholami. Efficient and scalable estimation of tool representations in vector space. *arXiv preprint arXiv:2409.02141*, 2024. 2, 3, 8\\n\\n[16] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. *arXiv preprint arXiv:2112.09332*, 2021. 3\\n\\n[17] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. Art: Automatic multi-step reasoning and tool-use for large language models. *arXiv preprint arXiv:2303.09014*, 2023. 3\\n\\n[18] Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. Gorilla: Large language model connected with massive apis. *Advances in Neural Information Processing Systems*, 37:126544–126565, 2024. 2, 3, 8\\n\\n[19] Yun Peng, Shuqing Li, Wenwei Gu, Yichen Li, Wenxuan Wang, Cuiyun Gao, and Michael R Lyu. Revisiting, benchmarking and exploring api recommendation: How far are we? *IEEE Transactions on Software Engineering*, 49(4):1876–1897, 2022. 8\\n\\n[20] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. Toolllm: Facilitating large language models to master 16000+ real-world apis. *arXiv preprint arXiv:2307.16789*, 2023. 8\\n\\n[21] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Xuanhe Zhou, Yufei Huang, Chaojun Xiao, et al. Tool learning with foundation models. *ACM Computing Surveys*, 57(4):1–40, 2024. 2\\n\\n[22] Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, et al. Alita: Generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal self-evolution. *arXiv preprint arXiv:2505.20286*, 2025. 10\\n\\n[23] Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, and Ji-Rong Wen. Colt: Towards completeness-oriented tool retrieval for large language models. *arXiv e-prints*, pages arXiv–2405, 2024. 3\\n\\n[24] Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report, 2025. 7\\n\\n[25] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. In-context retrieval-augmented language models. *Transactions of the Association for Computational Linguistics*, 11:1316–1331, 2023. 3\\n\\n[26] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. *Advances in Neural Information Processing Systems*, 36:68539–68551, 2023. 2, 3\\n\\n[27] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face. *Advances in Neural Information Processing Systems*, 36:38154–38180, 2023. 3\\n\\n[28] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, Boxi Cao, and Le Sun. Toolalpaca: Generalized tool learning for language models with 3000 simulated cases. *arXiv preprint arXiv:2306.05301*, 2023. 8\\n\\n[29] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, et al. Autogen: Enabling next-gen llm applications via multi-agent conversation. *arXiv preprint arXiv:2308.08155*, 2023. 3\\n\\n[30] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. *arXiv preprint arXiv:2505.09388*, 2025. 2\\n\\n[31] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In *International Conference on Learning Representations (ICLR)*, 2023. 3\\n\\n[32] Yuanhang Zheng, Peng Li, Wei Liu, Yang Liu, Jian Luan, and Bin Wang. Toolrerank: Adaptive and hierarchy-aware reranking for tool retrieval. *arXiv preprint arXiv:2403.06551*, 2024. 3', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6213807),\n",
       " NodeWithScore(node=TextNode(id_='da02f16e-705e-4a5b-bacf-fc38bbe5369e', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 3, 'start_page_index': 2, 'start_page_label': 3, 'end_page_index': 2, 'end_page_label': 3, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 16469, 'end_char_idx': 21079, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'alita-paper'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* We present Alita, a generalist agent that achieves scalable agentic reasoning with a radically simple design.  \\n* We empirically demonstrate that Alita, despite using no complex predefined tools and workflows for specific tasks, outperforms many systems with significantly more handcrafted complexity on the GAIA benchmark. We achieve 75.15% pass@1 and 87.27% pass@3, surpassing OpenAI’s Deep Research with 67.36% pass@1 and ranking top among all general-purpose agents.\\n\\n## 2 Related Works\\n\\n### 2.1 Generalist Agent\\n\\nThe concept of a Generalist Agent aims to construct an AI agent system capable of collaboratively completing a variety of complex tasks in a real-world environment. OWL [8] introduces a method that decomposes complex tasks into subtasks and dynamically allocates them to worker nodes with specialized toolkits. Omne [11] proposes a multi-agent collaborative development framework, where each agent possesses an independent system structure, enabling autonomous learning and the storage of a comprehensive world model to build an independent understanding of the environment. OpenAI Deep Research[^2] employs reinforcement learning for training on real-world tasks, aiming to provide precise and reliable research reports for knowledge-intensive tasks. A-World [12] offers a highly configurable, modular, and scalable simulation environment, allowing developers to flexibly define and integrate different types of AI agents. The Magentic-One [13] framework merges the Magentic and Autogen systems, distinguishing between the micro-level LLM-driven function generation and the macro-level multi-agent orchestration, resulting in a clearer and more efficient construction of agent systems. Alita, also a Generalist Agent, allows for the minimal use of predefined tools and workflows for direct problem-solving, yet still achieves impressive performance across diverse tasks.\\n\\n### 2.2 Auto Generating Agent\\n\\nAuto-generating agents aim to enhance the versatility of agents by enabling them to autonomously generate tools, agents, or workflows tailored to specific tasks. AutoAgents [14], for instance, generate multiple agents, each playing a distinct role, to handle the corresponding subtasks. OpenHands [15] offers an event-driven architecture that allows agents to interact with the environment like human developers, thereby enabling the creation of custom workflows. AFlow [16] redefines workflow optimization as a search problem, where each workflow consists of several nodes invoking large LLMs, and the optimal workflow is identified and executed through a search process. AutoAgent [17], as an autonomous agent operating system, permits agents to manage system-level operations and file data autonomously. In Alita, agents are empowered to automatically generate diverse, specialized, and highly accurate MCPs to aid in the completion of specific tasks, while also providing resources for future executions.\\n\\n### 2.3 Tool Creation\\n\\nTool Creation enables agents to autonomously create tools to assist in task execution, either on their own or with external support. CRAFT [18] utilizes GPT-4 to generate a set of code snippets that function as tools, which are then retrieved and used in the system. TroVE [19] maintains a collection of high-level functions, which are automatically generated, extended, and periodically pruned to optimize program generation. CREATOR [20] decouples the abstraction of tool creation from the actual execution, allowing LLMs to address tasks at different levels of granularity. AutoAgent [17] enables agents to autonomously create new tools based on task requirements, incorporating information gathered through web searches and integrating these tools into their workflow. OpenHands [15] allows agents to create code scripts in a human-like manner during interaction with the environment to assist in task completion. In comparison, Alita enables MCP creation, which provides additional benefits, including better reusability and easy environment management over tool creation.\\n\\n### 2.4 MCP\\n\\nThe Model Context Protocol (MCP) is a standard proposed by Anthropic, designed to unify the connection between AI systems and external data sources and services. RAG-MCP [21] enhances the efficiency and accuracy of agents by retrieving the most relevant tools from a large collection, based on the task description, within the database composed of MCP descriptions. After tool generation, Alita wraps the generated valid tools into MCPs for subsequent use, facilitating reuse by itself and other agents.\\n\\n[^2]: https://openai.com/index/introducing-deep-research/', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5971152),\n",
       " NodeWithScore(node=TextNode(id_='33d22e1b-3cc9-4e47-afc3-130ff82a540e', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 2, 'start_page_index': 1, 'start_page_label': 2, 'end_page_index': 1, 'end_page_label': 2, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 5429, 'end_char_idx': 10941, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'alita-paper'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# 1 Introduction\\n\\n> \"Simplicity is the ultimate sophistication.\"  \\n> — Leonardo da Vinci\\n\\nLarge language models (LLMs) have rapidly evolved from merely generating text to autonomous agents capable of independently planning and executing complex tasks on behalf of users with limited human oversight [2]. These capabilities have enabled a wide range of applications, ranging from travel planning [3], computer use [4, 5, 6], to the multi-step research tasks [7]. To support such diverse and demanding tasks, a new class of systems called generalist agents has emerged. These agents are designed to handle a wide range of domains and tasks through a unified architecture, allowing them to generalize beyond task-specific solutions, such as OpenAI Deep Research [1] and Manus.\\n\\nHowever, most of the current general-purpose agents heavily rely on large-scale manual engineering, including tediously designed workflows, considerable pre-defined tools, and hardcoded components [8, 9]. This reliance introduces several critical limitations:  \\ni) It is impractical, if not impossible, to predefine all the tools required for the wide variety of real-world tasks an agent might encounter (*incomplete coverage*);  \\nii) Many complex tasks require agents to creatively compose new tools or leverage existing ones in novel ways while pre-designed workflow and hardcoded components constrain this compositional flexibility and inhibit the development of adaptive behaviors (*limited creativity and flexibility*);  \\niii) It is not always the case that the interface or environment of different tools are compatible with the agent (*mismatch*). For example, many useful tools are not written in Python, which makes it difficult, though not entirely impossible, for them to be pre-connected to the mainstream agent frameworks that are primarily written in Python. Together, these challenges ultimately hinder the scalability, adaptability, and generalization of existing generalist agents.\\n\\nIn contrast to the prevailing trend of growing complexity, we propose a radically simple design philosophy built on two principles:  \\ni) *Minimal Predefinition*: Equip the agent with only a minimal set of core capabilities, avoiding manually engineered components for specific tasks or modalities;  \\nii) *Maximal Self-Evolution*: Empower the agent to autonomously create, refine, and reuse external capabilities as needed. We instantiate this vision through Alita, a generalist agent built with a single core capability (i.e., the web agent) and a small set of general-purpose modules that enable self-directed capability expansion. Specifically, we take advantage of the Model Context Protocols (MCPs) [1] which is an open protocol that standardizes how different systems provide context to LLMs, and empower Alita to dynamically generate, adapt, and reuse MCPs based on the demands of each task rather than relying on static, predefined tools. This shift from manually designed capabilities to on-the-fly MCP construction unlocks a new path for building agents that are simple yet profoundly capable.\\n\\n<table>\\n<thead>\\n<tr>\\n  <th colspan=\"6\">Traditional Generalist Agents</th>\\n  <th></th>\\n  <th colspan=\"3\">Large-scale Manual Engineering</th>\\n  <th></th>\\n  <th colspan=\"3\">Alita (Ours)</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n  <td>Url Text Extractor</td>\\n  <td>URL TEXT</td>\\n  <td>Image Captioner</td>\\n  <td>Relevant Patch Zoomer</td>\\n  <td>Other Agents</td>\\n  <td>Youtube Caption Crawler</td>\\n  <td></td>\\n  <td>Incomplete Coverage</td>\\n  <td>Limited Creativity & Flexibility</td>\\n  <td>Mismatch</td>\\n  <td></td>\\n  <td>Web Agent</td>\\n  <td>Manager Agent</td>\\n  <td>MCP Creation</td>\\n</tr>\\n<tr>\\n  <td>Web Agent</td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td>Self Evolving</td>\\n  <td>MCP Box</td>\\n</tr>\\n<tr>\\n  <td>Path Generalist Classifier</td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td>Manager Agent</td>\\n  <td></td>\\n  <td></td>\\n  <td>Minimal Predefinition</td>\\n  <td></td>\\n  <td>Maximal Self-Evolution</td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n</tr>\\n<tr>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td>SELF-EVOLUTION</td>\\n  <td></td>\\n</tr>\\n<tr>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td></td>\\n  <td>Scalable Dynamic Capability</td>\\n  <td>Enhanced Creativity & Flexibility</td>\\n  <td colspan=\"2\">Cross-ecosystem Compatibility</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n**Figure 2:** Comparison between Traditional Generalist Agents and Alita. Traditional generalist agents heavily rely on large-scale manual engineering while Alita adheres to minimal predefinition and maximal self-evolution.\\n\\nWe conduct comprehensive experiments on several benchmarks to assess Alita in real-world applications, especially on the most popular GAIA [10]. Alita proves that simplicity is not a constraint, but a strength, and that creative agent behavior can emerge from a design that prioritizes autonomy over manual engineering. To sum up, our key contributions can be summarized as follows.\\n\\n* We propose a new agent architecture centered on minimal predefinition and maximal self-evolution, challenging conventional design norms in generalist agents, aiming to call for a more scalable and generalizable agent framework.\\n\\n----\\n\\n[1]: https://www.anthropic.com/news/model-context-protocol', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.54594),\n",
       " NodeWithScore(node=TextNode(id_='0a8ced32-cc9c-4e43-912d-c155d50d4fc3', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-13T02:06:25', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': '7f9959a9-84df-4234-b475-e11e1bda3db1', 'pipeline_id': '6e287db8-a658-48c2-837f-1e13c85edc84', 'page_label': 1, 'start_page_index': 0, 'start_page_label': 1, 'end_page_index': 0, 'end_page_label': 1, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 1, 'end_char_idx': 2707, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'alita-paper'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# ALITA: GENERALIST AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL SELF-EVOLUTION\\n\\nJiahao Qiu*¹, Xuan Qi*², Tongcheng Zhang*³, Xinzhe Juan³⁴, Jiacheng Guo¹, Yifu Lu¹, Yimin Wang³⁴, Zixin Yao¹,  \\nQihan Ren³, Xun Jiang⁵, Xing Zhou⁵, Dongrui Liu³, Ling Yang¹, Yue Wu¹, Kaixuan Huang¹, Shilong Liu¹,  \\nHongru Wang⁶, Mengdi Wang¹\\n\\n¹ AI Lab, Princeton University  \\n² IIIS, Tsinghua University  \\n³ Shanghai Jiao Tong University  \\n⁴ University of Michigan  \\n⁵ Tianqiao and Chrissy Chen Institute  \\n⁶ The Chinese University of Hong Kong\\n\\n<table>\\n<thead>\\n<tr>\\n<th colspan=\"4\">GAIA Benchmark</th>\\n</tr>\\n<tr>\\n<th></th>\\n<th>Alita</th>\\n<th>manus.ai</th>\\n<th>OpenAI DeepResearch</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Level 1</td>\\n<td>88.7%</td>\\n<td>86.5%</td>\\n<td>74.3%</td>\\n</tr>\\n<tr>\\n<td>Level 2</td>\\n<td>89.5%</td>\\n<td>70.1%</td>\\n<td>69.1%</td>\\n</tr>\\n<tr>\\n<td>Level 3</td>\\n<td>76.9%</td>\\n<td>57.7%</td>\\n<td>47.6%</td>\\n</tr>\\n<tr>\\n<td>Average</td>\\n<td>87.3%</td>\\n<td>73.3%</td>\\n<td>67.4%</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n> Figure 1: Performance of Alita, manus.ai, and OpenAI DeepResearch[1]\\n\\n## ABSTRACT\\n\\nRecent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce **Alita**—a generalist agent designed with the principle of *\"Simplicity is the ultimate sophistication,\"* enabling scalable agentic reasoning through **minimal predefinition** and **maximal self-evolution**. \\n\\nFor minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. \\n\\nFor *Maximal self-evolution*, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. \\n\\nNotably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at https://github.com/CharlesQ9/Alita.\\n\\n\\\\* These authors contributed equally to this work.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5383771)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c38ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-agents-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
