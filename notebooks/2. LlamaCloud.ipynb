{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0dbdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f91599c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Alita? How does it work?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c9c6b",
   "metadata": {},
   "source": [
    "## Ingesting documents into Llama Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54286449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "alita_index = LlamaCloudIndex(\n",
    "  name=\"alita-index\",\n",
    "  project_name=\"Default\",\n",
    "  organization_id=\"bf9b425c-54cb-4182-a93f-8ac6aed04348\",\n",
    "  api_key=os.environ.get(\"LLAMA_CLOUD_API_KEY\"),\n",
    ")\n",
    "\n",
    "nodes = alita_index.as_retriever().retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c51b1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='2c753523-8829-4ad7-b85e-b648f422f5ae', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 1, 'start_page_index': 0, 'start_page_label': 1, 'end_page_index': 0, 'end_page_label': 1, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 1, 'end_char_idx': 2846}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='arXiv:2505.20286v1 [cs.AI] 26 May 2025\\n\\n# ALITA: GENERALIST AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL SELF-EVOLUTION\\n\\n<table>\\n<thead>\\n<tr>\\n<th>Author Name</th>\\n<th>Affiliation</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Jiahao Qiu*<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Xuan Qi*<sup>2</sup></td>\\n<td>IIIS, Tsinghua University</td>\\n</tr>\\n<tr>\\n<td>Tongcheng Zhang*<sup>3</sup></td>\\n<td>Shanghai Jiao Tong University</td>\\n</tr>\\n<tr>\\n<td>Xinzhe Juan<sup>3,4</sup></td>\\n<td>Shanghai Jiao Tong University, University of Michigan</td>\\n</tr>\\n<tr>\\n<td>Jiacheng Guo<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Yifu Lu<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Yimin Wang<sup>3,4</sup></td>\\n<td>Shanghai Jiao Tong University, University of Michigan</td>\\n</tr>\\n<tr>\\n<td>Zixin Yao<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Qihan Ren<sup>3</sup></td>\\n<td>Shanghai Jiao Tong University</td>\\n</tr>\\n<tr>\\n<td>Xun Jiang<sup>5</sup></td>\\n<td>Tianqiao and Chrissy Chen Institute</td>\\n</tr>\\n<tr>\\n<td>Xing Zhou<sup>5</sup></td>\\n<td>Tianqiao and Chrissy Chen Institute</td>\\n</tr>\\n<tr>\\n<td>Dongrui Liu<sup>3</sup></td>\\n<td>Shanghai Jiao Tong University</td>\\n</tr>\\n<tr>\\n<td>Ling Yang<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Yue Wu<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Kaixuan Huang<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Shilong Liu<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n<tr>\\n<td>Hongru Wang<sup>6</sup></td>\\n<td>The Chinese University of Hong Kong</td>\\n</tr>\\n<tr>\\n<td>Mengdi Wang<sup>1</sup></td>\\n<td>AI Lab, Princeton University</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n## GAIA Benchmark\\n\\n<table>\\n<thead>\\n<tr>\\n<th>Level</th>\\n<th>Alita</th>\\n<th>manus.ai</th>\\n<th>OpenAI DeepResearch</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Level 1</td>\\n<td>88.7%</td>\\n<td>74.3%</td>\\n<td>86.5%</td>\\n</tr>\\n<tr>\\n<td>Level 2</td>\\n<td>89.5%</td>\\n<td>69.1%</td>\\n<td>70.1%</td>\\n</tr>\\n<tr>\\n<td>Level 3</td>\\n<td>76.9%</td>\\n<td>47.6%</td>\\n<td>57.7%</td>\\n</tr>\\n<tr>\\n<td>Average</td>\\n<td>87.3%</td>\\n<td>67.4%</td>\\n<td>73.3%</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nFigure 1: Performance of Alita, manus.ai, and OpenAI DeepResearch[1]\\n\\n## ABSTRACT\\n\\nRecent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita—a generalist agent designed with the principle of \"Simplicity is the ultimate sophistication,\" enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution.', mimetype='text/plain', start_char_idx=1, end_char_idx=2847, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8338803),\n",
       " NodeWithScore(node=TextNode(id_='c35f0a11-6235-472e-af32-99b3c2ae8421', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 1, 'start_page_index': 0, 'start_page_label': 1, 'end_page_index': 0, 'end_page_label': 1, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 2452, 'end_char_idx': 3894}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2c753523-8829-4ad7-b85e-b648f422f5ae', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 1}, hash='54839ae8c513067124938ecec5a87010d66bd4c8cafd5e15395cd177f3486922')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita—a generalist agent designed with the principle of \"Simplicity is the ultimate sophistication,\" enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. For Maximal self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at https://github.com/CharlesQ9/Alita.\\n\\n* These authors contributed equally to this work.', mimetype='text/plain', start_char_idx=2452, end_char_idx=3895, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.80126834),\n",
       " NodeWithScore(node=TextNode(id_='203850d5-b779-4c3e-81a7-7d7ef6412599', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 4, 'start_page_index': 3, 'start_page_label': 4, 'end_page_index': 3, 'end_page_label': 4, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 26493, 'end_char_idx': 30382}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1bdba247-a335-4ff9-872e-b8bb6a1de5b5', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 3}, hash='139c24376132d75e44a9923e3fcc6601e9d9a885767d714476a9c0ee62e8cc82')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# 3 Methods\\n\\nWe propose Alita, a generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal self-evolution to tackle diverse and complex tasks. Figure 3 illustrates the framework of Alita. In contrast to generalist agents that typically depend on extensive manually-designed tools and workflows [8, 9], the manager agent in Alita solely orchestrates the web agent using only basic tools. Through this approach, our framework enables Alita to plan task-specific tools through brainstorming. It then utilizes a Web Agent to search for helpful open-source libraries and other resources related to these tools. Leveraging the search results, Alita autonomously generates new tools and configures the necessary environments to enhance its capabilities and effectively solve tasks. During this process, if any issues arise with the newly generated tools or their environments, Alita can provide feedback and self-correct, improving the quality of the generated tools. Furthermore, the new tools can be encapsulated as MCP servers for future reuse. With the aid of MCPs, Alita can generate increasingly powerful, diverse, and complex MCPs, thus establishing a self-reinforcing cycle. Therefore, Alita autonomously expands its capabilities through continuous MCP integration.\\n\\n```mermaid\\nflowchart TD\\n    A[Question] --> B[Manager Agent]\\n    B <--> C[Web Agent]\\n    B --> D[MCP Brainstorming]\\n    D --> E[CodeReAct Loop]\\n    E --> F[Open-source Searching]\\n    E --> G[Script Generating]\\n    E --> H[Virtual Env Execution]\\n    F --> I[Encapsulate]\\n    G --> I\\n    H --> I\\n    I --> J[MCP Box]\\n    J --> K[Self Evolving]\\n    K --> B\\n    B --> L[Output]\\n```\\n\\nFigure 3: The architecture of Alita. Upon receiving a question, the Manager Agent initiates an iterative CodeReAct loop to analyze tasks, identify functional gaps, and trigger MCP Brainstorming for creative synthesis. The system dynamically performs open-source searching, script generation, and virtual environment execution to construct task-related functions. Useful ones are encapsulated into reusable MCPs and stored in the MCP Box. Throughout this process, the Manager Agent collaborates with the Web Agent for external information retrieval and continuously integrates intermediate results until a final output is produced. This process enables Alita to self-evolve without relying on a huge hand-crafted, elaborate tools and workflows.\\n\\n## 3.1 Execution Pipeline\\n\\nEach task commences with the construction of an augmented prompt that incorporates the original query. The manager agent (Sec. 3.2) then initiates a multi-step reasoning process to address the task at hand. Throughout this process, the agent may query external sources via the web agent (Sec. 3.3), plan and synthesize new tools (Sec. 3.4), and execute them within isolated environments (Sec. 3.4.4).\\n\\nUpon successful tool generation and accurate result formulation, the corresponding script is transformed into an MCP and stored in the internal tool registry for future reuse. All reasoning steps, intermediate code, and final outputs are systematically logged to facilitate comprehensive analysis.\\n\\n## 3.2 Manager Agent\\n\\nThe Manager Agent functions as the central coordinator within framework of Alita. When receiving a task prompt, the manager agent initially calls the MCP Brainstorming to determine whether additional tools are needed and which specific tools are required. Then the manager agent decomposes the task into subtasks and dispatches them to web agent or generates the required external tools to complete the subtask. When necessary, the manager agent utilizes the information retrieved by the web agent to generate the required new tools along with their corresponding environment configuration instructions. After collecting all intermediate results, the manager performs final aggregation and response formulation.\\n\\n4', mimetype='text/plain', start_char_idx=1, end_char_idx=3891, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7366474),\n",
       " NodeWithScore(node=TextNode(id_='1bdba247-a335-4ff9-872e-b8bb6a1de5b5', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 3, 'start_page_index': 2, 'start_page_label': 3, 'end_page_index': 2, 'end_page_label': 3, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 17226, 'end_char_idx': 21851}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0f146545-b3af-470e-8b39-57d35d7889af', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 2}, hash='f2842960bb2d79c11b589f7383db5c6527307654f23c40f658dbe32cba932d17')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"* We present Alita, a generalist agent that achieves scalable agentic reasoning with a radically simple design.\\n* We empirically demonstrate that Alita, despite using no complex predefined tools and workflows for specific tasks, outperforms many systems with significantly more handcrafted complexity on the GAIA benchmark. We achieve 75.15% pass@1 and 87.27% pass@3, surpassing OpenAI's Deep Research with 67.36% pass@1 and ranking top among all general-purpose agents.\\n\\n## 2 Related Works\\n\\n### 2.1 Generalist Agent\\n\\nThe concept of a Generalist Agent aims to construct an AI agent system capable of collaboratively completing a variety of complex tasks in a real-world environment. OWL [8] introduces a method that decomposes complex tasks into subtasks and dynamically allocates them to worker nodes with specialized toolkits. Omne [11] proposes a multi-agent collaborative development framework, where each agent possesses an independent system structure, enabling autonomous learning and the storage of a comprehensive world model to build an independent understanding of the environment. OpenAI Deep Research<sup>2</sup> employs reinforcement learning for training on real-world tasks, aiming to provide precise and reliable research reports for knowledge-intensive tasks. A-World [12] offers a highly configurable, modular, and scalable simulation environment, allowing developers to flexibly define and integrate different types of AI agents. The Magentic-One [13] framework merges the Magentic and Autogen systems, distinguishing between the micro-level LLM-driven function generation and the macro-level multi-agent orchestration, resulting in a clearer and more efficient construction of agent systems. Alita, also a Generalist Agent, allows for the minimal use of predefined tools and workflows for direct problem-solving, yet still achieves impressive performance across diverse tasks.\\n\\n### 2.2 Auto Generating Agent\\n\\nAuto-generating agents aim to enhance the versatility of agents by enabling them to autonomously generate tools, agents, or workflows tailored to specific tasks. AutoAgents [14], for instance, generate multiple agents, each playing a distinct role, to handle the corresponding subtasks. OpenHands [15] offers an event-driven architecture that allows agents to interact with the environment like human developers, thereby enabling the creation of custom workflows. AFlow [16] redefines workflow optimization as a search problem, where each workflow consists of several nodes invoking large LLMs, and the optimal workflow is identified and executed through a search process. AutoAgent [17], as an autonomous agent operating system, permits agents to manage system-level operations and file data autonomously. In Alita, agents are empowered to automatically generate diverse, specialized, and highly accurate MCPs to aid in the completion of specific tasks, while also providing resources for future executions.\\n\\n### 2.3 Tool Creation\\n\\nTool Creation enables agents to autonomously create tools to assist in task execution, either on their own or with external support. CRAFT [18] utilizes GPT-4 to generate a set of code snippets that function as tools, which are then retrieved and used in the system. TroVE [19] maintains a collection of high-level functions, which are automatically generated, extended, and periodically pruned to optimize program generation. CREATOR [20] decouples the abstraction of tool creation from the actual execution, allowing LLMs to address tasks at different levels of granularity. AutoAgent [17] enables agents to autonomously create new tools based on task requirements, incorporating information gathered through web searches and integrating these tools into their workflow. OpenHands [15] allows agents to create code scripts in a human-like manner during interaction with the environment to assist in task completion. In comparison, Alita enables MCP creation, which provides additional benefits, including better reusability and easy environment management over tool creation.\\n\\n### 2.4 MCP\\n\\nThe Model Context Protocol (MCP) is a standard proposed by Anthropic, designed to unify the connection between AI systems and external data sources and services. RAG-MCP [21] enhances the efficiency and accuracy of agents by retrieving the most relevant tools from a large collection, based on the task description, within the database composed of MCP descriptions. After tool generation, Alita wraps the generated valid tools into MCPs for subsequent use, facilitating reuse by itself and other agents.\\n\\n<sup>2</sup>https://openai.com/index/introducing-deep-research/\\n\\n3\", mimetype='text/plain', start_char_idx=2, end_char_idx=4628, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7327644),\n",
       " NodeWithScore(node=TextNode(id_='0f146545-b3af-470e-8b39-57d35d7889af', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 2, 'start_page_index': 1, 'start_page_label': 2, 'end_page_index': 1, 'end_page_label': 2, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 7801, 'end_char_idx': 12505}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c35f0a11-6235-472e-af32-99b3c2ae8421', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 1}, hash='e9edaa9a6f3ed724e359e5a68c9e33dbc601a1333c3718ae04d95b459c555624')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# 1 Introduction\\n\\n> \"Simplicity is the ultimate sophistication.\" — Leonardo da Vinci\\n\\nLarge language models (LLMs) have rapidly evolved from merely generating text to autonomous agents capable of independently planning and executing complex tasks on behalf of users with limited human oversight [2]. These capabilities have enabled a wide range of applications, ranging from travel planning [3], computer use [4, 5, 6], to the multi-step research tasks [7]. To support such diverse and demanding tasks, a new class of systems called generalist agents has emerged. These agents are designed to handle a wide range of domains and tasks through a unified architecture, allowing them to generalize beyond task-specific solutions, such as OpenAI Deep Research [1] and Manus.\\n\\nHowever, most of the current general-purpose agents heavily rely on large-scale manual engineering, including tediously designed workflows, considerable pre-defined tools, and hardcoded components [8, 9]. This reliance introduces several critical limitations: i) It is impractical, if not impossible, to predefine all the tools required for the wide variety of real-world tasks an agent might encounter (incomplete coverage); ii) Many complex tasks require agents to creatively compose new tools or leverage existing ones in novel ways while pre-designed workflow and hardcoded components constrain this compositional flexibility and inhibit the development of adaptive behaviors (limited creativity and flexibility); iii) It is not always the case that the interface or environment of different tools are compatible with the agent (mismatch). For example, many useful tools are not written in Python, which makes it difficult, though not entirely impossible, for them to be pre-connected to the mainstream agent frameworks that are primarily written in Python. Together, these challenges ultimately hinder the scalability, adaptability, and generalization of existing generalist agents.\\n\\nIn contrast to the prevailing trend of growing complexity, we propose a radically simple design philosophy built on two principles: i) Minimal Predefinition: Equip the agent with only a minimal set of core capabilities, avoiding manually engineered components for specific tasks or modalities; ii) Maximal Self-Evolution: Empower the agent to autonomously create, refine, and reuse external capabilities as needed. We instantiate this vision through Alita, a generalist agent built with a single core capability (i.e., the web agent) and a small set of general-purpose modules that enable self-directed capability expansion. Specifically, we take advantage of the Model Context Protocols (MCPs)<sup>1</sup> which is an open protocol that standardizes how different systems provide context to LLMs, and empower Alita to dynamically generate, adapt, and reuse MCPs based on the demands of each task rather than relying on static, predefined tools. This shift from manually designed capabilities to on-the-fly MCP construction unlocks a new path for building agents that are simple yet profoundly capable.\\n\\n<table>\\n<thead>\\n<tr>\\n<th>Agent Type</th>\\n<th>Components</th>\\n<th>Approach</th>\\n<th>Characteristics</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Traditional Generalist Agents</td>\\n<td>Url Text Extractor, Web Agent, Path Generalist Classifier, Image Captioner, Relevant Patch Zoomer, Other Agents, Manager Agent, Youtube Caption Crawler</td>\\n<td>Large-scale Manual Engineering</td>\\n<td>Incomplete Coverage, Limited Creativity & Flexibility, Mismatch</td>\\n</tr>\\n<tr>\\n<td>Alita (Ours)</td>\\n<td>Web Agent, Manager Agent</td>\\n<td>Minimal Predefinition → MCP Creation → Self Evolving → MCP Box → Maximal Self-Evolution</td>\\n<td>Scalable Dynamic Capability, Enhanced Creativity & Flexibility, Cross-ecosystem Compatibility</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nFigure 2: Comparison between Traditional Generalist Agents and Alita. Traditional generalist agents heavily rely on large-scale manual engineering while Alita adheres to minimal predefinition and maximal self-evolution.\\n\\nWe conduct comprehensive experiments on several benchmarks to assess Alita in real-world applications, especially on the most popular GAIA [10]. Alita proves that simplicity is not a constraint, but a strength, and that creative agent behavior can emerge from a design that prioritizes autonomy over manual engineering. To sum up, our key contributions can be summarized as follows.\\n\\n• We propose a new agent architecture centered on minimal predefinition and maximal self-evolution, challenging conventional design norms in generalist agents, aiming to call for a more scalable and generalizable agent framework.\\n\\n<sup>1</sup>https://www.anthropic.com/news/model-context-protocol\\n\\n2', mimetype='text/plain', start_char_idx=1, end_char_idx=4706, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7206637),\n",
       " NodeWithScore(node=TextNode(id_='c8acfed6-c282-4778-a819-4a8317ce79c5', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 9, 'start_page_index': 8, 'start_page_label': 9, 'end_page_index': 8, 'end_page_label': 9, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 69886, 'end_char_idx': 71582}, excluded_embed_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], excluded_llm_metadata_keys=['file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'file_id', 'pipeline_file_id', 'id', 'file_size', 'last_modified_at', 'start_page_index', 'start_page_label', 'page_label', 'end_page_index', 'end_page_label', 'document_id', 'file_id', 'pipeline_file_id'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', node_type='4', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e'}, hash='76cd6f7819a71d4fb8109194b8946cd92baf1c69dad5b248f48391d4bfb6cc60'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d90db199-6b8a-4bb4-b591-b0a427b8dbee', node_type='1', metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 8}, hash='642087e1ccc06e93d8eddafc9fb20d77bff72fa00561c8db8486b411a150a1fa')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"<table>\\n<thead>\\n<tr>\\n<th>Model Configuration</th>\\n<th>Level 1</th>\\n<th>Level 2</th>\\n<th>Level 3</th>\\n<th>Total</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Alita (Claude-3.7-Sonnet, GPT-4o)</td>\\n<td>81.13%</td>\\n<td>75.58%</td>\\n<td>46.15%</td>\\n<td>72.73%</td>\\n</tr>\\n<tr>\\n<td>Alita (GPT-4o-mini)</td>\\n<td>54.72%</td>\\n<td>44.19%</td>\\n<td>19.23%</td>\\n<td>43.64%</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nTable 4: Comparison of performance between Alita(Claude-3.7-Sonnet,GPT-4o) and Alita(GPT-4o-mini). The results are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the performance at the respective GAIA levels. The integration of a smaller model significantly reduces the performance.\\n\\n### 5.3 Case Study\\n\\nTo investigate Alita's workflow when tackling tasks, we conducted a case study on its approach to solving a Level 3 difficult problem in GAIA. The details of this process are presented in Appendix A. From the case study, we observe that Alita is able to perform a structured MCP brainstorming session based on the task at hand, effectively identifying and utilizing relevant resources to implement a feasible MCP that aids in completing the task.\\n\\n## 6 Conclusion\\n\\nIn this work, we introduced Alita, a generalist agent designed with the principles of minimal predefinition and maximal self-evolution. By significantly reducing reliance on manually predefined tools and workflows for direct solving, Alita leverages creative, autonomous capabilities in real time, facilitating scalable agentic reasoning. Our approach demonstrates that simplicity in design does not undermine, but rather enhances, the performance and adaptability of generalist agents.\\n\\n9\", mimetype='text/plain', start_char_idx=2, end_char_idx=1699, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.638588)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b798f4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Response:** \n",
       "\n",
       "Alita is a generalist agent designed to enable scalable agentic reasoning through minimal reliance on predefined tools and workflows, prioritizing simplicity and autonomous capability development. It functions by utilizing a Manager Agent to orchestrate task execution, which leverages a Web Agent to identify and dynamically generate task-specific tools. These tools are systematically encapsulated as Model Context Protocols (MCPs), creating reusable components that can be adapted for diverse applications. The process involves iterative refinement of these MCPs, allowing Alita to autonomously expand its functional scope while ensuring compatibility across different environments. This approach minimizes manual intervention and enhances adaptability, enabling efficient problem-solving across complex tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "llm = OpenAILike(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    api_key=os.getenv(\"BENTO_CLOUD_API_KEY\"),\n",
    "    api_base=f'{os.getenv(\"qwen3_endpoint_url\")}/v1',\n",
    "    is_chat_model=True,\n",
    "    is_function_calling_model=True,\n",
    "    temperature=0,\n",
    "    timeout=600,\n",
    ")\n",
    "alita_query_engine = alita_index.as_query_engine(llm=llm)\n",
    "response = alita_query_engine.query(query)\n",
    "\n",
    "display(Markdown(f\"**Response:** {response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61dc8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_zero_index = LlamaCloudIndex(\n",
    "  name=\"mcp-zero-index\",\n",
    "  project_name=\"Default\",\n",
    "  organization_id=\"bf9b425c-54cb-4182-a93f-8ac6aed04348\",\n",
    "  api_key=os.environ.get(\"LLAMA_CLOUD_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc41bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_zero_engine = mcp_zero_index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a466aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82 ms, sys: 5.1 ms, total: 87.1 ms\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = mcp_zero_engine.query(\"What is MCP zero and how does it work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcec778c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Response:** \n",
       "\n",
       "MCP-Zero is a framework designed to enhance the autonomy of large language models (LLMs) by enabling them to dynamically identify and request tools based on task requirements, rather than relying on pre-defined schemas. This approach reduces context overhead and promotes active decision-making through a structured, iterative process.  \n",
       "\n",
       "The framework operates through three core mechanisms:  \n",
       "1. **Active Tool Request**: LLMs are prompted with system instructions to explicitly declare missing capabilities, such as emitting a `<tool_assistant>` block specifying required server domains and tool operations. This ensures alignment between task needs and available resources.  \n",
       "2. **Hierarchical Semantic Routing**: A lightweight tool index, curated with metadata and vectorized embeddings (e.g., using text-embedding-3-large), enables precise matching of tool descriptions to model-generated requests. This involves filtering candidate servers and ranking tools by semantic similarity to optimize retrieval efficiency.  \n",
       "3. **Iterative Capability Extension**: During task execution, agents dynamically refine tool selections by leveraging retrieved JSON-schemas, adapting to incomplete or insufficient initial choices. This allows for adaptive, fault-tolerant problem-solving across domains.  \n",
       "\n",
       "By integrating these steps, MCP-Zero minimizes context overhead, improves scalability, and maintains high accuracy in multi-turn interactions, empowering LLMs to autonomously shape their operational environment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"**Response:** {response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65bac49",
   "metadata": {},
   "source": [
    "## Composite retrieval\n",
    "Not recommended. It's better to break the question into sub parts and query the correct index with each part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "643b2c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Retriever(name='Alita and MCP Zero Retriever', pipelines=[RetrieverPipeline(name='alita-index', description='Knowledge base for the Alita paradigm for agents', pipeline_id='e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', preset_retrieval_parameters=PresetRetrievalParams(dense_similarity_top_k=30, dense_similarity_cutoff=0.0, sparse_similarity_top_k=30, enable_reranking=True, rerank_top_n=6, alpha=0.5, search_filters=None, search_filters_inference_schema=None, files_top_k=1, retrieval_mode=<RetrievalMode.CHUNKS: 'chunks'>, retrieve_image_nodes=False, retrieve_page_screenshot_nodes=False, retrieve_page_figure_nodes=False, class_name='base_component')), RetrieverPipeline(name='mcp-zero-index', description='Knowledge base of the (model context protocol) MCP zero paradigm', pipeline_id='a8f66184-b5e1-487d-a65f-3a78c5b4ae1d', preset_retrieval_parameters=PresetRetrievalParams(dense_similarity_top_k=30, dense_similarity_cutoff=0.0, sparse_similarity_top_k=30, enable_reranking=True, rerank_top_n=6, alpha=0.5, search_filters=None, search_filters_inference_schema=None, files_top_k=1, retrieval_mode=<RetrievalMode.CHUNKS: 'chunks'>, retrieve_image_nodes=False, retrieve_page_screenshot_nodes=False, retrieve_page_figure_nodes=False, class_name='base_component'))], id='d2c4add1-f4cb-41a0-bcfd-58dac5293769', created_at=datetime.datetime(2025, 8, 13, 2, 38, 0, 856052, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 8, 26, 14, 17, 53, 596305, tzinfo=datetime.timezone.utc), project_id='6bdb9346-fa87-4a33-a621-f595ccbb5986')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_cloud import CompositeRetrievalMode\n",
    "from llama_index.indices.managed.llama_cloud import (\n",
    "    LlamaCloudCompositeRetriever,\n",
    ")\n",
    "\n",
    "retriever = LlamaCloudCompositeRetriever(\n",
    "    name=\"Alita and MCP Zero Retriever\",\n",
    "    api_key=os.environ.get(\"LLAMA_CLOUD_API_KEY\"),\n",
    "    create_if_not_exists=True,\n",
    "    mode=CompositeRetrievalMode.FULL,\n",
    "    rerank_top_n=6,\n",
    ")\n",
    "retriever.add_index(\n",
    "    alita_index, description=\"Knowledge base for the Alita paradigm for agents\"\n",
    ")\n",
    "retriever.add_index(\n",
    "    mcp_zero_index, description=\"Knowledge base of the (model context protocol) MCP zero paradigm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "760496fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='5d413f8a-3005-45cc-b098-42fd1d4d1179', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-24T05:20:20', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '7e975483-54a7-4e46-ac11-74045fc733ee', 'pipeline_id': 'a8f66184-b5e1-487d-a65f-3a78c5b4ae1d', 'page_label': 10, 'start_page_index': 9, 'start_page_label': 10, 'end_page_index': 9, 'end_page_label': 10, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 89466, 'end_char_idx': 93609, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'mcp-zero-index'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='2. **Semantic grounding.** The example also clarifies the meaning of each field, helping the model understand the specific definitions of MCP server and tool, thereby limiting its expression scope. After seeing this, the model reliably emits phrases such as `filesystem_read` instead of a vague \"read the file\", sharply reducing semantic mismatch.\\n\\nIn short, a tiny demonstration patch acts as a schema anchor; future work could replace ICL with a short grammar-based decoder rule, but the one-shot approach is free and highly effective.\\n\\n**Multi-Agent Orchestration.** MCP-Zero\\'s active discovery approach could enable better multi-agent collaboration. Future work could investigate how different agents can automatically discover and share tools with each other, allowing them to work together more effectively on complex tasks that require diverse capabilities.\\n\\n## 7.3. Synergy with Alita: Using and Making Tools\\n\\nConcurrently, Alita [22] proposes a united manager agent that creates its own toolchain: it web-searches for code, clones GitHub repos, builds environments, and executes the resulting programs to accomplish tasks. We were pleasantly surprised by the contribution of this article, and found that the two lines of work are complementary:\\n\\n• MCP-Zero: efficiently finds and invokes existing tools\\n• Alita: automatically builds missing tools on-the-fly\\n\\nMCP-Zero and Alita address complementary halves of the same problem: the former maximises tool discovery while the latter maximises tool creation. When combined, they form a virtuous loop: an agent first actively discover tools from all available resources; if none fits, it switches to Alita\\'s workflow to synthesize a new one, then registers the freshly built tool for the community. We believe such a pipeline is a compelling direction toward self-evolving, cost-aware agentic AI systems.\\n\\n## 7.4. Future Work\\n\\nWhile MCP-Zero demonstrates significant improvements in tool retrieval efficiency and accuracy, several promising directions warrant further investigation:\\n\\n**Enhanced Experimental Validation.** Future work should expand evaluation across diverse domains. We plan to conduct comprehensive experiments on additional datasets to validate generalizability.\\n\\n**Advanced Matching Algorithms.** The current semantic similarity approach could be enhanced. We envision incorporating multi-modal descriptions (e.g., code examples, usage patterns, parameter schemas) into the retrieval process, and exploring usage co-occurrence patterns for improved contextual understanding.\\n\\n**MCP Server Implementation.** A natural extension involves packaging MCP-Zero as a dedicated MCP server providing tool discovery services. This \"meta-server\" would expose standardized APIs for active tool retrieval, enabling seamless integration into existing MCP ecosystems and serving as a centralized discovery hub for distributed tool collections.\\n\\n## References\\n\\n[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. 2\\n\\n[2] Anthropic. Model context protocol. https://docs.anthropic.com/en/docs/agents-and-tools/mcp, 2024. Accessed: June 25, 2025. 4\\n\\n[3] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. Improving language models by retrieving from trillions of tokens. In International conference on machine learning, pages 2206–2240. PMLR, 2022. 3\\n\\n[4] Harrison Chase. Langchain. https://github.com/langchain-ai/langchain, 2022. Python framework for developing applications powered by language models. 3\\n\\n[5] Yanfei Chen, Jinsung Yoon, Devendra Singh Sachan, Qingze Wang, Vincent Cohen-Addad, Mohammadhossein Bateni, Chen-Yu Lee, and Tomas Pfister. Re-invoke: Tool invocation rewriting for zero-shot tool retrieval. arXiv preprint arXiv:2408.01875, 2024. 3\\n\\n[6] Yu Du, Fangyun Wei, and Hongyang Zhang. Anytool: Self-reflective, hierarchical agents for large-scale api calls.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7760977),\n",
       " NodeWithScore(node=TextNode(id_='d781a3c5-d993-44b2-8c15-6ba6eca2dbed', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-24T05:20:20', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '7e975483-54a7-4e46-ac11-74045fc733ee', 'pipeline_id': 'a8f66184-b5e1-487d-a65f-3a78c5b4ae1d', 'page_label': 9, 'start_page_index': 8, 'start_page_label': 9, 'end_page_index': 8, 'end_page_label': 9, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 79220, 'end_char_idx': 83823, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'mcp-zero-index'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='• **Extreme Context Efficiency.** MCP-Zero cuts prompt length by 60–98% across all settings (e.g. 111 vs. 6.3k tokens in the full single-turn case), validating its ability to \"pay for tools only when they are needed\".\\n\\n• **Robust Scalability.** When moving from a hand-curated Domain subset to the Full tool pool (40x more APIs), standard schema-injection accuracy on Claude-3.5 plummets from 97.60 to 69.23 (single-turn) and 100.00 to 60.22 (multi-turn); MCP-Zero instead keeps accuracy at 95.19 / 90.32 respectively, demonstrating strong resilience to attention dilution.\\n\\n• **Multi-turn Consistency.** MCP-Zero maintains high accuracy over conversation rounds (≤3% drop from single- to multi-turn), whereas standard methods degrade sharply once the context accumulates previous calls and larger tool sets.\\n\\n• **Necessity of Active Requests.** Pure query-retrieval baselines stall at 65–72 % accuracy, confirming that letting the model author semantically aligned requests is crucial.\\n\\nExperiments on APIBank corroborate our claims: MCP-Zero delivers near-optimal or superior tool-selection accuracy while slashing context usage by up to two orders of magnitude, remaining robust in both single- and multi-turn conversations and under massive tool-pool scaling. These results highlight active, iterative tool discovery as a practical path toward scalable, cost-efficient agent systems.\\n\\n## 6. Conclusion\\n\\nThis work establishes active tool discovery as a fundamental paradigm for autonomous agent systems, enabling models to maintain decision autonomy while addressing critical scalability challenges in tool-calling architectures. MCP-Zero demonstrates that shifting from passive tool consumption to agent-driven capability acquisition achieves substantial efficiency gains—98% token reduction with preserved accuracy—while restoring the core principle of autonomous agency: the ability to assess limitations and actively acquire necessary resources. Our theoretical framework, empirical validation, and the MCP-tools dataset provide both the foundation and infrastructure for advancing autonomous agent architectures as tool ecosystems continue expanding exponentially.\\n\\n## 7. Discussion\\n\\nIn this section we reflect on how the MCP-Zero paradigm can be adopted by other researchers (§7.1), analyse the surprisingly gain from a single in–context example (§7.2), and position MCP-Zero with respect to the contemporaneous Alita system, outlining a promising path toward self-improving agentic AI (§7.3).\\n\\n### 7.1. Cookbook: Integrate MCP-Zero Into Agent\\n\\nMCP-Zero is fundamentally a simple yet effective approach that we hope will benefit the broader MCP community. The core methodology distills into three straightforward steps: prompting models to actively request tools, maintaining a lightweight tool index with semantic descriptions, and leveraging the improved semantic alignment for high-precision retrieval. Below we provide a practical guide for integrating these ideas into existing agent frameworks.\\n\\n**Step 1 – Prompting the LLM to ask for tools.** Give the model an explicit \"permission\" to declare missing capabilities. In practice this is a system instruction such as:\\n\\n```\\nIf the current task cannot be solved with your\\nown knowledge, emit a <tool_assistant> block\\nspecifying the server domain and the tool\\noperation you require.\\n```\\n\\nIn addition, the output structure needs to be specified as we mentioned in Section 3.1. This step aims to stimulate the model\\'s ability to \"actively\" propose requirements.\\n\\n**Step 2 – Curate a lightweight MCP-style tool index.**\\nFirstly, choose a scope based on your needs: the entire MCP-tools collection, a vertical slice (e.g. databases only), or your in-house APIs. Then, for every server/tool:\\n• extract the name and description from metadata;\\n• optionally let a strong LLM generate an enhanced summary that emphasises capabilities and usage patterns;\\n• store all texts in a vector store with pre-computed embeddings such as text-embedding-3-large.\\n\\n**Step 3 – Marry model output and retrieval.**\\nWhen the agent emits a `<tool_assistant>` block:\\n• Match the server field against server descriptions and summaries; take top-m candidates.\\n• Within each candidate server, rank tools by the tool field with the tool description embeddings.\\n• Feed the best (or top-k) JSON-schemas back to the LLM.\\n\\nBecause the request text is already semantically aligned with the documents, retrieval precision is higher than \"user query → API doc\" matching, maintaining performances while significantly conserving context.\\n\\n### 7.2. Why Does a Single ICL Example Help?', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.68723184),\n",
       " NodeWithScore(node=TextNode(id_='5c68fd81-559a-4ac5-8735-14846e66a1ad', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 3, 'start_page_index': 2, 'start_page_label': 3, 'end_page_index': 2, 'end_page_label': 3, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 17226, 'end_char_idx': 21851, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'alita-index'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"* We present Alita, a generalist agent that achieves scalable agentic reasoning with a radically simple design.\\n* We empirically demonstrate that Alita, despite using no complex predefined tools and workflows for specific tasks, outperforms many systems with significantly more handcrafted complexity on the GAIA benchmark. We achieve 75.15% pass@1 and 87.27% pass@3, surpassing OpenAI's Deep Research with 67.36% pass@1 and ranking top among all general-purpose agents.\\n\\n## 2 Related Works\\n\\n### 2.1 Generalist Agent\\n\\nThe concept of a Generalist Agent aims to construct an AI agent system capable of collaboratively completing a variety of complex tasks in a real-world environment. OWL [8] introduces a method that decomposes complex tasks into subtasks and dynamically allocates them to worker nodes with specialized toolkits. Omne [11] proposes a multi-agent collaborative development framework, where each agent possesses an independent system structure, enabling autonomous learning and the storage of a comprehensive world model to build an independent understanding of the environment. OpenAI Deep Research<sup>2</sup> employs reinforcement learning for training on real-world tasks, aiming to provide precise and reliable research reports for knowledge-intensive tasks. A-World [12] offers a highly configurable, modular, and scalable simulation environment, allowing developers to flexibly define and integrate different types of AI agents. The Magentic-One [13] framework merges the Magentic and Autogen systems, distinguishing between the micro-level LLM-driven function generation and the macro-level multi-agent orchestration, resulting in a clearer and more efficient construction of agent systems. Alita, also a Generalist Agent, allows for the minimal use of predefined tools and workflows for direct problem-solving, yet still achieves impressive performance across diverse tasks.\\n\\n### 2.2 Auto Generating Agent\\n\\nAuto-generating agents aim to enhance the versatility of agents by enabling them to autonomously generate tools, agents, or workflows tailored to specific tasks. AutoAgents [14], for instance, generate multiple agents, each playing a distinct role, to handle the corresponding subtasks. OpenHands [15] offers an event-driven architecture that allows agents to interact with the environment like human developers, thereby enabling the creation of custom workflows. AFlow [16] redefines workflow optimization as a search problem, where each workflow consists of several nodes invoking large LLMs, and the optimal workflow is identified and executed through a search process. AutoAgent [17], as an autonomous agent operating system, permits agents to manage system-level operations and file data autonomously. In Alita, agents are empowered to automatically generate diverse, specialized, and highly accurate MCPs to aid in the completion of specific tasks, while also providing resources for future executions.\\n\\n### 2.3 Tool Creation\\n\\nTool Creation enables agents to autonomously create tools to assist in task execution, either on their own or with external support. CRAFT [18] utilizes GPT-4 to generate a set of code snippets that function as tools, which are then retrieved and used in the system. TroVE [19] maintains a collection of high-level functions, which are automatically generated, extended, and periodically pruned to optimize program generation. CREATOR [20] decouples the abstraction of tool creation from the actual execution, allowing LLMs to address tasks at different levels of granularity. AutoAgent [17] enables agents to autonomously create new tools based on task requirements, incorporating information gathered through web searches and integrating these tools into their workflow. OpenHands [15] allows agents to create code scripts in a human-like manner during interaction with the environment to assist in task completion. In comparison, Alita enables MCP creation, which provides additional benefits, including better reusability and easy environment management over tool creation.\\n\\n### 2.4 MCP\\n\\nThe Model Context Protocol (MCP) is a standard proposed by Anthropic, designed to unify the connection between AI systems and external data sources and services. RAG-MCP [21] enhances the efficiency and accuracy of agents by retrieving the most relevant tools from a large collection, based on the task description, within the database composed of MCP descriptions. After tool generation, Alita wraps the generated valid tools into MCPs for subsequent use, facilitating reuse by itself and other agents.\\n\\n<sup>2</sup>https://openai.com/index/introducing-deep-research/\\n\\n3\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.57837737),\n",
       " NodeWithScore(node=TextNode(id_='3f09cba4-f1b0-490e-82bd-6f557820b593', embedding=None, metadata={'id': 'alita_paper.pdf', 'file_size': 1113373, 'last_modified_at': '2025-08-24T05:14:27', 'file_path': 'alita_paper.pdf', 'file_name': 'alita_paper.pdf', 'external_file_id': 'alita_paper.pdf', 'file_id': 'bcee7eb9-6479-46a6-9122-fd5b454699ef', 'pipeline_file_id': 'd149ed00-0d38-4815-a641-d388a45063aa', 'pipeline_id': 'e4c3c794-6d8a-450a-b3b3-2d1dee470c2e', 'page_label': 2, 'start_page_index': 1, 'start_page_label': 2, 'end_page_index': 1, 'end_page_label': 2, 'document_id': 'c9f76edb0a0d2f097f23ba53edef10f99a6924dfccb183a929', 'start_char_idx': 7801, 'end_char_idx': 12505, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'alita-index'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='# 1 Introduction\\n\\n> \"Simplicity is the ultimate sophistication.\" — Leonardo da Vinci\\n\\nLarge language models (LLMs) have rapidly evolved from merely generating text to autonomous agents capable of independently planning and executing complex tasks on behalf of users with limited human oversight [2]. These capabilities have enabled a wide range of applications, ranging from travel planning [3], computer use [4, 5, 6], to the multi-step research tasks [7]. To support such diverse and demanding tasks, a new class of systems called generalist agents has emerged. These agents are designed to handle a wide range of domains and tasks through a unified architecture, allowing them to generalize beyond task-specific solutions, such as OpenAI Deep Research [1] and Manus.\\n\\nHowever, most of the current general-purpose agents heavily rely on large-scale manual engineering, including tediously designed workflows, considerable pre-defined tools, and hardcoded components [8, 9]. This reliance introduces several critical limitations: i) It is impractical, if not impossible, to predefine all the tools required for the wide variety of real-world tasks an agent might encounter (incomplete coverage); ii) Many complex tasks require agents to creatively compose new tools or leverage existing ones in novel ways while pre-designed workflow and hardcoded components constrain this compositional flexibility and inhibit the development of adaptive behaviors (limited creativity and flexibility); iii) It is not always the case that the interface or environment of different tools are compatible with the agent (mismatch). For example, many useful tools are not written in Python, which makes it difficult, though not entirely impossible, for them to be pre-connected to the mainstream agent frameworks that are primarily written in Python. Together, these challenges ultimately hinder the scalability, adaptability, and generalization of existing generalist agents.\\n\\nIn contrast to the prevailing trend of growing complexity, we propose a radically simple design philosophy built on two principles: i) Minimal Predefinition: Equip the agent with only a minimal set of core capabilities, avoiding manually engineered components for specific tasks or modalities; ii) Maximal Self-Evolution: Empower the agent to autonomously create, refine, and reuse external capabilities as needed. We instantiate this vision through Alita, a generalist agent built with a single core capability (i.e., the web agent) and a small set of general-purpose modules that enable self-directed capability expansion. Specifically, we take advantage of the Model Context Protocols (MCPs)<sup>1</sup> which is an open protocol that standardizes how different systems provide context to LLMs, and empower Alita to dynamically generate, adapt, and reuse MCPs based on the demands of each task rather than relying on static, predefined tools. This shift from manually designed capabilities to on-the-fly MCP construction unlocks a new path for building agents that are simple yet profoundly capable.\\n\\n<table>\\n<thead>\\n<tr>\\n<th>Agent Type</th>\\n<th>Components</th>\\n<th>Approach</th>\\n<th>Characteristics</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Traditional Generalist Agents</td>\\n<td>Url Text Extractor, Web Agent, Path Generalist Classifier, Image Captioner, Relevant Patch Zoomer, Other Agents, Manager Agent, Youtube Caption Crawler</td>\\n<td>Large-scale Manual Engineering</td>\\n<td>Incomplete Coverage, Limited Creativity & Flexibility, Mismatch</td>\\n</tr>\\n<tr>\\n<td>Alita (Ours)</td>\\n<td>Web Agent, Manager Agent</td>\\n<td>Minimal Predefinition → MCP Creation → Self Evolving → MCP Box → Maximal Self-Evolution</td>\\n<td>Scalable Dynamic Capability, Enhanced Creativity & Flexibility, Cross-ecosystem Compatibility</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nFigure 2: Comparison between Traditional Generalist Agents and Alita. Traditional generalist agents heavily rely on large-scale manual engineering while Alita adheres to minimal predefinition and maximal self-evolution.\\n\\nWe conduct comprehensive experiments on several benchmarks to assess Alita in real-world applications, especially on the most popular GAIA [10]. Alita proves that simplicity is not a constraint, but a strength, and that creative agent behavior can emerge from a design that prioritizes autonomy over manual engineering. To sum up, our key contributions can be summarized as follows.\\n\\n• We propose a new agent architecture centered on minimal predefinition and maximal self-evolution, challenging conventional design norms in generalist agents, aiming to call for a more scalable and generalizable agent framework.\\n\\n<sup>1</sup>https://www.anthropic.com/news/model-context-protocol\\n\\n2', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.50886196),\n",
       " NodeWithScore(node=TextNode(id_='44b791bd-f69c-4da8-8af0-7e7bf928e245', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-24T05:20:20', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '7e975483-54a7-4e46-ac11-74045fc733ee', 'pipeline_id': 'a8f66184-b5e1-487d-a65f-3a78c5b4ae1d', 'page_label': 11, 'start_page_index': 10, 'start_page_label': 11, 'end_page_index': 10, 'end_page_label': 11, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 102167, 'end_char_idx': 104870, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'mcp-zero-index'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='ACM Computing Surveys, 57(4):1–40, 2024. 2\\n\\n[22] Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, et al. Alita: Generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal self-evolution. arXiv preprint arXiv:2505.20286, 2025. 10\\n\\n[23] Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, and Ji-Rong Wen. Colt: Towards completeness-oriented tool retrieval for large language models. arXiv e-prints, pages arXiv–2405, 2024. 3\\n\\n[24] Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report, 2025. 7\\n\\n[25] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. In-context retrieval-augmented language models. Transactions of the Association for Computational Linguistics, 11:1316–1331, 2023. 3\\n\\n[26] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems, 36:68539–68551, 2023. 2, 3\\n\\n[27] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face. Advances in Neural Information Processing Systems, 36:38154–38180, 2023. 3\\n\\n[28] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, Boxi Cao, and Le Sun. Toolalpaca: Generalized tool learning for language models with 3000 simulated cases. arXiv preprint arXiv:2306.05301, 2023. 8\\n\\n[29] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, et al. Autogen: Enabling next-gen llm applications via multi-agent conversation. arXiv preprint arXiv:2308.08155, 2023. 3\\n\\n[30] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025. 2\\n\\n[31] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.507544),\n",
       " NodeWithScore(node=TextNode(id_='a60b5937-0ab8-4615-841e-4baeb9e3c9f6', embedding=None, metadata={'id': 'mcp_zero_paper.pdf', 'file_size': 975244, 'last_modified_at': '2025-08-24T05:20:20', 'file_path': 'mcp_zero_paper.pdf', 'file_name': 'mcp_zero_paper.pdf', 'external_file_id': 'mcp_zero_paper.pdf', 'file_id': '99275b01-66e2-4f31-9b1c-914c3916ba5d', 'pipeline_file_id': '7e975483-54a7-4e46-ac11-74045fc733ee', 'pipeline_id': 'a8f66184-b5e1-487d-a65f-3a78c5b4ae1d', 'page_label': 11, 'start_page_index': 10, 'start_page_label': 11, 'end_page_index': 10, 'end_page_label': 11, 'document_id': '2e13a37a379d317a1af0a61b9d831caed3d655a04d32d55bc9', 'start_char_idx': 99980, 'end_char_idx': 102723, 'retriever_id': 'd2c4add1-f4cb-41a0-bcfd-58dac5293769', 'retriever_pipeline_name': 'mcp-zero-index'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='11\\n\\n[12] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. arXiv preprint arXiv:2304.08244, 2023. 8\\n\\n[13] Zhiling Luo, Xiaorong Shi, Xuanrui Lin, and Jinyang Gao. Evaluation report on mcp servers. arXiv preprint arXiv:2504.11094, 2025. 3, 6, 7\\n\\n[14] Tula Masterman, Sandi Besen, Mason Sawtell, and Alex Chao. The landscape of emerging ai agent architectures for reasoning, planning, and tool calling: A survey. arXiv preprint arXiv:2404.11584, 2024. 2\\n\\n[15] Suhong Moon, Siddharth Jha, Lutfi Eren Erdogan, Sehoon Kim, Woosang Lim, Kurt Keutzer, and Amir Gholami. Efficient and scalable estimation of tool representations in vector space. arXiv preprint arXiv:2409.02141, 2024. 2, 3, 8\\n\\n[16] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021. 3\\n\\n[17] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. Art: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014, 2023. 3\\n\\n[18] Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. Gorilla: Large language model connected with massive apis. Advances in Neural Information Processing Systems, 37:126544–126565, 2024. 2, 3, 8\\n\\n[19] Yun Peng, Shuqing Li, Wenwei Gu, Yichen Li, Wenxuan Wang, Cuiyun Gao, and Michael R Lyu. Revisiting, benchmarking and exploring api recommendation: How far are we? IEEE Transactions on Software Engineering, 49(4): 1876–1897, 2022. 8\\n\\n[20] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. Toolllm: Facilitating large language models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789, 2023. 8\\n\\n[21] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Xuanhe Zhou, Yufei Huang, Chaojun Xiao, et al. Tool learning with foundation models. ACM Computing Surveys, 57(4):1–40, 2024. 2\\n\\n[22] Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, et al. Alita: Generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal self-evolution. arXiv preprint arXiv:2505.20286, 2025. 10\\n\\n[23] Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, and Ji-Rong Wen. Colt: Towards completeness-oriented tool retrieval for large language models. arXiv e-prints, pages arXiv–2405, 2024.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5062259)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\n",
    "    \"What is Alita and what is MCP Zero? Can Alita and MCP zero work together?\"\n",
    ")\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d6ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 108 ms, sys: 7.47 ms, total: 116 ms\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(llm=llm)\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What is Alita and what is MCP Zero? Can Alita and MCP zero work together?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530de41f",
   "metadata": {},
   "source": [
    "This query took 3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "863cfa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Response:** \n",
       "\n",
       "Alita is a generalist agent designed for scalable agentic reasoning, capable of automatically generating tools and workflows to solve diverse tasks without relying on complex predefined structures. It excels at creating new tools on-the-fly when existing ones are insufficient, enhancing its adaptability. MCP-Zero focuses on efficiently discovering and invoking pre-existing tools through semantic alignment and active requests, optimizing tool retrieval accuracy and reducing context usage.  \n",
       "\n",
       "Alita and MCP-Zero can work synergistically. MCP-Zero's strength in locating existing tools complements Alita's ability to synthesize new tools when needed. Together, they form a self-reinforcing loop: MCP-Zero prioritizes tool discovery, while Alita handles tool creation for gaps, with the newly built tools being registered for future use. This integration enables a more robust, self-evolving system that balances efficiency and adaptability in complex tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"**Response:** {response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924c38ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Response:** \n",
       "\n",
       "Alita and MCP-Zero are complementary components designed to work together in an agent system. MCP-Zero focuses on efficiently discovering and invoking existing tools by actively requesting them through semantically aligned queries, while Alita specializes in automatically building tools from scratch when no suitable existing tool is found. They are not separate tools but rather two sides of the same problem: MCP-Zero maximizes tool discovery, and Alita maximizes tool creation.  \n",
       "\n",
       "To integrate them into an agent:  \n",
       "1. **Prompt the model** to request tools explicitly (e.g., using a structured format like `<tool_assistant>`).  \n",
       "2. **Curate a lightweight tool index** with semantic descriptions for existing tools.  \n",
       "3. **Match the model's requests** against the tool index for retrieval. If no match is found, trigger Alita's workflow to synthesize a new tool.  \n",
       "4. **Register newly created tools** back into the shared pool for future use.  \n",
       "\n",
       "This integration creates a self-evolving loop where MCP-Zero handles existing tools, and Alita fills gaps, enabling agents to scale effectively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How can I use Alita and MCP Zero in an agent? Are they separate tools?\"\n",
    ")\n",
    "display(Markdown(f\"**Response:** {response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8faf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-agents-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
